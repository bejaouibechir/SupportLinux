# Démo 1 — Comprendre le mecanisme

## Objectif

Montrer concrètement que :

- le **démon cron tourne en continu** et **se réveille chaque minute**,

- il lit les **crontabs** et déclenche la commande planifiée,

- on peut **observer l’exécution** via un log utilisateur et via les **journaux système**.

---

## Pré-requis (Debian/Ubuntu)

```bash
# Vérifier que le service cron est actif
sudo systemctl status cron --no-pager
# Si besoin :
# sudo systemctl enable --now cron
```

---

## Étape A — Préparer une action observable

Un mini-script qui écrit la date et l’UID dans un log dans /tmp (pas d’attente longue).

**/usr/local/bin/cron_probe.sh**

```bash
#!/usr/bin/env bash
set -eu
echo "$(date +'%F %T') | UID=$UID | whoami=$(whoami)" 



```

2. Le rendre exécutable
   
   
   
   
   ```bash
   sudo chmod +x /usr/local/bin/cron_probe.sh
   ```
   
   

> Pourquoi /usr/local/bin ? Pour éviter les problèmes de PATH dans cron et utiliser un **chemin absolu** (bonne pratique).

---

## Étape B — Ajouter une crontab utilisateur « chaque minute »

On veut un effet quasi-immédiat (≤60 s) et sans e-mails.

```bash
# Ouvrir la crontab de l'utilisateur courant
crontab -e
```

Ajoutez ces trois lignes tout en haut (pour éviter les mails et fixer le PATH), puis la tâche :

```
MAILTO=""
SHELL=/bin/bash
PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin

* * * * * /usr/local/bin/cron_probe.sh >>/tmp/cron_probe.log 2>&1
```

Enregistrez / quittez.

> Principe : **cron** scrute les **crontabs** et **déclenche à la minute** exacte les commandes planifiées. Les crontabs utilisateur sont stockées sous **/var/spool/cron/** (selon distro), et la syntaxe est « 5 champs de temps + commande ».

---

## Étape C — Observer l’exécution (retour visible en < 60 s)

### 1) Journal applicatif (notre log)

```bash
# Ouvrir un suivi temps réel
tail -f /tmp/cron_probe.log
```

Attendez la prochaine minute : vous verrez apparaître une ligne du type :

```
2025-09-21 20:xx:00 | UID=1000 | whoami=bechir
```

### 2) Journal système (activité du démon cron)

Dans un autre terminal :

```bash
# Debian/Ubuntu : journald
sudo journalctl -u cron -f
# ou parfois via syslog :
# sudo tail -f /var/log/syslog | grep -i CRON
```

Vous verrez des entrées indiquant l’exécution planifiée à chaque minute par le démon.

> Ce que l’on vient d’observer illustre le **principe de fonctionnement** : le **démon cron tourne en continu, se réveille chaque minute, lit les entrées de crontab et exécute la commande au créneau prévu**.

---

## Étape D — (Option) Vérifier la crontab chargée

```bash
crontab -l
```

---

## Nettoyage

```bash
crontab -r                    # supprime la crontab utilisateur
sudo rm -f /usr/local/bin/cron_probe.sh /tmp/cron_probe.log
```





## Étape A — Crontab utilisateur

On veut que **l’utilisateur courant** journalise automatiquement la taille de son répertoire `~/Documents` chaque minute.

```bash
# 1) Créer un script
mkdir -p ~/bin
tee ~/bin/check_docs_size.sh >/dev/null <<'SH'
#!/usr/bin/env bash
du -sh ~/Documents 2>/dev/null | awk '{print strftime("%F %T"), $0}' >> ~/Documents/docs_size.log
SH

chmod +x ~/bin/check_docs_size.sh
```

Ajouter la tâche à la crontab utilisateur :

```bash
crontab -e
```

```
MAILTO=""
* * * * * ~/bin/check_docs_size.sh
```

Vérification après une minute :

```bash
tail -f ~/Documents/docs_size.log
```

👉 Résultat attendu : une ligne ajoutée toutes les minutes avec date + taille du répertoire.

---

## Étape B — Crontab système (/etc/crontab)

On veut que **root** surveille l’espace disque global du serveur (via `df -h`) et logge cela dans `/var/log/disk_check.log`.

```bash
# 1) Éditer le fichier crontab système
sudo nano /etc/crontab
```

Ajouter une ligne (7 champs → inclut l’utilisateur) :

```
* * * * * root df -h / >> /var/log/disk_check.log 2>&1
```

> Ici on utilise `root` explicitement car c’est une crontab système.

Vérification après une minute :

```bash
sudo tail -f /var/log/disk_check.log
```

👉 Résultat attendu : une nouvelle ligne du `df` toutes les minutes.

---

## Étape C — Différences observées

- **Crontab utilisateur** : pas besoin de préciser l’utilisateur, chaque crontab est stockée sous `/var/spool/cron/username`.

- **Crontab système** : champ supplémentaire (utilisateur) obligatoire ; utilisée pour les tâches globales du système (/etc/crontab, /etc/cron.d/).

- **Contexte d’exécution** : la crontab utilisateur hérite du `$HOME` de l’utilisateur, alors que la crontab système hérite souvent d’un environnement minimal.

- **Observation** : logs séparés (dans le répertoire utilisateur vs dans `/var/log`).

---

## Étape D — Nettoyage

```bash
crontab -r
sudo sed -i '/df -h \//d' /etc/crontab
rm -f ~/bin/check_docs_size.sh ~/Documents/docs_size.log
sudo rm -f /var/log/disk_check.log
```

---

## Points pédagogiques clés

- **Crontabs utilisateurs** : fichiers texte propres à chaque utilisateur (via `crontab -e`), stockés dans `/var/spool/cron/`.

- **Crontabs système** : gérés uniquement par root dans `/etc/crontab` ou `/etc/cron.d/*`, nécessitent un champ utilisateur supplémentaire.

- **Usage typique** :
  
  - **Utilisateur** → tâches personnelles (ex : backup de Documents).
  
  - **Système** → surveillance globale ou maintenance serveur.

# 

## 

## Étape A — Crontab utilisateur

**But** : journaliser automatiquement la taille du répertoire `~/Documents` chaque minute.

### 1) Créer un script

bash:

```bash
mkdir -p ~/bin
```

Créer le fichier `~/bin/check_docs_size.sh` :  
bash:

```bash
#!/usr/bin/env bash
du -sh ~/Documents 2>/dev/null | awk '{print strftime("%F %T"), $0}' >> ~/Documents/docs_size.log
```

### 2) Rendre le script exécutable

bash:

```bash
chmod +x ~/bin/check_docs_size.sh
```

### 3) Ajouter une tâche cron utilisateur

Éditer la crontab de l’utilisateur :  
bash:

```bash
crontab -e
```

Ajouter la ligne suivante :

```
MAILTO=""
* * * * * ~/bin/check_docs_size.sh
```

### 4) Vérification

Après une minute :  
bash:

```bash
tail -f ~/Documents/docs_size.log
```

---

## Étape B — Crontab système

**But** : root surveille l’espace disque global et consigne le résultat dans `/var/log/disk_check.log`.

### 1) Éditer la crontab système

bash:

```bash
sudo nano /etc/crontab
```

Ajouter la ligne suivante :

```
* * * * * root df -h / >> /var/log/disk_check.log 2>&1
```

### 2) Vérification

Après une minute :  
bash:

```bash
sudo tail -f /var/log/disk_check.log
```

---

## Étape C — Différences observées

- **Crontab utilisateur** → ne précise pas l’utilisateur, chaque tâche appartient à un compte.

- **Crontab système** → champ supplémentaire obligatoire pour indiquer l’utilisateur.

- **Stockage** :
  
  - Utilisateur → `/var/spool/cron/<username>`
  
  - Système → `/etc/crontab`, `/etc/cron.d/*`

- **Contexte d’exécution** : environnement différent (HOME utilisateur vs contexte root).

---

## Étape D — Nettoyage

bash:

```bash
crontab -r
sudo sed -i '/df -h \//d' /etc/crontab
rm -f ~/bin/check_docs_size.sh ~/Documents/docs_size.log
sudo rm -f /var/log/disk_check.log
```

Parfait. Je reprends entièrement la démo “Crontabs utilisateurs et système” en respectant **votre style** (étapes séparées, création de fichiers explicite, scripts commentés, astuces pratiques), avec un scénario **réel** et un effet **quasi-instantané** (tâches à la minute).

# Démo 2 — Crontabs utilisateurs et système

## Objectif réel

- Côté **utilisateur** : détecter les gros fichiers qui “gonflent” le $HOME (veille de capacité personnelle).

- Côté **système (root)** : surveiller l’espace disque et **journaliser une alerte** si un seuil est dépassé.

- Montrer concrètement la différence **crontab utilisateur** vs **crontab système** et comment vérifier ce que cron exécute.

---

## Pré-requis (Debian/Ubuntu)

bash:

```bash
# Vérifier que le démon cron tourne (sinon l’activer)
sudo systemctl status cron --no-pager
# sudo systemctl enable --now cron
```

---

## Partie A — Crontab **utilisateur** : détecter les gros fichiers du $HOME

### 1) Créer un dossier pour les scripts perso

bash:

```bash
mkdir -p ~/bin
```

### 2) Créer le fichier `~/bin/large_files_watch.sh` (script commenté)

bash:

```bash
#!/usr/bin/env bash
# Objet : lister les 5 plus gros fichiers (>100 Mo) dans $HOME, avec horodatage
# Pièges visés : PATH minimal dans cron → on utilisera des chemins absolus
# Sortie : journalisation append dans ~/cron.d/home_watch.log (stdout) et ~/cron.d/home_watch.err (stderr)

set -Eeuo pipefail

# Variables
THRESHOLD_SIZE="+100M"                      # Seuil de taille
LOG_DIR="${HOME}/cron.d"
OK_LOG="${LOG_DIR}/home_watch.log"
ERR_LOG="${LOG_DIR}/home_watch.err"

# Prépare le dossier de logs
mkdir -p "${LOG_DIR}"

# whoami pour lever toute ambiguïté d’utilisateur → utile en crontab utilisateur
EXEC_USER="$(/usr/bin/id -u -n)"
NOW="$(/usr/bin/date +'%F %T')"

# Commandes avec chemins absolus (cron a un PATH minimal):contentReference[oaicite:1]{index=1}
/usr/bin/find "${HOME}" -xdev -type f -size "${THRESHOLD_SIZE}" -printf '%s %p\n' \
  2>>"${ERR_LOG}" \
| /usr/bin/sort -nr \
| /usr/bin/head -n 5 \
| /usr/bin/awk -v now="${NOW}" -v user="${EXEC_USER}" '{
    size=$1; $1=""; sub(/^ /,"");
    printf "%s | user=%s | size=%s bytes | file=%s\n", now, user, size, $0
  }' >> "${OK_LOG}"
```

### 3) Rendre le script exécutable

bash:

```bash
chmod +x ~/bin/large_files_watch.sh
```

### 4) Tester **avant** d’attendre 1 minute (bon réflexe)

bash:

```bash
bash ~/bin/large_files_watch.sh
tail -n 5 ~/cron.d/home_watch.log
```

### 5) Ajouter la tâche dans la **crontab utilisateur**

bash:

```bash
crontab -e
```

Ajoutez (tout en haut pour l’environnement), puis la ligne planifiée :

```
MAILTO=""
SHELL=/bin/bash
PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin

* * * * * /home/$USER/bin/large_files_watch.sh >> /home/$USER/cron.d/home_watch.log 2>> /home/$USER/cron.d/home_watch.err
```

> Rappels issus du document : crontab utilisateur = 5 champs + commande, exécutée si la machine est allumée au créneau ; `MAILTO` contrôle l’envoi de mails ; définir un `PATH` explicite évite les surprises.

### 6) Vérifier l’exécution (≤ 60 s)

bash:

```bash
tail -f ~/cron.d/home_watch.log
```

---

## Partie B — Crontab **système** : garde disque (alerte quand / dépasse 80%)

### 1) Créer le fichier `/usr/local/sbin/disk_guard.sh` (script commenté)

bash:

```bash
sudo bash -c 'cat > /usr/local/sbin/disk_guard.sh' << "EOF"
#!/usr/bin/env bash
# Objet : alerter si la partition / dépasse 80% d’utilisation
# Différences "système" : s’exécute en contexte root via /etc/crontab (7 champs, champ utilisateur requis):contentReference[oaicite:3]{index=3}

set -Eeuo pipefail
THRESHOLD=80
LOG=/var/log/disk_guard.log

NOW="$(/usr/bin/date +'%F %T')"
WHO="$((/usr/bin/id -u -n) 2>/dev/null || echo root)"

# Utiliser des chemins absolus (PATH minimal dans cron):contentReference[oaicite:4]{index=4}
USAGE="$(/bin/df -P / | /usr/bin/awk "NR==2 {gsub(/%/,\"\",\$5); print \$5}")"

if [ "${USAGE}" -ge "${THRESHOLD}" ]; then
  echo "${NOW} | user=${WHO} | ALERT: / usage=${USAGE}% (>=${THRESHOLD}%)" >> "${LOG}"
else
  echo "${NOW} | user=${WHO} | OK: / usage=${USAGE}%" >> "${LOG}"
fi
EOF
```

### 2) Rendre exécutable

bash:

```bash
sudo chmod +x /usr/local/sbin/disk_guard.sh
```

### 3) Tester manuellement

bash:

```bash
sudo /usr/local/sbin/disk_guard.sh
sudo tail -n 5 /var/log/disk_guard.log
```

### 4) Ajouter la tâche dans **/etc/crontab** (crontab système)

bash:

```bash
sudo nano /etc/crontab
```

Ajoutez en haut (environnement), puis la ligne planifiée **avec le champ utilisateur `root`** :

```
MAILTO=""
SHELL=/bin/sh
PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin

* * * * * root /usr/local/sbin/disk_guard.sh >> /var/log/disk_guard.log 2>&1
```

> Rappels issus du document : crontab système = **7 champs** (les 5 temps + **utilisateur** + commande). `/etc/crontab` et `/etc/cron.d/*` sont réservés à root.

### 5) Vérifier l’exécution (≤ 60 s)

bash:

```bash
sudo tail -f /var/log/disk_guard.log
```

---

## Contrôles & diagnostics utiles (les bons réflexes)

bash:

```bash
# Ce que cron a réellement chargé pour VOUS (utilisateur)
crontab -l

# Ce que le système va exécuter (crontab système)
sudo cat /etc/crontab

# Journaux du démon cron (utile pour voir le déclenchement minute par minute)
sudo journalctl -u cron -f
# (sur certaines distros, on peut aussi voir via syslog : sudo tail -f /var/log/syslog | grep -i CRON)
```

> Le démon cron tourne en continu et se réveille **chaque minute** pour lire les crontabs et exécuter les commandes planifiées ; la sortie est envoyée par mail sauf si redirigée ou `MAILTO=""`.

---

## Astuces pédagogiques (applicables en prod)

- **Chemins absolus** : le `$PATH` de cron est minimal → utilisez `/bin/df`, `/usr/bin/awk`, etc., ou définissez `PATH` en tête de la crontab.

- **Qui exécute ?** Ajoutez `$(whoami)` / `id -u -n` dans vos logs pour tracer le **contexte utilisateur**.

- **Éviter le spam d’emails** : `MAILTO=""` ou redirigez proprement `>> ok.log 2>> err.log`.

- **Tester avant d’attendre** : lancez le script **à la main** (bash …) puis attendez la minute pour valider l’intégration cron.

- **Séparer stdout/stderr** : `>> ~/…/ok.log 2>> ~/…/error.log` pour accélérer le diagnostic.

- **Crontab utilisateur vs système** : utilisateur = 5 champs ; système = 7 champs (**+ utilisateur**) et édité par root.

---

## Nettoyage

bash:

```bash
# Crontab utilisateur
crontab -r
rm -rf ~/cron.d
rm -f  ~/bin/large_files_watch.sh

# Crontab système
sudo sed -i '\|/usr/local/sbin/disk_guard.sh|d' /etc/crontab
sudo rm -f /usr/local/sbin/disk_guard.sh /var/log/disk_guard.log
```

---

## Ce que vous avez vraiment appris (valeur)

- Différencier **crontab utilisateur** et **crontab système**, avec preuves observables dans des logs distincts.

- Composer des **scripts robustes** pour cron (chemins absolus, logs séparés, `whoami`, `set -euo pipefail`).

- Savoir **diagnostiquer** (journal du démon cron, inspection des crontabs chargées).

Souhaitez-vous que je passe au **point suivant du plan** (syntaxe des champs + opérateurs `* , - /` avec une démo “zéro attente”), ou préférez-vous que j’ajoute une variante à cette démo (par ex. surveillance d’un **répertoire applicatif** via **/etc/cron.d** au lieu de `/etc/crontab`) ?

---

# Démo 3 — Maîtriser la syntaxe des champs cron avec un cas concret

## 🎯 Objectif

Mettre en pratique les **5 champs cron** (minute, heure, jour, mois, jour-semaine) pour planifier des tâches variées, en utilisant un cas **réel et simple** :

- **Surveillance d’un petit service web local** (un serveur Python minimal).

- Envoi périodique d’une requête avec `curl`, et journalisation dans un log.

Ainsi, chaque champ de cron aura un rôle concret visible.

---

## Étape A — Lancer un petit service web local (zéro dépendance externe)

1. Dans un terminal, lancez un mini serveur Python sur le port 8080 :

```bash
python3 -m http.server 8080 --bind 127.0.0.1
```

2. Vérifiez dans un autre terminal :

```bash
curl http://127.0.0.1:8080/
```

Vous devez voir une page HTML listant les fichiers du répertoire courant.

👉 Ce serveur est **instantané, léger, et ne détourne pas du sujet principal**.

---

## Étape B — Préparer le script de « health-check »

On veut une commande qui enregistre dans un log si le service répond.

Créer les fichier **/usr/local/bin/health_check.sh**

```bash
#!/usr/bin/env bash
URL="http://127.0.0.1:8080/"
STATUS=$(curl -s -o /dev/null -w "%{http_code}" "$URL")
DATE=$(date +'%F %T')
if [ "$STATUS" = "200" ]; then
  echo "$DATE | $URL OK" 
else
  echo "$DATE | $URL DOWN (status=$STATUS)"
fi
```

Puis ajouter les premissions d'execution

```bash
sudo chmod +x /usr/local/bin/health_check.sh
```

## Étape C — Ajouter des entrées crontab avec différentes syntaxes

Ouvrez votre crontab utilisateur :

```bash
crontab -e
```

Ajoutez (en haut) les variables utiles :

```
MAILTO=""
SHELL=/bin/bash
PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
```

Puis insérez les lignes suivantes (toutes redirigent vers `/tmp/health.log`) :

```
# Chaque minute → vérification rapide
* * * * * /usr/local/bin/health_check.sh >>/tmp/health.log 2>&1

# Toutes les 5 minutes entre 09h et 17h (plage d'heures)
*/5 9-17 * * * /usr/local/bin/health_check.sh >>/tmp/health.log 2>&1

# Tous les lundis à 08h30
30 8 * * 1 /usr/local/bin/health_check.sh >>/tmp/health.log 2>&1

# Le 1er de chaque mois à minuit pile
0 0 1 * * /usr/local/bin/health_check.sh >>/tmp/health.log 2>&1
```

---

## Étape D — Observer les résultats

1. Surveiller le log :

```bash
tail -f /tmp/health.log
```

Exemple attendu (visible quasi immédiatement grâce à la première ligne `* * * * *`) :

```
2025-09-23 19:01:00 | http://127.0.0.1:8080/ OK
2025-09-23 19:02:00 | http://127.0.0.1:8080/ OK
```

2. Désactivez le serveur pour tester un cas d’échec :
   
   - Stoppez le serveur Python (Ctrl+C).
   
   - Attendez la prochaine minute → vous verrez :

```
2025-09-23 19:03:00 | http://127.0.0.1:8080/ DOWN (status=000)
```

---

## Étape E — Nettoyage

```bash
crontab -r
sudo rm -f /usr/local/bin/health_check.sh /tmp/health.log
```

---

## 🧩 Points pédagogiques mis en avant

- **Minute** : `*` ou `*/5` pour des fréquences différentes.

- **Heure** : `9-17` pour limiter la plage horaire.

- **Jour du mois** : `1` pour cibler le 1er jour.

- **Mois** : (non utilisé ici, mais on aurait pu mettre `1,6` pour janvier et juin).

- **Jour de la semaine** : `1` (lundi).

- **Commande** : toujours un chemin absolu (`/usr/local/bin/...`).

- Observation **immédiate** grâce à l’entrée `* * * * *`.

# Démo 4 — Opérateurs cron (* , - /) sur un cas réel « sonde de santé HTTP »

## Objectif

Mettre en place une **sonde de santé** d’un service web (intranet, API, site « status ») avec un planning **granulaire** exploitant tous les opérateurs :

- `*` (toutes les valeurs), `,` (liste), `-` (plage), `/` (pas) dans les 5 champs cron.  
  Rappel : les 5 champs sont minute, heure, jour du mois, mois, jour de semaine, suivis de la commande.

---

## Pré-requis (Debian/Ubuntu)

```bash
# 1) curl est requis pour sonder une URL
sudo apt-get update && sudo apt-get install -y curl

# 2) s'assurer que cron tourne
sudo systemctl enable --now cron
```

---

## Étape A — Préparer le script (dépendances présentées et installées)

Ce script sonde une URL, **log uniquement les anomalies** (non-200) dans `/var/log/site_health.log`.

Créer le fichier */usr/local/bin/site_health.sh:*

```bash
#!/usr/bin/env bash
set -euo pipefail

URL="${URL:-https://example.com}"     # surcharge possible via variable d'env
TS="$(date +'%F %T')"
CODE="$(curl -k -s -o /dev/null -w '%{http_code}' "$URL")"

# On ne log QUE si ça ne va pas (code != 200)
if [ "$CODE" != "200" ]; then
  echo "$TS | ALERT | url=$URL | http_code=$CODE | host=$(hostname)" 
fi
```

Executer les commandes:

```bash
# Droits et log
sudo chmod +x /usr/local/bin/site_health.sh
sudo touch /var/log/site_health.log
sudo chmod 666 /var/log/site_health.log   # pour voir le log sans sudo en démo
```

> Bonnes pratiques cron : **chemins absolus**, environnement minimal.

---

## Étape B — MODE DÉMO (visible en <60 s)

On exécute **chaque minute** pour observer immédiatement.

```bash
crontab -e
```

Ajoutez en haut :

```
MAILTO=""
SHELL=/bin/bash
PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
URL=https://example.com
```

Puis la tâche démo (une ligne) :

```
*/1 * * * * /usr/local/bin/site_health.sh >>/var/log/site_health.log 2>&1
```

Surveillance en temps réel :

```bash
tail -f /var/log/site_health.log
```

Optionnel (observer l’activité du démon cron) :

```bash
sudo journalctl -u cron -f
```

> Le démon **cron** tourne en continu, **se réveille chaque minute** et exécute selon les entrées de crontab.

---

## Étape C — MODE RÉEL (utilisation astucieuse des opérateurs)

Quand la démo est validée, remplacez la ligne précédente par **un planning fin** qui exploite `* , - /` :

```
*/5 9-18 * 1,6 1-5 /usr/local/bin/site_health.sh >>/var/log/site_health.log 2>&1
```

### Pourquoi cet exemple est « réel » et astucieux

- **`*/5` (opérateur `/`)** : sonde toutes les **5 minutes** (pas de 5) pendant les plages visées.

- **`9-18` (opérateur `-`)** : **plage horaire** de bureau 09:00→18:59 (heures locales).

- **`*` (généralisation)** sur le jour du mois : tous les jours du mois.

- **`1,6` (opérateur `,`)** sur le mois : **janvier et juin** seulement (ex. période de haute charge ou audits semestriels).

- **`1-5` (opérateur `-`)** sur le jour de semaine : **lundi à vendredi** (on épargne les week-ends).

Résultat : en **janvier** et **juin**, du **lundi au vendredi**, entre **09:00 et 18:59**, la sonde s’exécute **toutes les 5 minutes**. C’est typique d’une **fenêtre de supervision renforcée** (période d’inventaire, campagne RH, clôture comptable…).

> Référence rappel opérateurs et champs de temps dans la crontab utilisateur/système.

---

## Tests ciblés (provoquer une alerte sans attendre)

- Remplacez provisoirement la variable d’environnement dans la crontab par une URL invalide pour déclencher un log d’alerte :
  
  ```
  URL=https://invalid.local
  ```

- Ou lancez le script **à la main** avec une URL en erreur :
  
  ```bash
  URL=https://invalid.local /usr/local/bin/site_health.sh | tee -a /var/log/site_health.log
  ```

---

## Pièges & astuces utiles

- **Évitez de combiner “jour du mois” et “jour de semaine” sans y réfléchir** : selon l’implémentation, la tâche peut se déclencher si **l’un OU l’autre** correspond. Séparez les cas au besoin (deux lignes) pour un contrôle strict.

- **MAILTO** vide en démo pour ne pas spammer ; en prod, envoyez-vous **uniquement les erreurs** (le script n’écrit que si code ≠ 200).

- **PATH explicite** et **chemins absolus** (cron a un environnement minimal).

- Si vous avez besoin d’un **contexte réseau/dépendances** (VPN, secrets), lancez via **crontab système** sous un **compte dédié** avec droits limités et variables chargées depuis un fichier sécurisé.

---

## Nettoyage

```bash
crontab -r
sudo rm -f /usr/local/bin/site_health.sh /var/log/site_health.log
```

Parfait. On reste strictement dans le plan.

# Démo 5 — Raccourcis cron (@hourly, @daily, @weekly) appliqués à un cas réel

**Objectif :** mettre en place une maintenance “intelligente” d’un dossier d’uploads d’application avec trois niveaux :

- **@hourly** : compresser les fichiers de plus d’1h pour économiser de l’espace.

- **@daily** : déplacer les archives du jour vers un répertoire de backup et purger au-delà de 7 jours.

- **@weekly** : produire un rapport synthèse (taille, nombre de fichiers) pour contrôle.

> On utilise les **raccourcis cron** plutôt que les 5 champs classiques, tels que documentés dans le cours (ex. `@hourly`, `@daily`, `@weekly`).

---

## Pré-requis (Debian/Ubuntu)

Aucune dépendance exotique. On n’utilise que des utilitaires standards (`bash`, `find`, `tar`, `du`, `date`).  
Vérifier que cron tourne :

```bash
sudo systemctl enable --now cron
sudo systemctl status cron --no-pager
```

Les raccourcis (`@hourly`, `@daily`, `@weekly`, `@monthly`, `@annually`) font partie de la syntaxe cron prévue par la doc.

---

## Préparation de l’environnement (pas de “solution parachutée”)

Créez l’arborescence, un log dédié et trois scripts **clairs** dans `/usr/local/bin` :

```bash
# Dossiers de travail
sudo mkdir -p /srv/app/uploads /var/backups/app
sudo touch /var/log/app_maintenance.log
sudo chmod 666 /var/log/app_maintenance.log
```

Créer ke script de compression des fichiers de uploads de plus d'une heure ***/usr/local/bin/app_hourly_pack.sh:***

```bash
#!/usr/bin/env bash
set -euo pipefail
UPS="/srv/app/uploads"
TMP="/var/backups/app"
LOG="/var/log/app_maintenance.log"
stamp="$(date +'%F %T')"

# Trouve les fichiers modifiés il y a > 60 min et les colle dans une archive horodatée
mapfile -t files < <(find "$UPS" -type f -mmin +60 2>/dev/null)
if (( ${#files[@]} )); then
  out="$TMP/hourly_$(date +'%F_%H%M').tar.gz"
  tar -C "$UPS" -czf "$out" "${files[@]/#${UPS}\//}" 2>>"$LOG"
  printf "%s | HOURLY | %d fichiers compressés -> %s\n" "$stamp" "${#files[@]}" "$out" >>"$LOG"
  # Optionnel: supprimer les originaux après archive (décommentez si souhaité)
  # rm -f "${files[@]}"
else
  printf "%s | HOURLY | rien à compresser\n" "$stamp" >>"$LOG"
fi

sudo chmod +x /usr/local/bin/app_hourly_pack.sh

# 2) Script @daily : déplacer les archives du jour en backups stables et purger > 7 jours
sudo tee /usr/local/bin/app_daily_rotate.sh >/dev/null <<'SH'
#!/usr/bin/env bash
set -euo pipefail
SRC="/var/backups/app"
DST="/var/backups/app/daily"
LOG="/var/log/app_maintenance.log"
stamp="$(date +'%F %T')"

mkdir -p "$DST"

# Déplacer les archives "hourly_*.tar.gz" de la veille vers le dossier daily
# (on prend tout ce qui existe pour simplifier la démo)
shopt -s nullglob
moved=0
for f in "$SRC"/hourly_*.tar.gz; do
  mv "$f" "$DST"/
  ((moved++))
done

# Purge : supprimer les daily de plus de 7 jours
purged=$(find "$DST" -type f -mtime +7 -name '*.tar.gz' -print -delete | wc -l)

printf "%s | DAILY | déplacés=%d | purgés>7j=%d | dossier=%s\n" "$stamp" "$moved" "$purged" "$DST" >>"$LOG"
SH
sudo chmod +x /usr/local/bin/app_daily_rotate.sh

# 3) Script @weekly : rapport d'intégrité (taille et nombre de fichiers)
sudo tee /usr/local/bin/app_weekly_report.sh >/dev/null <<'SH'
#!/usr/bin/env bash
set -euo pipefail
UPS="/srv/app/uploads"
DST="/var/backups/app/daily"
LOG="/var/log/app_maintenance.log"
stamp="$(date +'%F %T')"

# Taille en blocs et nombre de fichiers
size_uploads=$(du -sh "$UPS" 2>/dev/null | awk '{print $1}')
count_uploads=$(find "$UPS" -type f 2>/dev/null | wc -l)
size_daily=$(du -sh "$DST" 2>/dev/null | awk '{print $1}')
count_daily=$(find "$DST" -type f -name '*.tar.gz' 2>/dev/null | wc -l)

printf "%s | WEEKLY | uploads: %s (%s fichiers) | daily: %s (%s archives)\n" \
  "$stamp" "${size_uploads:-0}" "$count_uploads" "${size_daily:-0}" "$count_daily" >>"$LOG"
```

Puis executer la commande:

```bash
sudo chmod +x /usr/local/bin/app_weekly_report.sh
```

> Bonnes pratiques cron : **chemins absolus**, **SHELL/MAILTO/PATH** explicites dans la crontab, redirections gérées pour éviter des mails intempestifs.

---

## Installation des tâches avec les raccourcis cron

Ouvrez votre crontab utilisateur :

```bash
crontab -e
```

Ajoutez en haut :

```
MAILTO=""
SHELL=/bin/bash
PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
```

Puis ajoutez les trois tâches avec **raccourcis** :

```
@hourly  /usr/local/bin/app_hourly_pack.sh    >>/var/log/app_maintenance.log 2>&1
@daily   /usr/local/bin/app_daily_rotate.sh   >>/var/log/app_maintenance.log 2>&1
@weekly  /usr/local/bin/app_weekly_report.sh  >>/var/log/app_maintenance.log 2>&1
```

> Ces formes `@hourly/@daily/@weekly` sont **équivalentes** à des expressions classiques (ex. `0 * * * *` pour `@hourly`) mais **plus lisibles** et **moins sujettes à erreur**.

---

## Vérification & observation (quasi instantané)

1. **Générez de la matière** pour que l’@hourly ait quelque chose à compresser :

```bash
# Simuler des uploads "anciens" (touch -d pour antidater à > 60 min)
for i in {1..5}; do
  sudo dd if=/dev/urandom of="/srv/app/uploads/file_$i.bin" bs=1K count=128 status=none
  sudo touch -d "90 minutes ago" "/srv/app/uploads/file_$i.bin"
done
```

2. **Attendez le prochain top minute** (≤ 60 s). Surveillez le log dédié :

```bash
tail -f /var/log/app_maintenance.log
```

Vous devriez voir passer une ligne **HOURLY** indiquant combien de fichiers ont été compressés et où se trouve l’archive.

3. **Contrôle des artefacts** :

```bash
ls -lh /var/backups/app        # archives hourly_*.tar.gz
```

> Pour **@daily** et **@weekly**, vous n’avez rien à attendre en démo : lancez une **exécution manuelle** ponctuelle pour valider la logique sans attendre minuit ou la fin de semaine :

```bash
/usr/local/bin/app_daily_rotate.sh   && tail -n1 /var/log/app_maintenance.log
/usr/local/bin/app_weekly_report.sh  && tail -n1 /var/log/app_maintenance.log
```

Astuce : c’est exactement le **même code** que cron déclenchera aux créneaux prévus par les raccourcis.

---

## Ce que cette démo prouve

- **Lisibilité & robustesse** : en prod, les raccourcis `@hourly/@daily/@weekly` **réduisent les erreurs** par rapport aux 5 champs et facilitent la revue.

- **Cas réel** : on traite un vrai besoin DevOps (optimiser espace, organiser backups, suivi chiffré).

- **Traçabilité** : un **log unique** `/var/log/app_maintenance.log` raconte l’histoire (compactions, rotations, rapports).

- **Sans dépendances exotiques** : utilisables sur n’importe quelle Debian/Ubuntu standard.

- **Quasi instantané** : résultat visible en < 60 s pour @hourly ; exécution **manuelle** immédiate pour valider @daily/@weekly sans attendre.

---

## Nettoyage (si besoin)

```bash
crontab -r
sudo rm -rf /srv/app/uploads /var/backups/app /var/log/app_maintenance.log
sudo rm -f /usr/local/bin/app_hourly_pack.sh /usr/local/bin/app_daily_rotate.sh /usr/local/bin/app_weekly_report.sh
```

Parfait — on enchaîne strictement avec **Démo 5 — Raccourcis cron (@hourly, @daily, @weekly, @monthly, @annually)**, en gardant le même style : cas réel, quasi-instantané à tester, dépendances préparées, et **scripts présentés séparément des commandes** (pas de `tee <<'SH'`).  
Je m’appuie sur la section « Spécifications horaires particulières » et variables crontab du document.

# Démo 5 — Pipeline de maintenance de logs avec raccourcis cron

## Objectif

Mettre en place une **stratégie de maintenance de logs réaliste** (rotation, compression, purge, archivage) en s’appuyant sur les **raccourcis cron** (`@hourly`, `@daily`, `@weekly`, `@monthly`). 

## Pré-requis (Debian/Ubuntu)

```bash
# 1) S'assurer que cron tourne
sudo systemctl status cron --no-pager || sudo systemctl enable --now cron

# 2) Outils utiles (gzip, tar, tree)
sudo apt-get update
sudo apt-get install -y gzip tar tree
```

---

## Structure du cas réel

Commencer par créer ces dossiers:

- Dossier source de logs applicatifs : `/opt/demo-logs/incoming`

- Dossier de logs compressés : `/opt/demo-logs/compressed`

- Dossier d’archives mensuelles : `/opt/demo-logs/archive`

- Scripts d’orchestration : `/opt/demo-logs/scripts/`

Chaque raccourci cron lancera **le même script** avec un **mode** différent :

- `@hourly` → rotation “douce” des logs courants (renommage + ajout d’horodatage).

- `@daily` → **compression** des `.log` en `.gz`.

- `@weekly` → **purge** des `.gz` de plus de 14 jours.

- `@monthly` → **archivage** des `.gz` du mois précédent en un `.tar.gz`.

> Ces quatre fréquences correspondent exactement aux raccourcis décrits dans le document.

---

## Étape A — Préparer l’aire de test (quasi immédiat)

```bash
sudo mkdir -p /opt/demo-logs/{incoming,compressed,archive,scripts}
sudo chown -R "$USER":"$USER" /opt/demo-logs

# Générer quelques faux logs applicatifs pour la démo
cd /opt/demo-logs/incoming
printf "INFO Start %s\n" "$(date)" > app.log
for i in {1..5}; do printf "INFO line %02d at %s\n" "$i" "$(date)"; done >> app.log
cp app.log access.log
```

Vérifiez :

```bash
tree /opt/demo-logs
```

---

## Étape B — Créer les scripts (contenu + droits)

### 1) Fichier `/opt/demo-logs/scripts/log_maintenance.sh`

> Créez ce fichier avec votre éditeur (ex. `nano /opt/demo-logs/scripts/log_maintenance.sh`) puis **collez** le contenu ci-dessous.

```bash
#!/usr/bin/env bash
#-e → le script s’arrête immédiatement si une commande échoue 
#-u → le script s’arrête si on utilise une variable non définie 
#-o pipefail le script échoue si n’importe quelle commande du pipeline échoue (pas seulement la dernière).
set -euo pipefail

BASE="/opt/demo-logs"
SRC="$BASE/incoming"
CMP="$BASE/compressed"
ARC="$BASE/archive"
# ${1:-}" la variable est vide ou non définie, utilise la valeur par défaut (ici vide)
mode="${1:-}"
ts_now="$(date +'%Y%m%d-%H%M%S')"

case "$mode" in
  hourly)
    # Rotation douce: renomme les .log actifs avec timestamp pour figer un snapshot
    # (sans compression immédiate)
    find "$SRC" -maxdepth 1 -type f -name '*.log' | while read -r f; do
      mv -f "$f" "${f%.log}.$ts_now.log"
    done
    ;;

  daily)
    # Compression des .log en .gz vers compressed/
    mkdir -p "$CMP"
    find "$SRC" -maxdepth 1 -type f -name '*.log' | while read -r f; do
      gzip -c "$f" > "$CMP/$(basename "$f").$ts_now.gz"
      : > "$f"   # Troncature du log source (logrotate-like minimal)
    done
    ;;

  weekly)
    # Purge des .gz vieux de +14 jours
    find "$CMP" -type f -name '*.gz' -mtime +14 -print -delete
    ;;

  monthly)
    # Archivage des .gz du mois précédent → archive/YYYY-MM.tar.gz
    mkdir -p "$ARC"
    prev_month="$(date -d "$(date +%Y-%m-15) -1 month" +%Y-%m)"
    tmp_list="$(mktemp)"
    find "$CMP" -type f -name '*.gz' -newermt "$prev_month-01" ! -newermt "$prev_month-31 23:59:59" -print > "$tmp_list"
    if [ -s "$tmp_list" ]; then
      tar -czf "$ARC/${prev_month}.tar.gz" -T "$tmp_list"
      xargs -a "$tmp_list" rm -f
    fi
    rm -f "$tmp_list"
    ;;

  *)
    echo "Usage: $0 {hourly|daily|weekly|monthly}" >&2
    exit 2
    ;;
esac
```

Puis :

```bash
chmod +x /opt/demo-logs/scripts/log_maintenance.sh
```

### 2)  Fichier `/opt/demo-logs/scripts/inspect.sh` (Optionel)

> Pour visualiser rapidement l’état des dossiers.

```bash
#!/usr/bin/env bash
set -euo pipefail
echo "=== incoming ===";  ls -lh /opt/demo-logs/incoming || true
echo "=== compressed ===";ls -lh /opt/demo-logs/compressed || true
echo "=== archive ===";  ls -lh /opt/demo-logs/archive   || true
```

Puis :

```bash
chmod +x /opt/demo-logs/scripts/inspect.sh
```

---

## Étape C — Tests **instantanés** (sans attendre cron)

> On exécute **manuellement** chaque mode pour constater l’effet immédiatement, avant de confier la cadence à cron.

```bash
# 1) État initial
/opt/demo-logs/scripts/inspect.sh

# 2) Simuler @hourly
/opt/demo-logs/scripts/log_maintenance.sh hourly
/opt/demo-logs/scripts/inspect.sh

# 3) Simuler @daily
/opt/demo-logs/scripts/log_maintenance.sh daily
/opt/demo-logs/scripts/inspect.sh

# 4) Simuler @weekly (purge >14j) — créez vite un faux vieux .gz pour démonstration
touch -d "20 days ago" /opt/demo-logs/compressed/fake-old.gz
/opt/demo-logs/scripts/log_maintenance.sh weekly
/opt/demo-logs/scripts/inspect.sh

# 5) Simuler @monthly (archive le mois précédent)
# Pour la démo, on fabrique un .gz daté du mois précédent :
prev_month=$(date -d "$(date +%Y-%m-15) -1 month" +%Y-%m)
touch -d "$prev_month-10" /opt/demo-logs/compressed/synthetic-$prev_month.gz
/opt/demo-logs/scripts/log_maintenance.sh monthly
/opt/demo-logs/scripts/inspect.sh
```

---

## Étape D — Programmer avec **raccourcis cron**

> On inscrit maintenant les **raccourcis** dans la crontab **utilisateur**. La syntaxe des raccourcis (`@hourly`, `@daily`, etc.) est conforme au document.

```bash
crontab -e
```

Ajoutez (tout en haut) ces variables recommandées, puis les lignes de planification :

```
MAILTO=""
SHELL=/bin/bash
PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin

@hourly  /opt/demo-logs/scripts/log_maintenance.sh hourly
@daily   /opt/demo-logs/scripts/log_maintenance.sh daily
@weekly  /opt/demo-logs/scripts/log_maintenance.sh weekly
@monthly /opt/demo-logs/scripts/log_maintenance.sh monthly
# @annually (exemple si besoin) :
# @annually /opt/demo-logs/scripts/yearly_report.sh
```

> Rappel : dans les crontabs **utilisateur**, on a 5 champs “temps + commande”, mais les **raccourcis** remplacent ces 5 champs par un mot-clé lisible.

Vérifiez :

```bash
crontab -l
```

---

## Vérifications & observation

- **Exécution réelle par cron** :
  
  - Attendez le prochain **début d’heure** pour `@hourly` (ou laissez tourner).
  
  - Les autres suivront leur cadence.

- **Journaux système (activité du démon cron)** :

```bash
sudo journalctl -u cron -f
# ou selon distro :
# sudo tail -f /var/log/syslog | grep -i CRON
```

> Le démon cron fonctionne en continu et déclenche les tâches aux créneaux des raccourcis.

---

## Nettoyage (si nécessaire)

```bash
crontab -r
rm -rf /opt/demo-logs
```

---

## Points pédagogiques clés

- Les **raccourcis cron** (`@hourly`, `@daily`, `@weekly`, `@monthly`, `@annually`) **remplacent les 5 colonnes temporelles** et lisent mieux en production.

- Cas réel mis en place : **pipeline de maintenance de logs** complet (rotation, compression, purge, archivage) — pratique, réutilisable.

- **Quasi-instantané** : on **teste manuellement** chaque mode avec le même script pour valider sans attendre le calendrier.

- Bonnes pratiques : **chemins absolus**, `MAILTO=""`, `SHELL=/bin/bash`, `PATH` explicite.

---

parfait—je reprends **toute la démo “Variables de crontab (HOME, MAILTO, PATH, SHELL)”** en intégrant tous les correctifs que vous avez validés (fallback sur `USER`, création du dossier, debug, MTA local, etc.).  
Je garde votre style : **commandes séparées** des **contenus de scripts**, déclenchement **toutes les minutes** (effet < 60 s), pas de splitview.  
Les points de doctrine (rôle de cron, variables crontab, e-mails, PATH/SHELL/HOME) proviennent du doc.

---

# Démo 6 (corrigée) — Variables de crontab + mails locaux

## Objectif

Mettre en place un mini reporting lancé par cron, qui prouve concrètement l’effet de :

- `SHELL` (shell utilisé par cron ; par défaut `/bin/sh`, on force bash si besoin)

- `PATH` (accès aux binaires hors chemins “classiques”, ex. `/usr/local/bin`)

- `HOME` (répertoire de travail pour les chemins relatifs)

- `MAILTO` (où part la sortie/erreur ; chaîne vide = pas d’e-mail)

---

## 0) Préparer un MTA local (le plus simple possible)

**Commandes**

```bash
sudo apt-get update
sudo apt-get install -y postfix mailutils
```

- À l’assistant Postfix, choisissez **Local only** (local seulement).

- Laissez le hostname proposé.

**Vérification rapide**

```bash
systemctl status postfix --no-pager
echo "hello" | mail -s "test-local" "$USER"
mail   # (q pour quitter)
```

> Ainsi `MAILTO` pourra envoyer des mails **locaux** (boîte `/var/mail/<user>`).

---

## 1) S’assurer que cron tourne

```bash
sudo systemctl enable --now cron
```

> Cron est un démon qui se réveille **chaque minute** et exécute les jobs selon les crontabs.

---

## 2) Arborescence de travail (dossier appli)

```bash
sudo mkdir -p /opt/app/out
sudo chown -R "$USER":"$USER" /opt/app
```

---

## 3) Dépendance A — utilitaire `slugify` (sert à démontrer PATH)

### But & exemple

- Transforme une chaîne “humaine” en nom de fichier propre (minuscules, tirets, ASCII).

- Exemple :  
  Entrée → `Rapport 2025-09-23 Hébergement & Réseau`  
  Sortie → `rapport-2025-09-23-hebergement-reseau`

### Créer le fichier

```bash
sudo nano /usr/local/bin/slugify
```

### Contenu de `/usr/local/bin/slugify`

```bash
#!/usr/bin/env bash
# Transforme une chaîne en "slug": minuscules, tirets, ASCII simple
set -euo pipefail
if [[ $# -lt 1 ]]; then
  echo "usage: slugify <texte>" >&2
  exit 2
fi
s="$*"
# accents -> ASCII, espaces/punct -> '-', trim des '-'
s="$(echo "$s" | iconv -f UTF-8 -t ASCII//TRANSLIT 2>/dev/null || echo "$s")"
s="$(echo "$s" | tr '[:upper:]' '[:lower:]' | sed -E 's/[^a-z0-9]+/-/g; s/^-+|-+$//g')"
echo "$s"
```

### Rendre exécutable + test rapide

```bash
sudo chmod +x /usr/local/bin/slugify
/usr/local/bin/slugify "Rapport test Hébergement & Réseau"
# -> rapport-test-hebergement-reseau
```

> Beaucoup d’environnements cron n’incluent pas `/usr/local/bin` dans `PATH` par défaut : on le démontrera puis on corrigera via la crontab.

---

## 4) Dépendance B — script `daily-report.sh` (robuste pour cron)

### Créer le fichier

```bash
nano /opt/app/daily-report.sh
```

### Contenu de `/opt/app/daily-report.sh`

```bash
#!/usr/bin/env bash
# Script "bash-only" robuste pour cron
set -euo pipefail

# --- debug (redirige stdout+stderr vers un log dédié) ---
exec >>/opt/app/out/debug.log 2>&1
echo "==== NEW RUN $(date) ===="
env

# --- environnement cron: USER peut manquer -> fallback LOGNAME/whoami ---
EUSER="${USER:-${LOGNAME:-$(whoami)}}"

# --- dossiers ---
mkdir -p ./out

# --- traçage pédagogique des variables cron ---
echo "[$(date +'%F %T')] SHELL=${SHELL:-?} EUSER=$EUSER HOME=${HOME:-?} PATH=${PATH:-?}" >> ./out/env.log

# --- génération d'un nom de fichier propre ---
title="Rapport $(date +'%F') $(hostname)"
slug="$(slugify "$title")"   # nécessite PATH incluant /usr/local/bin

# --- contenu du rapport ---
report="./out/${slug}.txt"
{
  echo "=== Rapport système ==="
  echo "Date: $(date -Is)"
  echo "Hôte: $(hostname)"
  echo "Utilisateur effectif: $EUSER"
  echo "Uptime: $(uptime -p)"
  echo "Disque racine: $(df -h / | awk 'NR==2{print $5\" used of \"$2}')"
} > "$report"

# --- message d'info (ira par mail si MAILTO non vide) ---
echo "INFO: Rapport écrit -> $report" >&2
```

### Droits

```bash
chmod +x /opt/app/daily-report.sh
```

---

## 5) Crontab (variables **en tête** + job par minute)

### Ouvrir la crontab utilisateur

```bash
crontab -e
```

### Coller EXACTEMENT ceci

```
MAILTO="bechir"   # ou "" si vous ne voulez aucun mail
SHELL=/bin/bash
PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
HOME=/opt/app

* * * * * /opt/app/daily-report.sh
```

- `SHELL` : force bash si le script utilise des features bash.

- `PATH` : inclut `/usr/local/bin` pour trouver `slugify`.

- `HOME` : garantit que `./out/...` pointe vers `/opt/app/out`.

- `MAILTO` : destinataire local de la sortie/erreur (ou “vide” pour désactiver).

---

## 6) Validation (≤ 60 s)

**Fichiers générés**

```bash
ls -l /opt/app/out/
tail -n 5 /opt/app/out/env.log
tail -n 20 /opt/app/out/debug.log
```

**Mails (si MAILTO non vide)**

```bash
mail
```

Vous devez voir :

- `env.log` avec `SHELL=/bin/bash`, `HOME=/opt/app`, `PATH=…`, `EUSER=bechir`.

- Un fichier rapport `rapport-<date>-<hostname>.txt`.

- Des mails “Cron … /opt/app/daily-report.sh” contenant le message `INFO: Rapport écrit -> …` (ou rien si `MAILTO=""`).

---

## 7) Variante “sans mails” (tout en fichiers)

Si vous préférez 0 e-mail :

```bash
crontab -e
```

Remplacez `MAILTO` par vide et logguez stdout/stderr vous-même :

```
MAILTO=""
SHELL=/bin/bash
PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
HOME=/opt/app

* * * * * /opt/app/daily-report.sh >>/opt/app/out/run.log 2>&1
```

> Le doc précise qu’un `MAILTO` vide désactive l’envoi d’e-mails ; sinon la sortie du job part au propriétaire ou à l’adresse indiquée.

---

## 8) Tests “comme cron” (diagnostic express)

Pour reproduire l’environnement minimal de cron à la main :

```bash
env -i HOME=/opt/app PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin SHELL=/bin/bash /opt/app/daily-report.sh
```

Puis :

```bash
ls -l /opt/app/out/
tail -n 20 /opt/app/out/debug.log
```

---

## 9) Nettoyage (optionnel)

```bash
crontab -r
rm -f /opt/app/out/* /opt/app/daily-report.sh
sudo rm -f /usr/local/bin/slugify
sudo rmdir /opt/app/out 2>/dev/null || true
sudo rmdir /opt/app 2>/dev/null || true
# (éventuel)
# sudo apt-get purge -y postfix mailutils
```

---

## Ce que vous avez prouvé (raccroché au doc)

- **Cron** exécute à la minute selon les crontabs utilisateurs/système.

- **SHELL** impacte la compatibilité (bash vs sh).

- **PATH** doit inclure vos binaires (ex. `/usr/local/bin`) si vous les utilisez dans les jobs.

- **HOME** fixe le répertoire courant pour les chemins relatifs.

- **MAILTO** contrôle l’acheminement de la sortie/erreur (adresse, liste, ou “vide” pour rien).
  
  ---

# Démo 7 — Restreindre qui a le droit de planifier avec `crontab`

## Objectif réaliste

Dans une VM Debian/Ubuntu multi-utilisateurs, on veut qu’**uniquement** le compte de service `report` puisse créer/éditer sa crontab, tandis que les développeurs (`dev1`, `dev2`) n’y aient pas accès. On validera le comportement immédiatement en lançant `crontab -e` sous chaque compte.

> Rappel de la règle officielle (résumé) :
> 
> - Si **`/etc/cron.allow` existe**, **seuls** les utilisateurs **listés dedans** ont le droit d’utiliser `crontab`.
> 
> - Sinon, si **`/etc/cron.deny` existe**, les utilisateurs **listés dedans** sont **interdits**; un `cron.deny` **vide** signifie “tout le monde autorisé”.
> 
> - Si **aucun** des deux n’existe, c’est **spécifique à la distribution**.
> 
> - Les deux fichiers contiennent des **noms d’utilisateurs, un par ligne**.

---

## Pré-requis (packages & service)

```bash
# Debian/Ubuntu : s'assurer que cron est installé et actif
sudo apt-get update
sudo apt-get install -y cron
sudo systemctl enable --now cron
```

---

## Étape 1 — Créer les comptes (dépendances humaines)

```bash
# Comptes développeurs
sudo adduser --disabled-password --gecos "" dev1
sudo adduser --disabled-password --gecos "" dev2

# Compte de service autorisé à planifier
sudo adduser --system --shell /bin/bash --home /home/report report
# (Optionnel) lui donner un mot de passe si vous voulez vous connecter en session
sudo passwd report
```

---

## Étape 2 — État initial (tout le monde peut tester `crontab -e` ?)

Testez rapidement (les 3 comptes) **avant** toute restriction :

```bash
# En tant que dev1
sudo -u dev1 -H bash -lc 'crontab -l || true; echo "---"; crontab -e <<<":q" 2>&1 | tail -n1'
# En tant que dev2
sudo -u dev2 -H bash -lc 'crontab -l || true; echo "---"; crontab -e <<<":q" 2>&1 | tail -n1'
# En tant que report
sudo -u report -H bash -lc 'crontab -l || true; echo "---"; crontab -e <<<":q" 2>&1 | tail -n1'
```

> But : constater que, par défaut, ils **peuvent** ouvrir `crontab -e` (selon la politique actuelle de votre distro).

---

## Étape 3 — Politique stricte avec `cron.allow` (liste blanche)

**Scénario sécurité “production”** : on impose une **liste blanche**. Seul `report` pourra planifier.

```bash
# 3.1 Créer/éditer /etc/cron.allow
sudo nano /etc/cron.allow
```

**Contenu de `/etc/cron.allow` :**

```
report
```

> Explication : dès que `cron.allow` existe, **seuls** les utilisateurs listés (ici `report`) ont droit à `crontab`. Les autres seront **refusés immédiatement**.

**Validation immédiate (zéro attente) :**

```bash
# dev1 : doit être refusé
sudo -u dev1 -H bash -lc 'crontab -e 2>&1 | tail -n1'

# dev2 : doit être refusé
sudo -u dev2 -H bash -lc 'crontab -e 2>&1 | tail -n1'

# report : doit être accepté
sudo -u report -H bash -lc 'crontab -e <<<":q"; echo "OK pour report"'
```

Vous verrez typiquement pour `dev1/dev2` un message du style “you are not allowed to use this program”.

---

## Étape 4 — Passage en “liste noire” avec `cron.deny` (exercice astucieux)

**Cas réel** : vous lancez un **hackathon** interne où *tous les devs* sont autorisés à utiliser `crontab` sauf un compte “bruyant” `dev2` qui surcharge la machine.

1. **Basculer la stratégie :** on retire la liste blanche et on met une **liste noire**.

```bash
# 4.1 Désactiver la whitelist
sudo rm -f /etc/cron.allow

# 4.2 Créer/éditer /etc/cron.deny
sudo nano /etc/cron.deny
```

**Contenu de `/etc/cron.deny` :**

```
dev2
```

> Résultat attendu : **tous** les utilisateurs **sauf** `dev2` peuvent utiliser `crontab`. Un fichier `cron.deny` **vide** autoriserait **tout le monde**.

**Validation immédiate :**

```bash
# dev1 : doit être autorisé
sudo -u dev1 -H bash -lc 'crontab -e <<<":q"; echo "OK pour dev1"'

# dev2 : doit être refusé
sudo -u dev2 -H bash -lc 'crontab -e 2>&1 | tail -n1'

# report : doit être autorisé
sudo -u report -H bash -lc 'crontab -e <<<":q"; echo "OK pour report"'
```

---

## Étape 5 — Test d’audit rapide (preuve de blocage/autorisation)

On va demander à chacun **d’essayer de poser un job**. On ne va pas attendre 1–2 minutes : l’objectif est juste de vérifier **droit d’accès** à `crontab`, pas d’exécuter un cron.

**Commande simple à saisir (si autorisé) :**

```
* * * * * date >>/tmp/cron_access_probe.log 2>&1
```

> Saisissez-la via `crontab -e` **uniquement** avec les comptes autorisés (ici `dev1`, `report` en mode deny; `report` seul en mode allow).  
> Le fichier `/tmp/cron_access_probe.log` se remplira ensuite, mais la **validation des droits** est **instantanée** : soit l’édition est possible, soit elle est refusée immédiatement.

---

## Étape 6 — Edge cases & bonnes pratiques

- **Root bypass** : `root` n’est pas concerné par `cron.allow/deny` pour utiliser `crontab` (il gère aussi `/etc/crontab` et `/etc/cron.d/*`). C’est le comportement attendu d’administration. (Rappel sur crontab système /etc/crontab & /etc/cron.d)

- **Format** : un **nom d’utilisateur par ligne** dans `cron.allow`/`cron.deny`. Pas d’espaces ni de commentaires exotiques.

- **Priorité** : si `cron.allow` existe, il **prime** sur `cron.deny`. Sinon, `cron.deny` s’applique.

- **Journalisation** : en cas de doute, vérifiez le journal du service :
  
  ```bash
  sudo journalctl -u cron -n 50 --no-pager
  ```

---

## Nettoyage (optionnel)

```bash
sudo rm -f /etc/cron.allow /etc/cron.deny
sudo deluser --remove-home dev1
sudo deluser --remove-home dev2
sudo deluser --remove-home report 2>/dev/null || true
sudo rm -f /tmp/cron_access_probe.log
```

---

## Résultats attendus (checklist rapide)

- ✅ En mode **liste blanche** (avec `/etc/cron.allow`), **seul `report`** peut ouvrir/éditer sa crontab.

- ✅ En mode **liste noire** (avec `/etc/cron.deny`), **tout le monde sauf `dev2`** peut utiliser `crontab`.

- ✅ La **validation est instantanée** (aucune attente), car on **teste les droits d’édition** de crontab, pas l’exécution d’un job.

# Démo 8 — Exploiter `/etc/cron.daily` et `/etc/cron.weekly` (live, sans attente)

## Objectif

Mettre en place un mini-cycle d’exploitation réel pour une appli :

1. **tâche quotidienne** qui **archive et compresse** le log de l’appli,

2. **tâche hebdomadaire** qui **purg e les archives** de plus de 4 semaines.  
   Puis déclencher ces tâches **immédiatement** (sans attendre) via `run-parts` pour la démonstration.  
   Les répertoires `/etc/cron.daily` et `/etc/cron.weekly` sont prévus pour ça, selon la distro.

---

## Pré-requis (Debian/Ubuntu)

- Être sudoer

- Service cron actif :

```bash
sudo systemctl status cron --no-pager || sudo systemctl enable --now cron
```

---

## Mise en place des données de test (réaliste)

On simule une appli qui écrit dans un log dédié.

```bash
# 1) Créer l’arborescence de logs et d’archives
sudo mkdir -p /var/log/myapp/archive

# 2) Générer un log courant de l’appli
echo "startup ok $(date)" | sudo tee -a /var/log/myapp/app.log
echo "processing item #1 $(date)" | sudo tee -a /var/log/myapp/app.log
```

---

## Partie A — Tâche **quotidienne** (archive + compression)

### 1) Créer le script dans `/etc/cron.daily/backup_myapp_log`

> Utilisez votre éditeur (ex. `sudo nano /etc/cron.daily/backup_myapp_log`) puis collez **exactement** le contenu ci-dessous.

#### Contenu du script (à coller) :

```bash
#!/usr/bin/env bash
set -euo pipefail

LOG_DIR="/var/log/myapp"
ARCHIVE_DIR="$LOG_DIR/archive"
LOG_FILE="$LOG_DIR/app.log"

# 1) Rien à faire si le log courant n'existe pas
[ -f "$LOG_FILE" ] || exit 0

# 2) Nom horodaté (YYYYMMDD-HHMMSS) pour un archivage traçable
STAMP="$(date +'%Y%m%d-%H%M%S')"
ARCHIVE_FILE="$ARCHIVE_DIR/app-$STAMP.log"

# 3) Déplacer le log courant vers l'archive, puis compresser
install -d -m 0755 "$ARCHIVE_DIR"
mv "$LOG_FILE" "$ARCHIVE_FILE"
gzip -9 "$ARCHIVE_FILE"

# 4) Recréer un log courant vide avec permissions safe
install -m 0640 -o root -g adm /dev/null "$LOG_FILE"

# 5) Journaliser dans syslog pour audit (visible via journalctl / syslog)
logger -t myapp.cron.daily "Archived $ARCHIVE_FILE.gz and rotated $LOG_FILE"
```

### 2) Rendre exécutable

```bash
sudo chmod 0755 /etc/cron.daily/backup_myapp_log
```

### 3) **Déclencher tout de suite** (live)

Certaines distros lancent `cron.daily` via `run-parts`. On va l’appeler **manuellement** :

```bash
# Voir ce qui serait exécuté
run-parts --test /etc/cron.daily

# Lancer réellement (verbose pour voir l'exécution)
sudo run-parts --verbose /etc/cron.daily
```

### 4) Vérifications

```bash
# a) Archives créées
ls -lh /var/log/myapp/archive/

# b) Log courant recréé et vidé
ls -l /var/log/myapp/app.log
sudo tail -n 5 /var/log/syslog | grep -i myapp.cron.daily || true
# (ou) sudo journalctl -e | grep -i myapp.cron.daily
```

> Ce flux illustre l’usage attendu de `/etc/cron.daily` : y déposer des scripts exécutés à la fréquence « quotidienne » par la mécanique cron/`run-parts` de la distro.

---

## Partie B — Tâche **hebdomadaire** (purge d’archives > 4 semaines)

### 1) Préparer de « fausses » archives anciennes (pour prouver la purge)

```bash
# Créer 2 archives "anciennes" (45 et 33 jours)
sudo touch -d '45 days ago' /var/log/myapp/archive/app-OLD1.log.gz
sudo touch -d '33 days ago' /var/log/myapp/archive/app-OLD2.log.gz

# Créer 1 archive "récente" (5 jours)
sudo touch -d '5 days ago' /var/log/myapp/archive/app-RECENT.log.gz

# Vérifier les dates vues par ls (colonne date/heure)
ls -l /var/log/myapp/archive/
```

### 2) Créer le script `/etc/cron.weekly/prune_myapp_archives`

> Éditez avec `sudo nano /etc/cron.weekly/prune_myapp_archives`, puis collez le contenu.

#### Contenu du script (à coller) :

```bash
#!/usr/bin/env bash
set -euo pipefail

ARCHIVE_DIR="/var/log/myapp/archive"
RETENTION_DAYS=28

# 1) Ne rien faire si le dossier n'existe pas
[ -d "$ARCHIVE_DIR" ] || exit 0

# 2) Supprimer les archives plus vieilles que 28 jours
#    -print pour loguer ce qui est supprimé (visible via syslog/journal)
DELETED="$(find "$ARCHIVE_DIR" -type f -name 'app-*.log.gz' -mtime +$RETENTION_DAYS -print -delete | wc -l || true)"

logger -t myapp.cron.weekly "Pruned $DELETED archive(s) older than $RETENTION_DAYS days from $ARCHIVE_DIR"
```

### 3) Rendre exécutable

```bash
sudo chmod 0755 /etc/cron.weekly/prune_myapp_archives
```

### 4) **Déclencher tout de suite** (live)

```bash
# Voir les scripts "éligibles"
run-parts --test /etc/cron.weekly

# Exécuter maintenant
sudo run-parts --verbose /etc/cron.weekly
```

### 5) Vérifications

```bash
# Les archives > 28 jours ont disparu, la récente est conservée
ls -l /var/log/myapp/archive/

# Traces dans les journaux
sudo tail -n 5 /var/log/syslog | grep -i myapp.cron.weekly || true
# (ou) sudo journalctl -e | grep -i myapp.cron.weekly
```

### Netoyage

```bash
# 1) Vérifier ce qui a été créé (optionnel)
ls -l /etc/cron.daily/backup_myapp_log /etc/cron.weekly/prune_myapp_archives || true
ls -l /var/log/myapp /var/log/myapp/archive || true

# 2) Supprimer les scripts cron
sudo rm -f /etc/cron.daily/backup_myapp_log
sudo rm -f /etc/cron.weekly/prune_myapp_archives

# 3) Supprimer les logs et archives de l’appli
sudo rm -rf /var/log/myapp

# 4) Contrôle final (optionnel)
run-parts --test /etc/cron.daily | grep -i myapp || true
run-parts --test /etc/cron.weekly | grep -i myapp || true
```

## Points pédagogiques clés

- Les **répertoires cron système** (`/etc/cron.daily`, `/etc/cron.weekly`, etc.) contiennent des scripts exécutés à la fréquence correspondante (selon la distro), **sans éditer la crontab utilisateur**.

- En **démo live**, on **déclenche immédiatement** via `run-parts` pour vérifier le comportement **sans attendre**.

- **Bonnes pratiques** : noms de scripts **compatibles run-parts** (pas de point dans le nom), chemins **absolus**, `set -euo pipefail`, `logger` pour audit, permissions 0755 côté `/etc/cron.*` et 0640 côté log.

- Séparation des responsabilités : **daily → rotation/archivage**, **weekly → purge** (rétention). C’est un pattern réaliste en prod.

# Démo 8 — Planifier une action unique avec `at` (archivage + checksum immédiat)

## Objectif (cas réel)

Simuler une tâche ponctuelle « post-opération » : **archiver un répertoire de travail et produire un checksum puis journaliser**, déclenché **une seule fois** dans ~1 minute via `at`. On verra aussi **lister** (`atq`), **annuler** (`atrm`), et **contrôler l’accès** via `/etc/at.allow` et `/etc/at.deny`.  
Références : syntaxe de `at`, commandes `atq`/`atrm`, et contrôle d’accès par fichiers allow/deny sont explicités dans le document fourni.

---

## Pré-requis

```bash
# Installer l’outil et s’assurer que le démon "atd" est actif
sudo apt update && sudo apt install -y at
sudo systemctl enable --now atd
sudo systemctl status atd --no-pager
```

> `at` exécute les commandes avec **/bin/sh** (message d’avertissement visible à l’invite), et s’emploie pour une **tâche unique à un instant donné**.

---

## Étape A — Préparer l’atelier (répertoire & fichiers)

```bash
# 1) Dossier de travail
mkdir -p /tmp/at_demo/work

# 2) Générer quelques fichiers “résidus” à archiver
printf 'alpha\nbeta\ngamma\n'  > /tmp/at_demo/work/data1.txt
printf 'log line 1\nlog line 2\n' > /tmp/at_demo/work/app.log
```

---

## Étape B — Créer le script d’archivage à exécuter par `at`

**Chemin du fichier** : `/usr/local/bin/archive_and_verify.sh` (chemin **absolu** recommandé pour éviter les soucis d’environnement).  
Créez le fichier avec votre éditeur (nano/vim), puis collez **exactement** le contenu ci-dessous ; enregistrez, fermez, puis rendez-le exécutable.

```bash
sudo nano /usr/local/bin/archive_and_verify.sh
sudo chmod +x /usr/local/bin/archive_and_verify.sh
```

**Contenu de `/usr/local/bin/archive_and_verify.sh`** :

```bash
#!/usr/bin/env bash
set -euo pipefail

WORKDIR="/tmp/at_demo/work"
OUTDIR="/tmp/at_demo/out"
LOGFILE="/tmp/at_demo/at_demo.log"

mkdir -p "$OUTDIR"
ts="$(date +'%F_%H-%M-%S')"
archive="$OUTDIR/work_${ts}.tar.gz"
checksum="$archive.sha256"

{
  echo "[$(date +'%F %T')] START: archiving $WORKDIR"
  tar -C "$WORKDIR" -czf "$archive" .
  sha256sum "$archive" > "$checksum"
  echo "[$(date +'%F %T')] DONE: archive=$archive"
  echo "[$(date +'%F %T')] SHA256: $(cut -d' ' -f1 "$checksum")"
} >>"$LOGFILE" 2>&1
```

**Pourquoi ce design ?**

- **Cas réel** : on capture un état de travail puis on **trace** l’opération (journal + intégrité).

- **Robuste** : `set -euo pipefail`, chemins absolus, et sortie vers un log dédié.

- **Instantané** : exécution courte (quelques ms) → visible dès que `at` déclenche (≈ 1 minute).

---

## Étape C — Planifier l’exécution unique (≈ 1 minute)

Option 1 (invite interactive) :

```bash
at now + 1 minute
# À l'invite "at>", tapez:
# /usr/local/bin/archive_and_verify.sh
# (puis Ctrl+D pour valider)
```

Option 2 (non-interactive, recommandé) :

```bash
at -f /usr/local/bin/archive_and_verify.sh now + 1 minute
```

**Lister les jobs en file d’attente** :

```bash
atq
# Affiche un identifiant (job id), l’heure prévue, et l’utilisateur
```

**Vérifier l’environnement** : le message « warning: commands will be executed using /bin/sh » rappelle le shell utilisé par `at`.

---

## Étape D — Observer l’exécution (≤ 60 s)

Dans un terminal :

```bash
tail -f /tmp/at_demo/at_demo.log
```

Attendez la minute suivante : vous verrez des entrées `START`, `DONE`, et la **SHA256**.  
Vérifiez les artefacts :

```bash
ls -lh /tmp/at_demo/out/
```

---

## Étape E — Annuler proprement une tâche avant son exécution

Planifions une **seconde** exécution puis **annulons-la** :

```bash
# 1) Replanifier pour dans 1 minute
at -f /usr/local/bin/archive_and_verify.sh now + 1 minute

# 2) Récupérer l’ID
atq
# Supposons que l'ID affiché soit 12

# 3) Annuler
atrm 12

# 4) Vérifier qu'il n'y a plus de job
atq
```

> `atq` liste la file, `atrm <id>` supprime un job : ces commandes font partie du triptyque `at`/`atq`/`atrm` décrit dans le document.

---

## Étape F — Contrôler l’accès avec `/etc/at.allow` et `/etc/at.deny`

Le document précise le mécanisme d’autorisation :

- Si **`/etc/at.allow` existe**, seuls les utilisateurs listés **sont autorisés** à utiliser `at`.

- Sinon, si **`/etc/at.deny` existe**, les utilisateurs listés **sont interdits** (un `at.deny` vide → tous autorisés).

- Si **aucun des deux** n’existe, le comportement dépend de la distribution.

### Exemple 1 — Restreindre à un seul utilisateur (whitelist)

```bash
# Créer un allow "strict" (remplacez $USER par l'utilisateur cible)
echo "$USER" | sudo tee /etc/at.allow
# S'assurer qu'il n'existe pas de deny contradictoire
sudo rm -f /etc/at.deny
```

**Test** : l’utilisateur présent dans `at.allow` peut planifier ; un autre non listé reçoit un refus.

### Exemple 2 — Interdire un utilisateur (blacklist)

```bash
# Variante : autoriser tout le monde sauf "guest"
echo "guest" | sudo tee /etc/at.deny
sudo rm -f /etc/at.allow
```

**Test** : `guest` ne peut pas utiliser `at`, les autres oui.

> Format attendu : **un nom d’utilisateur par ligne** dans `at.allow`/`at.deny`.

---

## Nettoyage

```bash
# Supprimer la file (si nécessaire, annulez chaque job restant)
atq | awk '{print $1}' | xargs -r atrm

# Retirer les fichiers/dossiers de démo
sudo rm -f /usr/local/bin/archive_and_verify.sh
rm -rf /tmp/at_demo

# (optionnel) Restaurer la config d'accès
# sudo rm -f /etc/at.allow /etc/at.deny
```

---

## Pièges & bonnes pratiques (résumé)

- **Chemins absolus & PATH** : `at` n’hérite pas toujours de votre environnement interactif → **toujours** pointer vers des chemins absolus dans les commandes/scripts.

- **Redirections** : redirigez stdout/stderr **dans le script** (journal dédié) pour éviter des e-mails ou des sorties silencieuses.

- **Sécurité d’accès** : exploitez `at.allow` / `at.deny` pour cadrer qui peut planifier.

- **Usage pertinent** : réservez `at` aux **tâches ponctuelles** (correctifs, archivage, bascule technique…), quand **cron** convient au périodique et les **timers systemd** offrent une alternative intégrée à systemd.
