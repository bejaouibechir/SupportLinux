# Atelier : Mise en place d’un Load-Balancer simple avec IPVS

---

## 1. Contexte & objectif

Dans cet atelier, nous allons transformer **machine1** en **load-balancer IPVS** qui répartit les connexions TCP (par ex. HTTP) entre deux serveurs applicatifs.

- **machine1** : load-balancer IPVS

- **machine2** : backend web 1 (Apache/Nginx simple)

- **machine1 (namespace supplémentaire)** ou **machine2 (conteneur léger)** : backend web 2

L’objectif est de montrer :

- comment IPVS permet de faire du load-balancing L4 (niveau transport)

- comment vérifier la répartition du trafic

- différence avec une simple redirection statique

---

## 2. Préparation du terrain

### 2.1. Paquets nécessaires

Sur **machine1 (load-balancer)** :

```bash
sudo apt update
sudo apt install -y ipvsadm iproute2 curl
```

Sur **machine2 (backend 1)** :

```bash
sudo apt update
sudo apt install -y apache2
echo "Réponse du serveur BACKEND-1" | sudo tee /var/www/html/index.html
sudo systemctl restart apache2
```

Sur **machine1 (pour backend 2 en namespace)** :

```bash
sudo apt install -y apache2
```

*(nous allons lancer un deuxième Apache dans un namespace réseau pour simuler un second serveur)*

---

### 2.2. Schéma réseau simplifié

- `machine1 enp0s8 = 10.10.10.1` → Load Balancer IPVS

- `machine2 enp0s8 = 10.10.10.2` → Backend 1 (Apache classique)

- `machine1 namespace ns-backend2 = 10.10.10.3` → Backend 2 (Apache dans un namespace)

---

## 3. Déroulement de l’exercice

### Étape 1 : Créer un namespace pour le deuxième backend

Sur **machine1** :

```bash
sudo ip netns add ns-backend2
sudo ip link add veth0 type veth peer name veth1
sudo ip link set veth0 netns ns-backend2
sudo ip addr add 10.10.10.3/24 dev veth1
sudo ip link set veth1 up
sudo ip netns exec ns-backend2 ip addr add 10.10.10.3/24 dev veth0
sudo ip netns exec ns-backend2 ip link set veth0 up
sudo ip netns exec ns-backend2 ip link set lo up
```

Vérification :

```bash
ping -c 2 10.10.10.3
```

### Étape 2 : Lancer Apache dans le namespace (backend 2)

```bash
sudo ip netns exec ns-backend2 bash -c "echo 'Réponse du serveur BACKEND-2' > /var/www/html/index.html"
sudo ip netns exec ns-backend2 systemctl start apache2
```

Vérification :

```bash
curl http://10.10.10.3
```

---

### Étape 3 : Configurer IPVS sur machine1

Définir une IP virtuelle pour le load balancer (VIP) :

```bash
sudo ip addr add 10.10.10.100/24 dev enp0s8
```

Configurer IPVS :

```bash
sudo ipvsadm -A -t 10.10.10.100:80 -s rr
sudo ipvsadm -a -t 10.10.10.100:80 -r 10.10.10.2:80 -m
sudo ipvsadm -a -t 10.10.10.100:80 -r 10.10.10.3:80 -m
```

Explications :

- `-A` ajoute un service virtuel (VIP:PORT)

- `-s rr` = round-robin

- `-r` ajoute un backend réel (realserver)

- `-m` active le mode NAT (masquerade)

---

### Étape 4 : Tester le load-balancing

Depuis machine1 ou machine2 :

```bash
for i in {1..6}; do curl -s http://10.10.10.100 | grep Réponse; done
```

Résultat attendu (alternance) :

```
Réponse du serveur BACKEND-1
Réponse du serveur BACKEND-2
Réponse du serveur BACKEND-1
Réponse du serveur BACKEND-2
...
```

Visualiser la table IPVS :

```bash
sudo ipvsadm -Ln
```

---

## 4. Nettoyage

À la fin de l’exercice, remettre le système propre :

### Supprimer configuration IPVS :

```bash
sudo ipvsadm -C
```

### Retirer l’IP virtuelle :

```bash
sudo ip addr del 10.10.10.100/24 dev enp0s8
```

### Supprimer le namespace backend2 :

```bash
sudo ip netns delete ns-backend2
```

### (Optionnel) Supprimer Apache si installé juste pour l’exercice :

```bash
sudo apt remove --purge -y apache2
sudo apt autoremove -y
```

---

# Atelier unique — HAProxy + 3 serveurs Apache + Centralisation des logs + Statistiques + Tests réseau

**Mode : recette pédagogique complète (une seule version)**

## 1) Contexte & objectif

Mettre en place un **load balancer HAProxy** devant **3 serveurs Apache** (web1/web2/web3) avec :

- **Page de statistiques HAProxy** visible.
- **Tests d’algorithmes** d’équilibrage (`roundrobin`, `leastconn`, `source`).
- **Centralisation des logs** (HAProxy + Apache) vers un serveur `log1` via **rsyslog**.
- **Simulation de panne réseau** avec `iptables` et observation de l’effet.
- **Page d’erreur personnalisée** (503) côté HAProxy.
- (Optionnel) **Node Exporter** sur toutes les machines (et **Netdata** si besoin d’interface visuelle).

> Valeur pédagogique : observer la répartition, la détection de pannes, la visibilité opérationnelle (stats/logs), et comparer des stratégies de load balancing sans complexifier l’infra.

---

## 2) Préparation de l’environnement

### 2.1 Topologie & adresses

| Rôle                   | Hôte   | IP (exemple)  | Logiciels                              |
| ---------------------- | ------ | ------------- | -------------------------------------- |
| Load Balancer          | `lb1`  | `10.10.10.10` | haproxy, rsyslog-client                |
| Web 1                  | `web1` | `10.10.10.11` | apache2, rsyslog-client                |
| Web 2                  | `web2` | `10.10.10.12` | apache2, rsyslog-client                |
| Web 3                  | `web3` | `10.10.10.13` | apache2, rsyslog-client                |
| Logs centralisés       | `log1` | `10.10.10.20` | rsyslog-server                         |
| (Option) Observabilité | `*`    | `toutes`      | node-exporter (+ netdata si besoin UI) |

> Toutes les machines sont Debian/Ubuntu avec accès `sudo`.

### 2.2 Paquets requis

- Sur **lb1**, **web1–3** :
  
  ```bash
  sudo apt update
  sudo apt install -y haproxy apache2 rsyslog curl apache2-utils
  ```
- Sur **log1** :
  
  ```bash
  sudo apt update
  sudo apt install -y rsyslog
  ```
- (Option) **Node Exporter** (toutes) :
  
  ```bash
  cd /tmp
  curl -LO https://github.com/prometheus/node_exporter/releases/download/v1.8.1/node_exporter-1.8.1.linux-amd64.tar.gz
  tar xzf node_exporter-1.8.1.linux-amd64.tar.gz
  sudo mv node_exporter-1.8.1.linux-amd64/node_exporter /usr/local/bin/
  sudo useradd --no-create-home --system --shell /usr/sbin/nologin nodeexp || true
  sudo bash -c 'cat >/etc/systemd/system/node_exporter.service' <<'EOF'
  [Unit]
  Description=Node Exporter
  After=network.target
  [Service]
  User=nodeexp
  ExecStart=/usr/local/bin/node_exporter
  [Install]
  WantedBy=multi-user.target
  EOF
  sudo systemctl daemon-reload
  sudo systemctl enable --now node_exporter
  ```
- (Option UI humaine) **Netdata** (toutes ou sur lb1) :
  
  ```bash
  bash <(curl -Ss https://my-netdata.io/kickstart.sh) --disable-telemetry
  ```

---

## 3) Exécution pas à pas

### 3.1 Publier 3 pages distinctes sur web1–web3

- **Sur web1** :
  
  ```bash
  echo '<h1>Bienvenue sur WEB1 (Apache)</h1>' | sudo tee /var/www/html/index.html
  sudo systemctl enable --now apache2
  ```
- **Sur web2** :
  
  ```bash
  echo '<h1>Bienvenue sur WEB2 (Apache)</h1>' | sudo tee /var/www/html/index.html
  sudo systemctl enable --now apache2
  ```
- **Sur web3** :
  
  ```bash
  echo '<h1>Bienvenue sur WEB3 (Apache)</h1>' | sudo tee /var/www/html/index.html
  sudo systemctl enable --now apache2
  ```
  
  **Vérification locale** (depuis lb1 ou votre poste) :
  
  ```bash
  curl http://10.10.10.11; echo
  curl http://10.10.10.12; echo
  curl http://10.10.10.13; echo
  ```

### 3.2 Configurer HAProxy (lb1)

1) **Créer le fichier** `/etc/haproxy/haproxy.cfg` :
   
   ```bash
   # ================= /etc/haproxy/haproxy.cfg =================
   global
    log /dev/log local0
    maxconn 2048
    daemon
   ```

defaults
    mode http
    log global
    option httplog
    timeout connect 5s
    timeout client  50s
    timeout server  50s
    errorfile 503 /etc/haproxy/errors/503.http

# Frontend HTTP (port 80)

frontend http_front
    bind *:80
    default_backend web_backends

# Backend des applications

backend web_backends
    balance roundrobin                  # Algorithme par défaut : roundrobin
    option httpchk GET /                # Health check sur /
    http-check expect rstring Bienvenue # Attendre "Bienvenue" dans la réponse
    server web1 10.10.10.11:80 check
    server web2 10.10.10.12:80 check
    server web3 10.10.10.13:80 check

# Page de statistiques HAProxy

listen stats
    bind *:8404
    mode http
    stats enable
    stats uri /haproxy?stats
    stats refresh 2s
    stats auth admin:password

# ============================================================

```
2) **Créer la page d’erreur 503** `/etc/haproxy/errors/503.http` :
```bash
# ================ /etc/haproxy/errors/503.http ===============
HTTP/1.0 503 Service Unavailable
Cache-Control: no-cache
Connection: close
Content-Type: text/html

<html><body>
<h1>Service indisponible</h1>
<p>Nos serveurs sont temporairement indisponibles. Merci de réessayer.</p>
</body></html>
# ============================================================
```

3) **Activer & vérifier** :
   
   ```bash
   sudo haproxy -c -f /etc/haproxy/haproxy.cfg
   sudo systemctl enable --now haproxy
   sudo systemctl restart haproxy
   sudo systemctl status haproxy --no-pager
   ```

### 3.3 Centralisation des logs (rsyslog)

#### 3.3.1 Configurer le **serveur de logs** (log1)

1) **Activer l’écoute UDP 514** : créer `/etc/rsyslog.d/10-udp-server.conf` :
   
   ```bash
   # === /etc/rsyslog.d/10-udp-server.conf ===
   module(load="imudp")
   input(type="imudp" port="514")
   # === fin ===
   ```
2) **Ranger les logs entrants par hôte** : créer `/etc/rsyslog.d/20-remote-store.conf` :
   
   ```bash
   # === /etc/rsyslog.d/20-remote-store.conf ===
   template(name="RemotePerHost" type="string"
   string="/var/log/remote/%HOSTNAME%/%PROGRAMNAME%.log")
   *.* ?RemotePerHost
   & stop
   # === fin ===
   ```
3) **Redémarrer** :
   
   ```bash
   sudo systemctl restart rsyslog
   ```

#### 3.3.2 Configurer les **clients** (lb1, web1–3)

- **Au minimum, forwarder tout vers log1** — créer `/etc/rsyslog.d/50-forward-all.conf` :
  
  ```bash
  # === /etc/rsyslog.d/50-forward-all.conf ===
  *.* @10.10.10.20:514
  # === fin ===
  ```
- (Recommandé) **Capturer HAProxy localement** (lb1) — créer `/etc/rsyslog.d/49-haproxy.conf` :
  
  ```bash
  # === /etc/rsyslog.d/49-haproxy.conf ===
  if ($programname == "haproxy") then /var/log/haproxy.log
  & stop
  # === fin ===
  ```
- (Option) **Sur web1–3**, collecter `access.log` et `error.log` via imfile : créer `/etc/rsyslog.d/48-apache-imfile.conf` :
  
  ```bash
  # === /etc/rsyslog.d/48-apache-imfile.conf ===
  module(load="imfile")
  input(type="imfile" File="/var/log/apache2/access.log" Tag="apache_access" Severity="info" Facility="local6")
  input(type="imfile" File="/var/log/apache2/error.log"  Tag="apache_error"  Severity="warning" Facility="local6")
  # === fin ===
  ```
- **Redémarrer rsyslog sur lb1 et web1–3** :
  
  ```bash
  sudo systemctl restart rsyslog
  ```

### 3.4 Tests fonctionnels

#### 3.4.1 Répartition avec `curl`

Depuis **lb1** :

```bash
for i in {1..9}; do curl -s http://localhost/ | grep Bienvenue; done
```

**Attendu** : alternance entre WEB1/WEB2/WEB3 (round-robin).

#### 3.4.2 Répartition avec `ab` (ApacheBench)

Depuis **lb1** :

```bash
ab -n 60 -c 10 http://localhost/
```

**Observations** : temps moyens, taux d’erreur. Sur `http://lb1:8404/haproxy?stats` (admin/password), vérifier l’activité des 3 backends.

### 3.5 Changer d’algorithme (comparatif)

Dans `/etc/haproxy/haproxy.cfg`, remplacer **temporairement** :

- `balance roundrobin` → `balance leastconn` (puis `sudo systemctl reload haproxy`)
- Tester de nouveau `curl` et `ab`.
- Puis `balance source` et re-tester.
  **Attendu** : différences de répartition (notamment avec `source`).

### 3.6 Simuler une panne réseau (web2)

Sur **web2** :

```bash
sudo iptables -A INPUT -p tcp --dport 80 -j DROP
```

Tester depuis **lb1** :

```bash
for i in {1..9}; do curl -s http://localhost/ | grep Bienvenue; done
```

**Attendu** : web2 passe `DOWN` en stats, trafic vers WEB1/WEB3 uniquement.  
**Rétablir** :

```bash
sudo iptables -D INPUT -p tcp --dport 80 -j DROP
```

### 3.7 Tester la page d’erreur 503

**Arrêter Apache partout** (temporairement) :

```bash
ssh web1 'sudo systemctl stop apache2'
ssh web2 'sudo systemctl stop apache2'
ssh web3 'sudo systemctl stop apache2'
curl -i http://localhost/ | head
```

**Attendu** : code **503** avec la page personnalisée.  
**Relancer** :

```bash
ssh web1 'sudo systemctl start apache2'
ssh web2 'sudo systemctl start apache2'
ssh web3 'sudo systemctl start apache2'
```

### 3.8 Vérifier la centralisation des logs (log1)

Sur **log1** :

```bash
sudo bash -lc 'command -v tree >/dev/null && tree -L 2 /var/log/remote || ls -R /var/log/remote | head -n 50'
sudo grep -i haproxy /var/log/remote/*/haproxy.log | tail -n 10 || true
sudo grep -i "GET / " /var/log/remote/*/apache_access.log | tail -n 10 || true
```

---

## 4) Vérifications / Résultats attendus

- **Stats HAProxy** accessibles : `http://lb1:8404/haproxy?stats` (admin/password).
- **Round-robin** → alternance WEB1/WEB2/WEB3, **leastconn** → favorise le moins chargé, **source** → affinité par IP.
- **Panne réseau web2** → web2 `DOWN` côté stats, trafic redistribué.
- **503 personnalisée** servie si tous les backends sont `DOWN`.
- **Logs** : visibles sur `log1` triés par hôte et programme.

---

## 5) Nettoyage / Rollback

Sur **lb1** :

```bash
sudo systemctl stop haproxy rsyslog
sudo rm -f /etc/haproxy/haproxy.cfg /etc/haproxy/errors/503.http
sudo rm -f /etc/rsyslog.d/49-haproxy.conf /etc/rsyslog.d/50-forward-all.conf
sudo systemctl restart rsyslog
```

Sur **web1–web3** :

```bash
sudo systemctl stop apache2 rsyslog
sudo rm -f /var/www/html/index.html /etc/rsyslog.d/48-apache-imfile.conf /etc/rsyslog.d/50-forward-all.conf
sudo iptables -D INPUT -p tcp --dport 80 -j DROP 2>/dev/null || true
sudo systemctl restart rsyslog
```

Sur **log1** :

```bash
sudo systemctl stop rsyslog
sudo rm -f /etc/rsyslog.d/10-udp-server.conf /etc/rsyslog.d/20-remote-store.conf
sudo rm -rf /var/log/remote
sudo systemctl restart rsyslog
```

(Option observabilité) :

```bash
sudo systemctl disable --now node_exporter 2>/dev/null || true
sudo rm -f /etc/systemd/system/node_exporter.service /usr/local/bin/node_exporter
```

---

## 6) Astuces & pièges

- **HAProxy logs** : assurez-vous que rsyslog capte bien `haproxy` dans `/var/log/haproxy.log` localement (utile en débogage).
- **Health checks** : `http-check expect rstring` est pédagogique ; en prod, préférez un endpoint `/healthz` plus robuste.
- **iptables** : en cloud, des SG/NACL peuvent interférer ; préférez bloquer localement comme montré.
- **Node Exporter** n’a pas d’UI ; pour une interface humaine, **Netdata** est rapide à installer (port 19999).
- **Reload** : `sudo systemctl reload haproxy` suffit souvent après un simple changement d’algorithme.
- **Sécurité** : changez `stats auth` et limitez l’accès à la page stats (firewall, IP source).
