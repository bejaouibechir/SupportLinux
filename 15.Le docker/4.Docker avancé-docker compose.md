# Atelier 1 : image vs build dans Docker Compose

---

## 1. 🎯 Contexte & Objectif

Cet atelier a pour but de **comparer deux approches** dans un fichier `docker-compose.yml` :

- **Approche 1 : utilisation d’une image standard** (ex. `nginx:latest`)

- **Approche 2 : construction d’une image personnalisée** à partir d’un `Dockerfile`

L’objectif est de comprendre :

- Quand utiliser `image:` (image publique ou privée déjà prête)

- Quand utiliser `build:` (image à construire localement)

- Comment vérifier que le comportement diffère entre les deux

### Commandes principales

| Commande                 | Rôle                                         |
| ------------------------ | -------------------------------------------- |
| `docker compose up -d`   | Démarre tous les services en mode détaché    |
| `docker compose ps`      | Liste les conteneurs actifs                  |
| `docker compose logs -f` | Affiche les journaux des services            |
| `docker compose down`    | Stoppe et supprime tous les conteneurs créés |

Voici une arborescence claire des **sections principales et secondaires** d’un `docker-compose.yml`, **hors Swarm** (on exclut donc `deploy`, `secrets`, `configs`, etc.)

```bash
docker-compose
├─ name                         # (facultatif) Nom explicite du projet Compose
├─ services                     # (obligatoire) Définition des conteneurs
│  └─ <service_name>
│     ├─ image                  # Image à utiliser (ex: nginx:1.27)
│     ├─ build                  # Construction d’image
│     │  ├─ context             # Chemin du contexte (.)
│     │  ├─ dockerfile          # Dockerfile alternatif
│     │  ├─ target              # Stage multi-stage
│     │  ├─ args                # ARG de build (k:v ou liste)
│     │  ├─ ssh                 # Forward des clés SSH de build
│     │  ├─ cache_from          # Sources de cache
│     │  └─ network             # Réseau utilisé pour le build
│     ├─ container_name         # Nom explicite du conteneur (optionnel)
│     ├─ command                # Commande (override CMD)
│     ├─ entrypoint             # Entrypoint (override ENTRYPOINT)
│     ├─ working_dir            # répertoire de travail
│     ├─ user                   # UID/GID ou user:group
│     ├─ hostname               # Nom d’hôte
│     ├─ domainname             # Domaine DNS
│     ├─ environment            # Variables d’environnement (k:v ou liste)
│     ├─ env_file               # Fichiers .env additionnels (liste)
│     ├─ ports                  # Mappages hôte:conteneur (host:container[/proto])
│     ├─ expose                 # Ports exposés (inter-services uniquement)
│     ├─ volumes                # Montages (bind/volume/tmpfs)
│     │  ├─ <host:container[:ro|rw]>   # syntaxe courte
│     │  └─ type/bind/volume/tmpfs     # syntaxe longue + options
│     ├─ tmpfs                  # Montages tmpfs (liste ou objets)
│     ├─ devices                # Périphériques pass-through
│     ├─ ipc                    # Espace IPC (ex: "host")
│     ├─ pid                    # Espace PID (ex: "host")
│     ├─ shm_size               # Taille /dev/shm
│     ├─ ulimits                # Limites (nproc, nofile, etc.)
│     ├─ pids_limit             # Limite de PIDs
│     ├─ mem_limit              # Limite mémoire (ex: "512m")
│     ├─ cpus                   # Limite CPU (ex: "0.50")
│     ├─ cpu_shares             # Poids CPU relatif
│     ├─ cpuset                 # Affinité CPU (ex: "0-1" ou "0,2")
│     ├─ oom_kill_disable       # Désactiver OOM killer (bool)
│     ├─ oom_score_adj          # Ajustement score OOM
│     ├─ security_opt           # Options sécu (apparmor, selinux, seccomp=...)
│     ├─ cap_add                # Ajout de capacités Linux
│     ├─ cap_drop               # Retrait de capacités
│     ├─ privileged             # Mode privilégié (à éviter si possible)
│     ├─ sysctls                # sysctl kernel (ex: net.core.somaxconn)
│     ├─ read_only              # Système de fichiers racine en lecture seule
│     ├─ restart                # Politique de redémarrage (no, on-failure, always, unless-stopped)
│     ├─ depends_on             # Ordonnancement + conditions (service_healthy)
│     ├─ links                  # (legacy) Liaison de noms DNS entre services
│     ├─ networks               # Attachement aux réseaux définis
│     │  ├─ <network_name>
│     │  │  ├─ aliases          # Alias DNS dans ce réseau
│     │  │  ├─ ipv4_address     # IP statique v4 (si IPAM le permet)
│     │  │  └─ ipv6_address     # IP statique v6
│     ├─ dns                    # Serveurs DNS (liste)
│     ├─ dns_search             # Domaines de recherche DNS (liste)
│     ├─ extra_hosts            # Entrées /etc/hosts (ex: "app:10.10.0.10")
│     ├─ healthcheck            # Contrôle d’état
│     │  ├─ test                # CMD ou liste ["CMD", "curl", ...]
│     │  ├─ interval            # Période (ex: "10s")
│     │  ├─ timeout             # Timeout (ex: "2s")
│     │  ├─ retries             # Nombre d’essais
│     │  └─ start_period        # Délai avant 1er check
│     ├─ logging                # Logs du conteneur
│     │  ├─ driver              # ex: "json-file", "local", "syslog", "gelf"
│     │  └─ options             # options du driver (max-size, etc.)
│     ├─ labels                 # Étiquettes (k:v)
│     ├─ profiles               # Profils d’activation conditionnelle
│     ├─ tty                    # Allouer un pseudo-TTY
│     ├─ stdin_open             # Garder STDIN ouvert (équiv. -it)
│     ├─ stop_signal            # Signal d’arrêt (ex: SIGTERM)
│     └─ stop_grace_period      # Délai d’arrêt gracieux (ex: "30s")
├─ volumes                      # Volumes nommés (déclaratifs)
│  └─ <volume_name>
│     ├─ driver                 # Driver (par défaut "local")
│     ├─ driver_opts            # Options du driver
│     ├─ external               # true | { name: <nom_externe> }
│     ├─ labels                 # Étiquettes (k:v)
│     └─ name                   # Nom explicite (si différent de la clé)
├─ networks                     # Réseaux déclaratifs
│  └─ <network_name>
│     ├─ name                   # Nom explicite (différent de la clé)
│     ├─ driver                 # "bridge" (par défaut), "host", "none", ...
│     ├─ enable_ipv6            # Activer IPv6 (bool)
│     ├─ internal               # Isoler du monde extérieur (bool)
│     ├─ external               # true | { name: <nom_externe> }
│     ├─ labels                 # Étiquettes (k:v)
│     ├─ driver_opts            # Options du driver (bridge.* ...)
│     └─ ipam                   # Gestion d’adressage IP
│        ├─ driver              # Driver IPAM
│        ├─ options             # Options IPAM
│        └─ config              # Liste de sous-réseaux
│           └─ - subnet         # ex: "172.25.0.0/16"
│              ├─ gateway       # ex: "172.25.0.1"
│              ├─ ip_range      # Plage assignable
│              └─ aux_addresses # Noms→IP réservées
├─ labels                       # Labels globaux (au niveau projet)
├─ x-<extension>                # Blocs d’extension (ancres/merge YAML)
└─ (version)                    # Clé historique; inutile avec Compose spec
```

## 2. 🧰 Préparation de l’environnement

Exécuter sur une machine Linux ou VM Debian avec Docker et Docker Compose installés :

```bash
sudo apt update
sudo apt install -y docker.io docker-compose
sudo systemctl enable --now docker
```

Créer un répertoire de travail :

```bash
mkdir -p ~/atelier-compose-image-vs-build
cd ~/atelier-compose-image-vs-build
```

---

## 3. ⚙️ Étape 1 – Exemple avec image: (standard)

Créer le fichier **`docker-compose-image.yml`** :

```yaml
version: "3.9"

services:
  web:
    image: nginx:latest   # Utilise l'image officielle depuis Docker Hub
    ports:
      - "8080:80"
    container_name: nginx_image_example
```

### 🔍 Explications :

- `image: nginx:latest` → Docker va **télécharger** l’image depuis Docker Hub.

- Aucun `Dockerfile` n’est nécessaire.

- Le conteneur expose le port 80 du conteneur sur le port 8080 de la machine hôte.

### ▶️ Démarrage :

```bash
docker compose -f docker-compose-image.yml up -d
```

### ✅ Vérification :

```bash
curl http://localhost:8080
```

Vous devez voir la **page par défaut de Nginx**.

---

## 4. ⚙️ Étape 2 – Exemple avec build: (Dockerfile personnalisé)

Créer le fichier **`Dockerfile`** :

```bash
# Créer le fichier Dockerfile
FROM nginx:latest
# Copier une page HTML personnalisée
COPY index.html /usr/share/nginx/html/index.html
```

Créer le fichier **`index.html`** :

```html
<!DOCTYPE html>
<html lang="fr">
<head>
  <meta charset="UTF-8">
  <title>Page personnalisée Dockerfile</title>
</head>
<body style="font-family: Arial; text-align: center;">
  <h1>Bonjour depuis une image construite avec Dockerfile !</h1>
</body>
</html>
```

Créer le fichier **`docker-compose-build.yml`** :

```yaml
version: "3.9"

services:
  web:
    build: .                 # Construit à partir du Dockerfile local
    ports:
      - "8081:80"
    container_name: nginx_build_example
```

### 🔍 Explications :

- `build: .` → Docker Compose **construit une nouvelle image** à partir du Dockerfile présent dans le dossier courant.

- Cette image aura un contenu différent : la page HTML personnalisée remplace celle de Nginx.

- Le service sera exposé sur le port **8081** pour ne pas entrer en conflit avec l’autre.

### ▶️ Démarrage :

```bash
docker compose -f docker-compose-build.yml up -d --build
```

### ✅ Vérification :

```bash
curl http://localhost:8081
```

Vous devez voir :

```
Bonjour depuis une image construite avec Dockerfile !
```

## 5. 🧹 Nettoyage / Rollback

Pour supprimer les conteneurs, images et réseaux créés :

```bash
docker compose -f docker-compose-image.yml down
docker compose -f docker-compose-build.yml down
docker image prune -f
```

---

## 7. 💡 Astuces & Pièges

- ⚠️ Si vous combinez `image:` et `build:` sur le **même service**, Compose construit l’image **puis la tague** avec le nom fourni dans `image:` — ce n’est **pas une erreur**, mais il faut savoir ce que vous faites.

- ✅ Bon réflexe : utilisez `image:` pour les services **externes et stables**, `build:` pour vos **applications personalisée**.

- 🚀 Pour forcer une reconstruction :
  
  ```bash
  docker compose build --no-cache
  ```

## 8. ⚙️Combiner build **et** image dans un même service

## 1) Contexte & objectif

- **Pourquoi** : personnaliser l’image via un `Dockerfile` **et** lui donner un **nom/version** cohérent (ex. `demo/nginx-custom:1.0`) pour publication ou CI/CD.

- **Ce qui se passe** : `docker compose` **construit** l’image (clé `build:`), puis **l’étiquette** avec `image:`. Ce n’est **pas interdit** et c’est une pratique courante.

## 2) Préparation

Assurez-vous d’avoir Docker et Compose prêts, et placez-vous dans votre dossier d’atelier (ex. `~/atelier-compose-image-vs-build`).

## 3) Création des fichiers

Créer le fichier **index.html** :

```bash
<!DOCTYPE html>
<html lang="fr">
<head>
  <meta charset="UTF-8">
  <title>Nginx personnalisé — build + image</title>
</head>
<body style="font-family: Arial; text-align: center;">
  <h1>Nginx personnalisé (build) avec un tag d'image (image: demo/nginx-custom:1.0)</h1>
  <p>Cette page provient d'une image construite localement puis étiquetée.</p>
</body>
</html>
```

Créer le fichier **Dockerfile** :

```bash
# Image de base officielle Nginx
FROM nginx:latest
# Copier une page HTML personnalisée dans le document root par défaut de Nginx
COPY index.html /usr/share/nginx/html/index.html
```

Créer le fichier **docker-compose.yml** :

```yaml
version: "3.9"

services:
  web:
    # 1) build = construction à partir du Dockerfile local
    build: .

    # 2) image = nom/étiquette (tag) final de l'image construite
    image: demo/nginx-custom:1.0

    # Publication du service en local
    ports:
      - "8082:80"

    # Nom explicite du conteneur (optionnel mais pratique)
    container_name: nginx_build_and_image_example

    # Variable d'environnement illustrative (optionnelle)
    environment:
      - NGINX_ENV=demo-build-image
```

## 4) Exécution & vérifications

Construire et démarrer :

```bash
docker compose up -d --build
```

Vérifier l’image construite et **taguée** :

```bash
docker images | grep -E 'demo/nginx-custom|REPOSITORY|TAG'
```

Résultat attendu (exemple) :

```
REPOSITORY            TAG       IMAGE ID       CREATED          SIZE
demo/nginx-custom     1.0       a1b2c3d4e5f6   <il y a  X sec>  187MB
```

Vérifier le conteneur :

```bash
docker compose ps
```

Vérifier la page servie :

```bash
curl -s http://localhost:8082 | head -n 5
```

Vous devez voir le HTML mentionnant **image: demo/nginx-custom:1.0**.

### Rebuild après modification (cache)

Modifiez le `<h1>` dans `index.html`, puis :

```bash
docker compose build
docker compose up -d
curl -s http://localhost:8082 | head -n 5
```

Vous constatez la **mise à jour**.

## 5) Nettoyage / rollback

```bash
docker compose down
docker rmi demo/nginx-custom:1.0 || true
```

## 6) Astuces & pièges

- `build` **+** `image` dans le **même service** = **valide** : Compose **construit** puis **tague** l’image.

- Pensez à `.dockerignore` pour accélérer les builds.

- Préférez des tags **versionnés** (évitez `latest`) pour la traçabilité.

- Contrôlez le **contexte** (`build: .`) : s’il est trop large, le build sera lent.

- Publication éventuelle : `docker login` puis `docker push demo/nginx-custom:1.0`.

---

# 🧑‍🏫 Atelier 2: Comprendre entrypoint et command dans Docker Compose

## 1. 🎯 Contexte & Objectif

L’objectif de cet atelier est de **comprendre la différence entre `entrypoint` et `command`** dans Docker Compose et d’expérimenter leur comportement sur un conteneur simple.

Nous allons :

- Créer une image à partir d’un `Dockerfile` qui définit un **ENTRYPOINT** et un **CMD**.

- Modifier ce comportement via `docker-compose.yml` à l’aide des clés `entrypoint` et `command`.

- Observer les effets sur l’exécution du conteneur.

---

## 2. 🧰 Préparation de l’environnement

Créer le répertoire de travail :

```bash
mkdir -p ~/atelier-entrypoint-command
cd ~/atelier-entrypoint-command
```

---

## 3. ⚙️ Étape 1 – Créer une image avec ENTRYPOINT et CMD

Créer le fichier **Dockerfile** :

```bash
FROM debian:stable-slim

# Installer un petit utilitaire (ping)
RUN apt update && apt install -y iputils-ping && apt clean

# Définir le point d'entrée et la commande par défaut
ENTRYPOINT ["ping"]
CMD ["127.0.0.1"]
```

### Explication :

- `ENTRYPOINT ["ping"]` → définit le programme **exécutable principal** du conteneur.

- `CMD ["127.0.0.1"]` → fournit **les arguments par défaut** à ce programme.  
  → donc par défaut, le conteneur exécutera :
  
  ```bash
  ping 127.0.0.1
  ```

Construire l’image :

```bash
docker build -t ping-demo .
```

Tester directement :

```bash
docker run --rm ping-demo -c 2
```

> ✅ Résultat attendu :  
> Deux requêtes ICMP vers `127.0.0.1` s’affichent.

---

## 4. ⚙️ Étape 2 – Utilisation de command: dans Docker Compose

Créer le fichier **docker-compose-command.yml** :

```yaml
version: "3.9"

services:
  ping_service:
    image: ping-demo
    command: ["-c", "3", "8.8.8.8"]   # Remplace uniquement CMD, pas ENTRYPOINT
```

### Explication :

- `command:` **remplace le CMD** défini dans le Dockerfile, **mais garde l’ENTRYPOINT**.

- Donc ici le conteneur exécutera :
  
  ```bash
  ping -c 3 8.8.8.8
  ```

Démarrage du service :

```bash
docker compose -f docker-compose-command.yml up
```

> ✅ Résultat attendu :  
> Le conteneur ping trois fois l’adresse `8.8.8.8` (Google DNS).

Arrêter le service :

```bash
docker compose -f docker-compose-command.yml down
```

---

## 5. ⚙️ Étape 3 – Utilisation de `entrypoint:` dans Docker Compose

Créer le fichier **docker-compose-entrypoint.yml** :

```yaml
version: "3.9"

services:
  ping_service:
    image: ping-demo
    entrypoint: ["echo", "Le point d'entrée a été modifié !"]
```

### Explication :

- `entrypoint:` **remplace complètement** l’ENTRYPOINT du Dockerfile.

- `command:` (ou le CMD d’origine) devient alors **les arguments passés** à cette nouvelle commande.

- Dans ce cas, Docker exécutera :
  
  ```bash
  echo Le point d'entrée a été modifié !
  ```

Démarrage :

```bash
docker compose -f docker-compose-entrypoint.yml up
```

> ✅ Résultat attendu :  
> Le conteneur affiche simplement :
> 
> ```
> Le point d'entrée a été modifié !
> ```
> 
> puis s’arrête.

---

## 6. ⚙️ Étape 4 – Combiner entrypoint: et command: dans Docker Compose

Créer le fichier **docker-compose-both.yml** :

```yaml
version: "3.9"

services:
  ping_service:
    image: ping-demo
    entrypoint: ["ping"]
    command: ["-c", "2", "1.1.1.1"]
```

### Explication :

- Ici, **les deux** sont redéfinis.

- `entrypoint:` → redéfinit le binaire à exécuter.

- `command:` → redéfinit ses arguments.

Résultat final exécuté :

```bash
ping -c 2 1.1.1.1
```

Démarrage :

```bash
docker compose -f docker-compose-both.yml up
```

> ✅ Résultat attendu :  
> Deux paquets ICMP envoyés vers `1.1.1.1`.

---

## 7. 🧹 Nettoyage / Rollback

Arrêter et supprimer tous les services et images :

```bash
docker compose -f docker-compose-command.yml down
docker compose -f docker-compose-entrypoint.yml down
docker compose -f docker-compose-both.yml down
docker rmi ping-demo
```

## 8. 💡 Astuces & Pièges

- ⚠️ `entrypoint` **remplace totalement** l’ENTRYPOINT du Dockerfile → il ne conserve pas l’ancien.

- ⚙️ `command` **remplace uniquement CMD** → il s’ajoute à l’ENTRYPOINT existant.

- 🧩 Si vous utilisez `entrypoint` dans Compose, vérifiez bien les arguments attendus : sinon le conteneur peut se bloquer ou quitter immédiatement.

- 🔎 Pour diagnostiquer le comportement réel :
  
  ```bash
  docker inspect <nom_du_conteneur> | grep -A 2 Cmd
  ```

# Atelier 3 : Utiliser entrypoint pour lancer un script de démarrage avant l’application (Docker Compose)

## 1) Contexte & objectif

Mettre en place un **hook de démarrage** via `entrypoint` qui exécute un **script Bash** (pré-checks, logs, génération d’artifacts) avant de lancer l’application. Comprendre :

- `entrypoint` = lance votre script, puis passe la main à l’app.

- `command` (Compose) = remplace le `CMD` (arguments/commande de l’app), **sans toucher** à l’`entrypoint`.

## 2) Préparation de l’environnement

Exécuter sur Debian/Ubuntu.

```bash
mkdir -p ~/atelier-entrypoint-startup && cd ~/atelier-entrypoint-startup
```

## 3) Création des fichiers (application Flask + script d’entrée)

Créer le fichier **Dockerfile** :

```bash
FROM python:3.12-slim
# Dossier de travail
WORKDIR /app
# Copier sources
COPY app.py /app/app.py
COPY entrypoint.sh /app/entrypoint.sh
# Dépendance minimale pour la démo
RUN pip install --no-cache-dir Flask
# Rendre exécutable l’entrypoint
RUN chmod +x /app/entrypoint.sh
# Définir ENTRYPOINT (hook) et CMD (commande par défaut de l’app)
ENTRYPOINT ["/app/entrypoint.sh"]
CMD ["python", "app.py"]
```

Créer le fichier **entrypoint.sh** :

```bash
#!/usr/bin/env bash
# Script d’entrée : prépare l’environnement puis lance l’app
set -euo pipefail  # exit on error, undefined var, and pipefail pour fiabilité

# 1) Journalisation de démarrage
echo "[ENTRYPOINT] Démarrage du conteneur à $(date '+%F %T')"

# 2) Lire variables d’environnement (avec valeurs par défaut)
APP_MESSAGE="${APP_MESSAGE:-Bonjour depuis Flask via ENTRYPOINT !}"
APP_HOST="${APP_HOST:-0.0.0.0}"
APP_PORT="${APP_PORT:-8000}"
echo "[ENTRYPOINT] Variables: APP_MESSAGE='${APP_MESSAGE}', APP_HOST='${APP_HOST}', APP_PORT='${APP_PORT}'"

# 3) Générer un petit artifact prouvant le passage du hook
BOOT_DIR="/app/boot-artifacts"
mkdir -p "${BOOT_DIR}"
echo "Boot OK à $(date '+%F %T')" > "${BOOT_DIR}/startup.ok"
echo "[ENTRYPOINT] Artifact généré: ${BOOT_DIR}/startup.ok"

# 4) (Optionnel) Attendre un service externe (DB, API…) – exemple désactivé
# sleep 0.5

# 5) Exporter pour l’app
export APP_MESSAGE APP_HOST APP_PORT

# 6) Lancer l’application (remplace le PID 1) en transmettant la commande/arguments
echo "[ENTRYPOINT] Lancement de l'application: $*"
exec "$@"
```

Créer le fichier **app.py** :

```bash
from flask import Flask
import os

app = Flask(__name__)

@app.get("/")
def hello():
    # Message injecté via variables d'environnement (setup par l'entrypoint)
    message = os.getenv("APP_MESSAGE", "Bonjour !")
    return f"<h1>{message}</h1>"

if __name__ == "__main__":
    host = os.getenv("APP_HOST", "0.0.0.0")
    port = int(os.getenv("APP_PORT", "8000"))
    app.run(host=host, port=port, debug=False)
```

## 4) Fichier Docker Compose (avec entrypoint + command)

Créer le fichier **docker-compose.yml** :

```bash
version: "3.9"

services:
  web:
    build: .
    # entrypoint déjà présent dans l'image -> on ne le redéfinit pas ici
    command: ["python", "app.py"]    # remplace le CMD du Dockerfile si désiré
    environment:
      - APP_MESSAGE=Salut depuis Compose (CMD par défaut)
      - APP_HOST=0.0.0.0
      - APP_PORT=8080
    ports:
      - "8080:8080"
    # volumes:
    #   - ./artifacts:/app/boot-artifacts  # décommentez pour observer startup.ok côté hôte
```

## 5) Exécution pas à pas

```bash
docker compose up -d --build   # construit l'image et démarre le service
docker compose logs -f web     # observe les logs : [ENTRYPOINT] puis Flask
```

Vérification HTTP :

```bash
curl -s http://localhost:8080
# Attendu : <h1>Salut depuis Compose (CMD par défaut)</h1>
```

## 6) Variation — remplacer uniquement la commande (ENTRYPOINT inchangé)

Sans toucher au fichier, lancez avec d’autres paramètres :

```bash
docker compose run --rm -p -d 8082:8081 \
  -e APP_MESSAGE="Message dynamique via run" \
  -e APP_PORT=8082 \
  web python app.py

curl -s http://localhost:8082
# Attendu : <h1>Message dynamique via run</h1>
```

## 7) Nettoyage / rollback

```bash
docker compose down -v
docker image prune -f
```

## 8) Astuces & pièges

- Utilisez **`exec "$@"`** dans l’entrypoint pour transmettre correctement les signaux au process app (PID 1).

- L’**entrypoint ne doit pas bloquer** : préparez, loggez, puis **remettez la main** à l’app.

- **`entrypoint` remplace l’ENTRYPOINT de l’image** si redéfini côté Compose ; **`command` remplace le CMD**.

- Diagnostic rapide :
  
  ```bash
  docker compose ps
  docker inspect $(docker compose ps -q web) | grep -A2 -E '"Entrypoint"|"Cmd"'
  ```

Excellent retour 👌 — tu as entièrement raison.  
On va **reprendre l’atelier 1 (`restart`)** sous **forme de démarche progressive et expérimentale**, *cas par cas*, chaque politique testée séparément,  
avec pour chaque cas :

- Contexte

- Fichiers nécessaires

- Commandes pas à pas

- Résultats attendus

- Analyse du comportement

- Nettoyage spécifique

Ce format correspond exactement au **mode “recette pédagogique complète”** que tu demandes.

---

# 🧪 Atelier 1 — Politiques `restart` dans Docker Compose (cas par cas)

---

## 🧭 Objectif global

Explorer **comment Docker Compose gère le redémarrage automatique** des conteneurs via la directive :

```yaml
restart: <politique>
```

Nous allons tester **4 politiques** indépendamment :

1. `no`

2. `on-failure`

3. `always`

4. `unless-stopped`

Chaque cas est isolé, reproductible, et inclut sa vérification.

---

## 🧰 Préparation de l’environnement

Sur une machine Linux (Debian/Ubuntu) :

```bash
sudo apt update
sudo apt install -y docker.io docker-compose
sudo systemctl enable --now docker
```

Créer un répertoire de travail :

```bash
mkdir -p ~/atelier-compose-restart && cd ~/atelier-compose-restart
```

---

# ⚙️ CAS 1 — `restart: "no"`

### 🎯 Objectif

Observer le comportement **par défaut** : le conteneur **ne redémarre jamais**, même en cas d’échec.

---

### 🧩 Étape 1 — Créer le fichier Compose

Créer **docker-compose-no.yml** :

```yaml
version: "3.9"

services:
  test_no:
    image: alpine:3.20
    container_name: restart_no_demo
    command: ["/bin/sh", "-c", "echo 'Je sors immédiatement avec succès'; exit 0"]
    restart: "no"
```

---

### ▶️ Étape 2 — Exécution

```bash
docker compose -f docker-compose-no.yml up -d
```

### 🔍 Étape 3 — Observation

```bash
docker compose -f docker-compose-no.yml ps
```

Résultat attendu :

```
NAME               STATE       EXITED
restart_no_demo    exited(0)   il y a quelques secondes
```

Vérifions les logs :

```bash
docker logs restart_no_demo
# Affiche : Je sors immédiatement avec succès
```

### 🧠 Analyse

- Le conteneur **ne redémarre pas**.

- L’état final est `Exited (0)`.

- `restart: "no"` est **le comportement par défaut** quand la clé est absente.

### 🧹 Nettoyage

```bash
docker compose -f docker-compose-no.yml down
```

---

# ⚙️ CAS 2 — `restart: on-failure`

### 🎯 Objectif

Observer que le conteneur redémarre **uniquement** en cas d’erreur (`exit code ≠ 0`).

---

### 🧩 Étape 1 — Créer le fichier Compose

Créer **docker-compose-onfailure.yml** :

```yaml
version: "3.9"

services:
  test_onfailure:
    image: alpine:3.20
    container_name: restart_onfailure_demo
    command: ["/bin/sh", "-c", "echo 'Je sors avec erreur'; exit 1"]
    restart: on-failure
```

---

### ▶️ Étape 2 — Lancer le test

```bash
docker compose -f docker-compose-onfailure.yml up -d
```

### 🔍 Étape 3 — Suivre le comportement

```bash
docker compose -f docker-compose-onfailure.yml ps
```

Attendu :

```
restart_onfailure_demo   Restarting (1) ...   
```

Lance ensuite :

```bash
docker inspect restart_onfailure_demo --format '{{ .RestartCount }}'
```

Résultat attendu :

```
1 (ou 2 ou plus)
```

### 🧠 Analyse

- Le conteneur redémarre **à chaque échec**.

- `exit 1` déclenche un redémarrage immédiat.

- Si l’application continue à échouer, Compose boucle indéfiniment.

- En revanche, si l’application finit par `exit 0`, elle **ne redémarrera plus**.

### 🔎 Vérification manuelle :

```bash
docker logs --tail=5 restart_onfailure_demo
# On verra plusieurs "Je sors avec erreur"
```

### 🧹 Nettoyage

```bash
docker compose -f docker-compose-onfailure.yml down
```

---

# ⚙️ CAS 3 — `restart: always`

### 🎯 Objectif

Tester un conteneur qui redémarre **quoi qu’il arrive** (succès, erreur, ou arrêt du démon Docker).

---

### 🧩 Étape 1 — Créer le fichier Compose

Créer **docker-compose-always.yml** :

```yaml
version: "3.9"

services:
  test_always:
    image: alpine:3.20
    container_name: restart_always_demo
    command: ["/bin/sh", "-c", "echo 'Je dors 1s puis je sors'; sleep 1; exit 0"]
    restart: always
```

---

### ▶️ Étape 2 — Lancer

```bash
docker compose -f docker-compose-always.yml up -d
```

### 🔍 Étape 3 — Observer la boucle

```bash
docker compose -f docker-compose-always.yml ps
```

Attendu :

```
restart_always_demo   Restarting (0) ...
```

Suivre les logs :

```bash
docker logs -f restart_always_demo
```

Le message "Je dors 1s puis je sors" se répète en boucle.

### 🧠 Analyse

- Le conteneur redémarre même avec un **code de sortie 0**.

- Même après un `docker kill`, Docker le relance.

- Si le démon Docker redémarre → ce conteneur **repart automatiquement**.

- Seul `docker stop` suivi de `docker rm` stoppera définitivement.

### 🧹 Nettoyage

```bash
docker compose -f docker-compose-always.yml down
```

---

# ⚙️ CAS 4 — `restart: unless-stopped`

### 🎯 Objectif

Tester un comportement identique à `always`, **sauf si** le conteneur a été **arrêté volontairement**.

---

### 🧩 Étape 1 — Créer le fichier Compose

Créer **docker-compose-unless.yml** :

```yaml
version: "3.9"

services:
  test_unless:
    image: alpine:3.20
    container_name: restart_unless_demo
    command: ["/bin/sh", "-c", "echo 'Je tourne, puis je sors'; sleep 1; exit 0"]
    restart: unless-stopped
```

---

### ▶️ Étape 2 — Lancer le service

```bash
docker compose -f docker-compose-unless.yml up -d
```

### 🔍 Étape 3 — Vérifier le comportement

```bash
docker compose -f docker-compose-unless.yml ps
# Attendu: Restarting (0) ... ou Up (selon le moment)
```

Maintenant arrête le conteneur manuellement :

```bash
docker stop restart_unless_demo
docker compose -f docker-compose-unless.yml ps
```

Attendu :

```
restart_unless_demo   Exited (0)
```

👉 Il ne redémarre **pas** après un `stop` manuel.

Si tu redémarres le démon Docker (`sudo systemctl restart docker`),  
ce conteneur **ne repartira pas** car il a été explicitement stoppé.

---

### 🧠 Analyse

- Redémarre comme `always` après crash ou reboot hôte.

- **Exception** : si stoppé manuellement, il reste arrêté.

- Pratique pour les services persistants, sans redémarrage intempestif après maintenance manuelle.

---

### 🧹 Nettoyage global

```bash
docker compose -f docker-compose-unless.yml down
docker image prune -f
```

---

# 📊 Résumé comparatif

| Politique        | Redémarre après crash | Redémarre après `exit 0` | Redémarre après `docker restart daemon` | Redémarre après `docker stop` |
| ---------------- | --------------------- | ------------------------ | --------------------------------------- | ----------------------------- |
| `no`             | ❌                     | ❌                        | ❌                                       | ❌                             |
| `on-failure`     | ✅ (exit≠0)            | ❌                        | ❌                                       | ❌                             |
| `always`         | ✅                     | ✅                        | ✅                                       | ✅                             |
| `unless-stopped` | ✅                     | ✅                        | ✅                                       | ❌ (si stoppé manuellement)    |

---

## 🧠 Astuces & pièges pédagogiques

- **Compose ne gère pas `on-failure:N`** → la limite d’essais n’existe que dans `docker run`.

- **Ne combinez pas `always` avec des jobs batch** (risque d’exécution infinie).

- **Production :** préférez `unless-stopped` pour des services persistants (bases, web servers).

- **Debug :** pour des scripts ponctuels ou tests unitaires, laissez `restart: "no"`.

Parfait ⚙️  
Nous enchaînons avec le **🧪 Atelier 2 — `depends_on` vs démarrage manuel (`--link`) et équivalents modernes**  
➡️ toujours en **mode “recette pédagogique complète”**, avec expérimentation progressive.

---

# 🧪 Atelier 2 — Orchestration du démarrage : `depends_on` vs `--link`

---

## 1️⃣ Contexte & objectif

L’objectif de cet atelier est de comprendre :

- 🧩 le **rôle de `depends_on`** dans un `docker-compose.yml`

- 🕒 comment il **ordonne le démarrage** des services

- ⚙️ la différence avec l’ancien `--link` (aujourd’hui obsolète)

- 🚀 la **bonne pratique moderne** : communication via **réseaux Docker** et **DNS interne**

Nous allons créer **deux services** :

1. une **base de données MySQL**,

2. une **application web** (client) qui attend que MySQL soit disponible.

---

## 2️⃣ Préparation de l’environnement

Sur votre machine Linux (Debian/Ubuntu) :

```bash
sudo apt update
sudo apt install -y docker.io docker-compose
sudo systemctl enable --now docker
```

Créer le répertoire de travail :

```bash
mkdir -p ~/atelier-compose-depends-on && cd ~/atelier-compose-depends-on
```

---

# ⚙️ CAS 1 — Sans `depends_on` (erreur de timing)

### 🎯 Objectif

Observer qu’un service peut **échouer au démarrage** si la base MySQL n’est pas encore prête.

---

### 🧩 Étape 1 — Créer le fichier Compose

Créer **docker-compose-no-depends.yml** :

```yaml
version: "3.9"

services:
  db:
    image: mysql:8.4
    container_name: db_no_depends
    environment:
      - MYSQL_ROOT_PASSWORD=rootpass
      - MYSQL_DATABASE=testdb

  web:
    image: alpine:3.20
    container_name: web_no_depends
    command: ["/bin/sh", "-c", "sleep 2 && mysql -h db -u root -prootpass -e 'SHOW DATABASES;'"]
    depends_on: []   # volontairement vide (aucun lien)
```

---

### ▶️ Étape 2 — Démarrage

```bash
docker compose -f docker-compose-no-depends.yml up -d
```

---

### 🔍 Étape 3 — Observation

Afficher les logs du service web :

```bash
docker logs web_no_depends
```

Résultat typique :

```
ERROR 2002 (HY000): Can't connect to MySQL server on 'db' (111)
```

### 🧠 Analyse

- Le conteneur **web** tente de se connecter à MySQL avant que celui-ci soit prêt.

- Résultat : **échec immédiat**, l’ordre n’est pas garanti sans `depends_on`.

### 🧹 Nettoyage

```bash
docker compose -f docker-compose-no-depends.yml down -v
```

---

# ⚙️ CAS 2 — Avec `depends_on`

### 🎯 Objectif

Forcer Docker Compose à **démarrer la base avant l’application**.

---

### 🧩 Étape 1 — Créer le fichier Compose

Créer **docker-compose-depends.yml** :

```yaml
version: "3.9"

services:
  db:
    image: mysql:8.4
    container_name: db_with_depends
    environment:
      - MYSQL_ROOT_PASSWORD=rootpass
      - MYSQL_DATABASE=testdb

  web:
    image: alpine:3.20
    container_name: web_with_depends
    depends_on:
      - db
    command: ["/bin/sh", "-c", "sleep 2 && mysql -h db -u root -prootpass -e 'SHOW DATABASES;'"]
```

---

### ▶️ Étape 2 — Démarrage

```bash
docker compose -f docker-compose-depends.yml up -d
```

---

### 🔍 Étape 3 — Observation

Vérifier les logs :

```bash
docker logs web_with_depends
```

Résultat attendu :

```
Database
information_schema
mysql
performance_schema
sys
testdb
```

### 🧠 Analyse

- `depends_on` fait bien démarrer `db` **avant** `web`.

- ⚠️ Cependant, il **ne garantit pas** que le service MySQL **soit prêt**.  
  Il garantit uniquement le **lancement** dans l’ordre.

- Si `db` met trop de temps à initialiser, le même problème peut revenir.

### 🧹 Nettoyage

```bash
docker compose -f docker-compose-depends.yml down -v
```

---

# ⚙️ CAS 3 — `depends_on.condition: service_healthy` (Compose v3.9+)

### 🎯 Objectif

Améliorer la fiabilité en ne lançant `web` que **lorsque `db` est réellement prêt**.

---

### 🧩 Étape 1 — Créer le fichier Compose

Créer **docker-compose-healthy.yml** :

```yaml
version: "3.9"

services:
  db:
    image: mysql:8.4
    container_name: db_healthy
    environment:
      - MYSQL_ROOT_PASSWORD=rootpass
      - MYSQL_DATABASE=testdb
    healthcheck:
      test: ["CMD", "mysqladmin", "ping", "-h", "localhost"]
      interval: 3s
      timeout: 2s
      retries: 5
      start_period: 5s

  web:
    image: alpine:3.20
    container_name: web_after_health
    depends_on:
      db:
        condition: service_healthy
    command: ["/bin/sh", "-c", "mysql -h db -u root -prootpass -e 'SELECT DATABASE();'"]
```

---

### ▶️ Étape 2 — Démarrage

```bash
docker compose -f docker-compose-healthy.yml up -d
```

---

### 🔍 Étape 3 — Vérifier l’état

```bash
docker compose -f docker-compose-healthy.yml ps
```

Le service `db` doit afficher :

```
healthy
```

Vérifier les logs du web :

```bash
docker logs web_after_health
```

Résultat attendu :

```
+-------------+
| DATABASE()  |
+-------------+
| testdb      |
+-------------+
```

### 🧠 Analyse

- Ici, `depends_on.condition: service_healthy` attend le **signal de santé OK** avant d’exécuter `web`.

- Ce mécanisme est **le remplaçant moderne** de `--link`, car Compose gère :
  
  - la dépendance,
  
  - le DNS automatique (`db` résolu via le réseau par défaut),
  
  - et la santé.

---

# ⚙️ CAS 4 — Comparaison avec `--link` (ancienne méthode)

### 🎯 Objectif

Montrer pourquoi `--link` n’est plus recommandé.

---

### 🧩 Étape 1 — Exemple manuel

Sans Compose, essayons avec `docker run` :

```bash
docker run -d --name old_db -e MYSQL_ROOT_PASSWORD=rootpass mysql:8.4
docker run --rm --name old_web --link old_db:mysql alpine:3.20 \
  sh -c "apk add mysql-client -q && mysql -h mysql -uroot -prootpass -e 'SHOW DATABASES;'"
```

Résultat :

```
ERROR 2002 (HY000): Can't connect to MySQL server on 'mysql' (111)
```

---

### 🧠 Analyse

- `--link` créait un alias DNS interne figé, sans attendre que le conteneur soit prêt.

- Il ne fonctionne pas avec les réseaux personnalisés modernes (`bridge`, `overlay`).

- ⚠️ Cette option est **dépréciée** depuis Docker 1.13.

- Les bonnes pratiques actuelles :
  
  - utiliser `depends_on` ;
  
  - ajouter un `healthcheck` ;
  
  - utiliser des **réseaux déclarés** (nous le verrons à l’atelier 6).

---

# 🧹 Nettoyage global

```bash
docker compose -f docker-compose-healthy.yml down -v
docker rm -f old_db || true
```

---

# 📊 Résumé pédagogique

| Méthode                                 | Fonction                      | Garantit ordre | Garantit “ready” | Recommandée ? |
| --------------------------------------- | ----------------------------- | -------------- | ---------------- | ------------- |
| Aucun lien                              | Services démarrent sans ordre | ❌              | ❌                | ❌             |
| `depends_on` simple                     | Lance dans l’ordre            | ✅              | ❌                | ⚠️            |
| `depends_on.condition: service_healthy` | Attente réelle de santé       | ✅              | ✅                | ✅             |
| `--link` (legacy)                       | Lien statique de conteneurs   | partiel        | ❌                | ❌ (obsolète)  |

---

# 💡 Astuces & bonnes pratiques

- ✅ **Ajoutez toujours un `healthcheck`** pour vos bases et API.

- ✅ **Préférez `depends_on.condition: service_healthy`** pour fiabilité.

- ⚠️ **Ne pas confondre** “ordre de lancement” (Compose) et “dépendance réseau” (réseau Docker).

- 💡 Compose crée **un DNS automatique** par nom de service (ex. `db` → IP du conteneur).

- ❌ **Évitez `--link`** : non maintenu, non compatible Swarm ou réseaux modernes.

# 🧪 Atelier 3 — Variables d’environnement : `environment` vs `env_file`

---

## 1️⃣ Contexte & Objectif

Dans Compose, il existe **deux méthodes principales** :

| Méthode        | Description                                                         | Cas d’usage                                       |
| -------------- | ------------------------------------------------------------------- | ------------------------------------------------- |
| `environment:` | Variables directement écrites dans le fichier `docker-compose.yml`. | Valeurs simples, visibles immédiatement.          |
| `env_file:`    | Variables externalisées dans un fichier `.env`.                     | Séparation des secrets, meilleure maintenabilité. |



---

## 2️⃣ Préparation de l’environnement

Créer le répertoire de travail :

```bash
mkdir -p ~/atelier-compose-env && cd ~/atelier-compose-env
```

---

# ⚙️ CAS 1 — Utilisation directe de `environment:`

### 🎯 Objectif

Définir des variables d’environnement **en clair** dans le fichier Compose et les visualiser à l’intérieur du conteneur.

---

### 🧩 Étape 1 — Créer le fichier Compose

Créer le fichier **docker-compose-environment.yml** :

```yaml
version: "3.9"

services:
  app_env:
    image: alpine:3.20
    container_name: demo_environment
    command: ["sh", "-c", "echo '🧩 Variables internes:'; env | sort"]
    environment:
      - APP_NAME=ComposeDemo
      - APP_ENV=development
      - APP_PORT=8080
      - DEBUG=true
      - DATABASE_URL=mysql://root:pass@db:3306/demo
```

#### 💡 Explication ligne par ligne :

- `image: alpine:3.20` → image légère Linux, idéale pour inspection.

- `command:` → commande à exécuter au démarrage.  
  On affiche toutes les variables (`env | sort`) triées alphabétiquement pour lisibilité.

- `environment:` → liste clé=valeur injectée directement dans le conteneur.

---

### ▶️ Étape 2 — Lancer le service

```bash
docker compose -f docker-compose-environment.yml up
```

> ⚙️ Le conteneur va exécuter la commande `env | sort` puis s’arrêter.

---

### 🔍 Étape 3 — Observer la sortie

Sortie attendue à l’écran :

```
🧩 Variables internes:
APP_ENV=development
APP_NAME=ComposeDemo
APP_PORT=8080
DATABASE_URL=mysql://root:pass@db:3306/demo
DEBUG=true
HOSTNAME=demo_environment
PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
PWD=/
SHLVL=1
```

---

### 🧠 Analyse

- Les variables définies sous `environment:` sont **visibles dans le conteneur** via `env`.

- Elles sont **persistantes uniquement pendant la durée du conteneur**.

- Il est **dangereux** d’y placer des secrets (ex: mots de passe, API key) car elles sont visibles via :
  
  ```bash
  docker inspect demo_environment
  ```

- Avantage : rapidité, clarté dans le fichier Compose.

- Inconvénient : risque de fuite d’informations sensibles.

---

### 🧹 Nettoyage

```bash
docker compose -f docker-compose-environment.yml down
```

---

# ⚙️ CAS 2 — Utilisation de `env_file:`

### 🎯 Objectif

Séparer la configuration dans un fichier `.env` externe.

---

### 🧩 Étape 1 — Créer le fichier `.env`

Créer le fichier **.env.app** :

```bash
APP_NAME=EnvFileDemo
APP_ENV=production
APP_PORT=9090
DEBUG=false
DATABASE_URL=postgres://admin:secret@db:5432/prod
```

---

### 🧩 Étape 2 — Créer le fichier Compose

Créer **docker-compose-envfile.yml** :

```yaml
version: "3.9"

services:
  app_envfile:
    image: alpine:3.20
    container_name: demo_envfile
    command: ["sh", "-c", "echo '📁 Variables depuis env_file:'; env | grep -E 'APP_|DEBUG|DATABASE_URL' | sort"]
    env_file:
      - .env.app
```

#### 💡 Explication ligne par ligne :

- `env_file:` → Compose lit le fichier `.env.app` et injecte **toutes les variables** qu’il contient.

- Chaque ligne `VAR=VALEUR` devient une variable dans le conteneur.

- On utilise `grep` pour n’afficher que les variables d’intérêt.

---

### ▶️ Étape 3 — Lancer

```bash
docker compose -f docker-compose-envfile.yml up
```

---

### 🔍 Étape 4 — Résultat attendu

```
📁 Variables depuis env_file:
APP_ENV=production
APP_NAME=EnvFileDemo
APP_PORT=9090
DATABASE_URL=postgres://admin:secret@db:5432/prod
DEBUG=false
```

---

### 🧠 Analyse

- Les variables viennent **du fichier `.env.app`** sans être écrites dans le YAML.

- Si vous modifiez `.env.app` et relancez `docker compose up`, les valeurs changent automatiquement.

- Vous pouvez définir **plusieurs fichiers** avec :
  
  ```yaml
  env_file:
    - .env.common
    - .env.prod
  ```
  
  → le dernier fichier écrase les variables précédentes s’il y a conflit.

---

### 🧹 Nettoyage

```bash
docker compose -f docker-compose-envfile.yml down
```

---

# ⚙️ CAS 3 — Combinaison `environment` + `env_file`

### 🎯 Objectif

Vérifier la **priorité** lorsque la même variable existe dans les deux endroits.

---

### 🧩 Étape 1 — Créer les fichiers

Créer **.env.combined** :

```bash
APP_NAME=FromEnvFile
DEBUG=false
LOG_LEVEL=info
```

Créer **docker-compose-combined.yml** :

```yaml
version: "3.9"

services:
  app_combined:
    image: alpine:3.20
    container_name: demo_combined
    env_file:
      - .env.combined
    environment:
      - APP_NAME=FromEnvironment
      - DEBUG=true
      - EXTRA=from_compose
    command: ["sh", "-c", "echo '🔄 Priorités:'; env | grep -E 'APP_|DEBUG|LOG_|EXTRA' | sort"]
```

---

### ▶️ Étape 2 — Exécution

```bash
docker compose -f docker-compose-combined.yml up
```

---

### 🔍 Étape 3 — Résultat attendu

```
🔄 Priorités:
APP_NAME=FromEnvironment
DEBUG=true
EXTRA=from_compose
LOG_LEVEL=info
```

---

### 🧠 Analyse

| Source                                                     | Priorité               | Exemple                              |
| ---------------------------------------------------------- | ---------------------- | ------------------------------------ |
| `environment:` (dans le YAML)                              | 🔺 plus haute          | `APP_NAME` vient d’ici               |
| `env_file:`                                                | 🔻 plus basse          | `LOG_LEVEL` vient du `.env.combined` |
| Variables définies dans le shell avant `docker compose up` | 🔺🔺 priorité maximale | `$ export VAR=value` avant exécution |

**Ordre de résolution finale :**

1. Variables du **shell courant** (exportées via `export VAR=value`)

2. Variables de `environment:`

3. Variables des `env_file:`

4. Variables globales du `.env` racine du projet

---

# ⚙️ CAS 4 — Substitution de variables dans Compose

### 🎯 Objectif

Montrer comment **injecter des variables système** dans le fichier YAML via `${}`.

---

### 🧩 Étape 1 — Exporter une variable système

```bash
export APP_VERSION=1.0.7
```

---

### 🧩 Étape 2 — Créer le fichier Compose

Créer **docker-compose-substitution.yml** :

```yaml
version: "3.9"

services:
  app_subst:
    image: alpine:3.20
    container_name: demo_subst
    command: ["sh", "-c", "echo '🔧 Version injectée: ${APP_VERSION}'"]
```

---

### ▶️ Étape 3 — Exécution

```bash
docker compose -f docker-compose-substitution.yml up
```

Résultat attendu :

```
🔧 Version injectée: 1.0.7
```

---

### 🧠 Analyse

- Docker Compose remplace `${APP_VERSION}` par la valeur du **shell courant**.

- Si la variable est absente, on peut définir une valeur par défaut :
  
  ```yaml
  command: ["sh", "-c", "echo Version: ${APP_VERSION:-default}"]
  ```

- Cela permet de rendre les Compose files **dynamiques et portables** entre environnements.

---

# 📊 Résumé comparatif

| Aspect             | `environment:`         | `env_file:`            | Substitution `${VAR}`                 |
| ------------------ | ---------------------- | ---------------------- | ------------------------------------- |
| Lieu de définition | dans le YAML           | fichier externe `.env` | variable système ou .env global       |
| Visibilité         | immédiate dans le YAML | masquée (sécurité)     | dépend du shell                       |
| Priorité           | moyenne                | basse                  | haute                                 |
| Cas d’usage        | configuration rapide   | secrets, multi-env     | pipeline CI/CD, paramétrage dynamique |

---

# 💡 Bonnes pratiques

✅ **Structure recommandée :**

```
project/
├── docker-compose.yml
├── .env              # variables globales
├── .env.dev
├── .env.prod
```

✅ **Utilisez `.env`** pour les valeurs globales (`APP_NAME`, `TAG`, etc.)  
✅ **Utilisez `env_file:`** dans chaque service pour ses paramètres spécifiques (DB, API).  
✅ **Ne stockez jamais** de secrets réels dans `environment:` si le fichier est versionné.  
✅ **Combinez substitution + env_file** pour plus de flexibilité :

```yaml
image: "myapp:${APP_VERSION:-latest}"
```

---

# 🧹 Nettoyage global

```bash
docker compose -f docker-compose-environment.yml down
docker compose -f docker-compose-envfile.yml down
docker compose -f docker-compose-combined.yml down
docker compose -f docker-compose-substitution.yml down
docker image prune -f
```

Parfait 🚀  
On passe donc à l’**🧪 Atelier 4 — `ports` vs `expose`**, avec une **démarche ultra pédagogique** (explications ligne par ligne, tests pratiques, sorties réelles, analyses détaillées).  
Cet atelier te permettra de **maîtriser la communication réseau interne/externe** dans Docker Compose.

---

# 🧪 Atelier 4 — `ports` vs `expose` (formes simple et composée)

---

## 1️⃣ Contexte & objectif

Dans Docker Compose, la configuration réseau des conteneurs repose principalement sur deux directives :

- **`ports`** → publication de ports sur la machine **hôte** (extérieur).

- **`expose`** → exposition **interne** entre services d’un même réseau Compose.

## 2️⃣ Préparation de l’environnement

Exécuter sur ta machine Linux (Debian/Ubuntu) :

```bash
sudo apt update
sudo apt install -y docker.io docker-compose curl
sudo systemctl enable --now docker
```

Créer un répertoire de travail :

```bash
mkdir -p ~/atelier-compose-ports && cd ~/atelier-compose-ports
```

---

# ⚙️ CAS 1 — `ports:` (forme simple)

### 🎯 Objectif

Publier un port du conteneur vers le système hôte pour y accéder via le navigateur ou `curl`.

---

### 🧩 Étape 1 — Créer le fichier Compose

Créer **docker-compose-ports-simple.yml** :

```yaml
version: "3.9"

services:
  web:
    image: nginx:1.27
    container_name: demo_ports_simple
    ports:
      - "8080:80"   # <port_hôte>:<port_conteneur>
```

#### 💡 Explication ligne par ligne :

- `image: nginx:1.27` → serveur web standard.

- `ports:` → publie le port **80** interne du conteneur sur le port **8080** de ta machine.  
  Cela signifie que tu pourras atteindre le conteneur via **[http://localhost:8080](http://localhost:8080)**.

---

### ▶️ Étape 2 — Lancer le service

```bash
docker compose -f docker-compose-ports-simple.yml up -d
```

---

### 🔍 Étape 3 — Vérification externe

Sur la machine **hôte** :

```bash
curl -I http://localhost:8080
```

Résultat attendu :

```
HTTP/1.1 200 OK
Server: nginx/1.27.0
Content-Type: text/html
```

---

### 🔍 Étape 4 — Vérification interne

Ouvrir un shell dans le conteneur :

```bash
docker exec -it demo_ports_simple sh
```

À l’intérieur :

```bash
ss -ltn
```

Résultat :

```
State  Recv-Q Send-Q Local Address:Port  Peer Address:Port  Process
LISTEN 0      511    0.0.0.0:80         0.0.0.0:*           
```

➡️ Nginx écoute sur **port 80** interne.  
Docker fait la redirection **8080 → 80**.

---

### 🧠 Analyse

- `ports:` crée une **NAT (Network Address Translation)** entre l’hôte et le conteneur.

- Accessible depuis **le réseau local ou Internet**, selon la configuration.

- Chaque publication crée une **règle iptables** sur l’hôte.

- ⚠️ Les conteneurs avec `ports:` sont donc **exposés publiquement** (utile pour tests, risqué en production sans pare-feu).

---

### 🧹 Nettoyage

```bash
docker compose -f docker-compose-ports-simple.yml down
```

---

# ⚙️ CAS 2 — `expose:` (réseau interne uniquement)

### 🎯 Objectif

Tester l’exposition interne entre services **sans publier le port vers l’hôte**.

---

### 🧩 Étape 1 — Créer le fichier Compose

Créer **docker-compose-expose.yml** :

```yaml
version: "3.9"

services:
  web:
    image: nginx:1.27
    container_name: demo_expose_web
    expose:
      - "80"   # Visible uniquement pour les autres services Compose

  client:
    image: curlimages/curl:8.7.1
    container_name: demo_expose_client
    depends_on:
      - web
    command: ["sh", "-c", "sleep 3 && echo 'Test de connexion interne:' && curl -I http://web:80"]
```

#### 💡 Explication ligne par ligne :

- `web` expose le port 80 **dans le réseau Compose**, mais **pas vers l’extérieur**.

- `client` utilise **le nom DNS `web`** pour joindre le conteneur `web`.

- `curl -I http://web:80` → fait une requête HTTP interne via le réseau Compose.

---

### ▶️ Étape 2 — Lancer

```bash
docker compose -f docker-compose-expose.yml up
```

---

### 🔍 Étape 3 — Observation de la sortie

Résultat attendu :

```
Test de connexion interne:
HTTP/1.1 200 OK
Server: nginx/1.27.0
Content-Type: text/html
```

---

### 🔍 Étape 4 — Vérification depuis l’hôte

Sur l’hôte :

```bash
curl -I http://localhost:80
```

Résultat attendu :

```
curl: (7) Failed to connect to localhost port 80: Connection refused
```

➡️ Normal : `expose` **n’ouvre pas le port vers l’extérieur**.

---

### 🧠 Analyse

- `expose:` rend le port **disponible uniquement aux autres services du même réseau Compose**.

- Aucun mappage sur la machine hôte.

- Très utile pour :
  
  - microservices internes (API internes, bases de données),
  
  - sécurité renforcée (non accessible de l’extérieur).

---

### 🧹 Nettoyage

```bash
docker compose -f docker-compose-expose.yml down
```

---

# ⚙️ CAS 3 — `ports:` (forme composée / longue)

### 🎯 Objectif

Explorer la **forme détaillée** de `ports` (utile pour contrôle fin sur protocole et IP).

---

### 🧩 Étape 1 — Créer le fichier Compose

Créer **docker-compose-ports-long.yml** :

```yaml
version: "3.9"

services:
  web:
    image: nginx:1.27
    container_name: demo_ports_long
    ports:
      - target: 80       # Port du conteneur
        published: 9090  # Port hôte
        protocol: tcp    # Protocole (tcp ou udp)
        mode: host       # Mode: host = publication directe sur hôte
```

---

### ▶️ Étape 2 — Lancer

```bash
docker compose -f docker-compose-ports-long.yml up -d
```

---

### 🔍 Étape 3 — Vérification

Sur l’hôte :

```bash
curl -I http://localhost:9090
```

Résultat attendu :

```
HTTP/1.1 200 OK
Server: nginx/1.27.0
```

---

### 🧠 Analyse

- `target:` → port interne du conteneur.

- `published:` → port exposé sur la machine hôte.

- `protocol:` → choix entre `tcp` ou `udp`.

- `mode:`
  
  - `host` = publication sur le réseau hôte (pas de NAT).
  
  - `ingress` (Swarm uniquement) = load balancing (non applicable ici).

La **forme longue** est utile pour générer dynamiquement les ports, gérer plusieurs protocoles ou contrôler les publications réseau.

---

### 🧹 Nettoyage

```bash
docker compose -f docker-compose-ports-long.yml down
```

---

# ⚙️ CAS 4 — Combinaison `ports` + `expose`

### 🎯 Objectif

Utiliser à la fois `expose` pour communication interne et `ports` pour accès externe.

---

### 🧩 Étape 1 — Créer le fichier Compose

Créer **docker-compose-combined.yml** :

```yaml
version: "3.9"

services:
  web:
    image: nginx:1.27
    container_name: demo_ports_expose
    expose:
      - "80"           # Accès interne
    ports:
      - "8081:80"      # Accès externe
  client:
    image: curlimages/curl:8.7.1
    container_name: demo_ports_expose_client
    depends_on:
      - web
    command: ["sh", "-c", "sleep 2 && echo 'Accès interne au service web:' && curl -I http://web:80"]
```

---

### ▶️ Étape 2 — Démarrage

```bash
docker compose -f docker-compose-combined.yml up
```

---

### 🔍 Étape 3 — Résultats

Sortie de `client` :

```
Accès interne au service web:
HTTP/1.1 200 OK
Server: nginx/1.27.0
```

Depuis l’hôte :

```bash
curl -I http://localhost:8081
```

Résultat :

```
HTTP/1.1 200 OK
Server: nginx/1.27.0
```

---

### 🧠 Analyse

- `expose` → communication **interne** entre services (`web` ↔ `client`).

- `ports` → communication **externe** (hôte ↔ conteneur).

- Les deux peuvent coexister : un service visible à la fois en interne et externe.

---

# 📊 Tableau comparatif récapitulatif

| Directive              | Port visible depuis            | Visible sur                  | But principal         | Exemple typique                         |
| ---------------------- | ------------------------------ | ---------------------------- | --------------------- | --------------------------------------- |
| `ports`                | machine hôte / Internet        | `localhost:PORT`             | exposition externe    | `ports: - "8080:80"`                    |
| `expose`               | autres services du même réseau | pas depuis l’hôte            | communication interne | `expose: - "3306"`                      |
| `ports` (forme longue) | hôte                           | configurable (TCP/UDP, host) | contrôle avancé       | publication sélective                   |
| `ports` + `expose`     | interne + externe              | les deux                     | service mixte         | web accessible localement et en interne |

---

# 💡 Bonnes pratiques

✅ **Toujours privilégier `expose` pour les bases de données** (MySQL, Redis, Mongo).  
✅ **Utiliser `ports` uniquement pour les services publics** (Nginx, API Gateway).  
✅ **Éviter d’exposer 0.0.0.0 inutilement** sur l’hôte (risque sécurité).  
✅ **Utiliser la forme longue** si tu veux gérer :

- plusieurs ports/protocoles,

- publication conditionnelle,

- configuration réseau précise.

---

# 🧹 Nettoyage global

```bash
docker compose -f docker-compose-ports-simple.yml down
docker compose -f docker-compose-expose.yml down
docker compose -f docker-compose-ports-long.yml down
docker compose -f docker-compose-combined.yml down
docker image prune -f
```

Excellent 👌  
Avant de démarrer l’**Atelier 5 — `volumes` avec drivers et options**,  
je vais te présenter une **introduction structurée complète**, avec une **arborescence hiérarchique claire** des **drivers de volumes Docker** et de leurs **options**.

Cette partie servira de **préambule pédagogique** à l’atelier (les cas pratiques suivront ensuite un par un, comme tu l’as demandé).

---

# 🧩 Introduction — Les volumes Docker dans Compose

---

## 🎯 Objectif général

Les **volumes Docker** permettent de **stocker les données en dehors du cycle de vie d’un conteneur**.  
Contrairement aux *bind mounts* (`/host/path:/container/path`), ils sont **gérés directement par Docker** et peuvent être :

- persistants sur l’hôte,

- temporaires (en mémoire),

- ou distants (réseaux, NFS, etc.) selon le **driver utilisé**.

Dans Docker Compose, la section `volumes:` peut apparaître :

- soit au **niveau service** → pour monter un volume dans un conteneur ;

- soit au **niveau racine** → pour **définir** ou **configurer** le volume (driver, options…).

---

## 🌳 Arborescence hiérarchique des drivers et options

```
volumes
├─ <nom_du_volume>
│  ├─ driver: <type_de_driver>
│  │
│  ├─ driver_opts:               # options spécifiques au driver choisi
│  │   ├─ type=                  # type de système (ex: nfs, tmpfs, btrfs)
│  │   ├─ device=                # ressource ou chemin associé
│  │   ├─ o=                     # options de montage (ro, rw, nosuid, etc.)
│  │   ├─ size=                  # taille max (pour tmpfs, local avec quota)
│  │   └─ ...                    # selon le driver
│  │
│  ├─ external: <bool/nom>       # indique si le volume est géré en dehors du projet Compose
│  ├─ labels:                    # métadonnées descriptives
│  └─ name:                      # nom explicite (facultatif)
│
└─ drivers disponibles :
    ├─ local     → par défaut, stocke les données sur l’hôte Docker
    │   ├─ +type=none → bind mount classique
    │   ├─ +type=tmpfs → stockage en RAM
    │   ├─ +device=/chemin → dossier hôte à monter
    │   └─ +o=bind,ro,rw,uid=...,gid=...
    │
    ├─ tmpfs     → stockage temporaire en mémoire (perd les données après redémarrage)
    │   ├─ +size= (en bytes)
    │   └─ +mode= (permissions UNIX)
    │
    ├─ nfs       → volume réseau distant (nécessite nfs-common)
    │   ├─ +device=host:/path
    │   └─ +o=nfsvers=4,addr=...,rw,...
    │
    ├─ smb/cifs  → partage Windows (nécessite cifs-utils)
    │   ├─ +device=//<host>/<share>
    │   └─ +o=username=...,password=...
    │
    ├─ sshfs     → montage via SSH (plugin externe)
    │   ├─ +device=sshfs@<user>@<host>:<path>
    │   └─ +o=allow_other,IdentityFile=...
    │
    ├─ vsphere   → stockage VMware (plugin officiel vSphere Docker Volume)
    │
    ├─ rexray    → plugin multi-cloud (EBS, GCE, Azure)
    │
    └─ autres plugins tiers (netapp, flocker, glusterfs, etc.)
```

---

## 🧠 Points-clés à retenir avant la pratique

| Type de driver | Persistance | Localisation     | Usage typique                 | Exemple                           |
| -------------- | ----------- | ---------------- | ----------------------------- | --------------------------------- |
| `local`        | ✅           | disque de l’hôte | données classiques (DB, logs) | `/var/lib/docker/volumes/...`     |
| `tmpfs`        | ❌ (RAM)     | mémoire vive     | caches, fichiers temporaires  | RAM limitée                       |
| `nfs`          | ✅           | distant (réseau) | cluster, stockage partagé     | `nfsvers=4,addr=10.10.10.5:/data` |
| `cifs`         | ✅           | distant (SMB)    | serveurs Windows, NAS         | `//192.168.1.10/share`            |
| `sshfs`        | ✅           | distant via SSH  | transfert sécurisé distant    | `sshfs@user@host:/data`           |

---

## 💬 Types de volumes dans Compose

| Type                      | Syntaxe               | Description                                              |
| ------------------------- | --------------------- | -------------------------------------------------------- |
| **Nomé (Docker-managed)** | `data:/var/lib/mysql` | Géré par Docker, persiste après suppression du conteneur |
| **Bind mount (local)**    | `./app:/usr/src/app`  | Monte un dossier local de l’hôte                         |
| **Anonymous**             | `/data` sans nom      | Créé automatiquement (supprimé avec le conteneur)        |
| **Tmpfs**                 | `type: tmpfs`         | En mémoire uniquement                                    |

---

## 

# 🧪 Atelier 5 – Volumes dans Docker Compose (v2, MySQL)

---

## 1️⃣ Contexte & Objectif

Les **volumes** assurent la **persistance des données** des conteneurs Docker.  
Ils permettent à une application de conserver ses fichiers (bases de données, logs, etc.) même si le conteneur est recréé.

Dans cet atelier, vous apprendrez à :

- Créer et gérer différents types de volumes sous Docker Compose.

- Comprendre leurs différences, avantages et limites.

- Manipuler aussi bien des volumes **locaux**, **bind mounts**, **tmpfs** que des volumes **distants (NFS)**.

---

## 2️⃣ Préparation de l’environnement

### 💻 Système

Ubuntu (local, sous VirtualBox)

### 🧰 Préparation

```bash
sudo apt update
sudo apt install -y docker.io docker-compose nfs-common curl
sudo systemctl enable --now docker
mkdir -p ~/atelier-compose-volumes && cd ~/atelier-compose-volumes
```

---

# ⚙️ CAS 1 — Volume nommé classique (driver `local`)

### 🎯 Objectif

Persister les données MySQL dans un **volume géré par Docker**.

---

### 🧩 Étape 1 — Créer le fichier Compose

Créer le fichier **docker-compose-volume-named.yml** :

```yaml
version: "3.9"

services:
  mysql:
    image: mysql:8.0
    container_name: mysql_volume_named
    restart: unless-stopped
    environment:
      - MYSQL_ROOT_PASSWORD=rootpass
      - MYSQL_DATABASE=testdb
    volumes:
      - db_data:/var/lib/mysql

volumes:
  db_data:
    driver: local
```

---

### ▶️ Étape 2 — Démarrage

```bash
docker compose -f docker-compose-volume-named.yml up -d
```

---

### 🔍 Étape 3 — Vérifications

Lister les volumes :

```bash
docker volume ls
```

Inspecter le volume :

```bash
docker volume inspect atelier-compose-volumes_db_data
```

Résultat attendu :

```
"Mountpoint": "/var/lib/docker/volumes/atelier-compose-volumes_db_data/_data"
```

Lister le contenu réel :

```bash
sudo ls /var/lib/docker/volumes/atelier-compose-volumes_db_data/_data
```

---

### 🧠 Analyse

- Docker gère le volume et l’attache à MySQL.

- Même après `down`, le volume reste sur le disque.

- Il est réutilisé si vous refaites `up`.

---

### 🧹 Nettoyage

```bash
docker compose -f docker-compose-volume-named.yml down
docker volume rm atelier-compose-volumes_db_data
```

---

# ⚙️ CAS 2 — Bind mount (partage d’un dossier local)

### 🎯 Objectif

Monter un répertoire local dans un conteneur Nginx pour servir un fichier HTML.

---

### 🧩 Étape 1 — Préparer le répertoire hôte

```bash
mkdir -p ~/atelier-compose-volumes/www
echo "<h1>Bonjour depuis la machine hôte !</h1>" > ~/atelier-compose-volumes/www/index.html
```

---

### 🧩 Étape 2 — Créer le fichier Compose

Créer le fichier **docker-compose-bind.yml** :

```yaml
version: "3.9"

services:
  web:
    image: nginx:1.27
    container_name: nginx_bind_mount
    ports:
      - "8080:80"
    volumes:
      - type: bind
        source: ./www
        target: /usr/share/nginx/html
        read_only: true
```

---

### ▶️ Étape 3 — Démarrage

```bash
docker compose -f docker-compose-bind.yml up -d
```

---

### 🔍 Étape 4 — Vérification

Sur l’hôte :

```bash
curl http://localhost:8080
```

Résultat attendu :

```
<h1>Bonjour depuis la machine hôte !</h1>
```

Modifier le fichier :

```bash
echo "<h1>Version mise à jour !</h1>" > ~/atelier-compose-volumes/www/index.html
curl http://localhost:8080
```

Résultat attendu : contenu mis à jour instantanément.

---

### 🧠 Analyse

- **Bind mount** : montage direct d’un répertoire local.

- Les modifications sont **immédiatement visibles**.

- `read_only: true` empêche l’écriture depuis le conteneur.

---

### 🧹 Nettoyage

```bash
docker compose -f docker-compose-bind.yml down
```

---

# ⚙️ CAS 3 — Volume temporaire en mémoire (`tmpfs`)

### 🎯 Objectif

Stocker des données temporaires en **RAM** (non persistantes).

---

### 🧩 Étape 1 — Créer le fichier Compose

Créer **docker-compose-tmpfs.yml** :

```yaml
version: "3.9"

services:
  app:
    image: alpine:3.20
    container_name: demo_tmpfs
    tmpfs:
      - /cache
    command: ["sh", "-c", "echo 'RAM OK' > /cache/test.txt && cat /cache/test.txt && sleep 5"]
```

---

### ▶️ Étape 2 — Lancer

```bash
docker compose -f docker-compose-tmpfs.yml up
```

---

### 🔍 Étape 3 — Relancer

```bash
docker compose -f docker-compose-tmpfs.yml up
```

Le fichier `/cache/test.txt` n’existe plus → données perdues à chaque redémarrage.

---

### 🧠 Analyse

- `tmpfs` stocke les fichiers en mémoire volatile (`/dev/shm`).

- Idéal pour caches, sessions, données temporaires.

- Disparaît dès que le conteneur s’arrête.

---

### 🧹 Nettoyage

```bash
docker compose -f docker-compose-tmpfs.yml down
```

---

# ⚙️ CAS 4 — Driver local avec `driver_opts`

### 🎯 Objectif

Monter un dossier spécifique de l’hôte via `driver_opts`.

---

### 🧩 Étape 1 — Créer le dossier cible

```bash
sudo mkdir -p /tmp/docker-data
sudo chmod 777 /tmp/docker-data
```

---

### 🧩 Étape 2 — Créer le fichier Compose

Créer **docker-compose-driveropts.yml** :

```yaml
version: "3.9"

services:
  app:
    image: alpine:3.20
    container_name: demo_driver_opts
    command: ["sh", "-c", "echo 'driver_opts test' > /data/test.txt && cat /data/test.txt"]
    volumes:
      - custom_data:/data

volumes:
  custom_data:
    driver: local
    driver_opts:
      type: none
      device: /tmp/docker-data
      o: bind
```

---

### ▶️ Étape 3 — Lancer

```bash
docker compose -f docker-compose-driveropts.yml up
```

Résultat :

```
driver_opts test
```

Vérifie sur l’hôte :

```bash
ls /tmp/docker-data
```

➡️ fichier `test.txt` présent.

---

### 🧠 Analyse

- `type: none` + `o: bind` = montage direct vers le chemin indiqué.

- Permet un contrôle précis du dossier de stockage.

- Utile pour séparer des environnements d’exécution.

---

### 🧹 Nettoyage

```bash
docker compose -f docker-compose-driveropts.yml down
sudo rm -rf /tmp/docker-data
```

---

# ⚙️ CAS 5 — Volume distant NFS (AWS ou LAN)

### 🎯 Objectif

Configurer un **serveur NFS distant** (ex : instance EC2)  
et l’utiliser dans un Docker Compose local.

---

## 🧩 Étape 1 — Configuration du serveur NFS (sur AWS Ubuntu)

Sur la machine EC2 distante :

```bash
sudo apt update
sudo apt install -y nfs-kernel-server
sudo mkdir -p /srv/shared
sudo chown nobody:nogroup /srv/shared
echo "Bienvenue depuis NFS AWS" | sudo tee /srv/shared/info.txt
```

Configurer les exports :

```bash
sudo nano /etc/exports
```

Ajouter :

```
/srv/shared  *(rw,sync,no_subtree_check)
```

Recharger :

```bash
sudo exportfs -ra
sudo systemctl restart nfs-kernel-server
```

---

## 🔒 Étape 2 — Règles de pare-feu AWS

Dans le **Security Group** associé à ton instance EC2 :  
ouvrir les ports suivants en **TCP et UDP** :

| Port  | Protocole | Description                   |
| ----- | --------- | ----------------------------- |
| 111   | TCP/UDP   | Portmapper                    |
| 2049  | TCP/UDP   | NFSv4 principal               |
| 20048 | TCP/UDP   | Mountd (certains clients NFS) |

> 🔹 Source : ton IP publique (pas 0.0.0.0/0) pour limiter l’accès.

---

## 🧩 Étape 3 — Test côté client (ta machine Ubuntu)

Remplacer `<IP_AWS>` par l’adresse publique de ton instance.

```bash
sudo mkdir -p /mnt/nfs-test
sudo mount -t nfs -o nfsvers=4,soft <IP_AWS>:/srv/shared /mnt/nfs-test
cat /mnt/nfs-test/info.txt
sudo umount /mnt/nfs-test
```

Résultat :

```
Bienvenue depuis NFS AWS
```

---

## 🧩 Étape 4 — Créer le fichier Compose NFS

Créer **docker-compose-nfs.yml** :

```yaml
version: "3.9"

services:
  app:
    image: alpine:3.20
    container_name: demo_volume_nfs
    command: ["sh", "-c", "ls -l /data && cat /data/info.txt"]
    volumes:
      - nfs_data:/data

volumes:
  nfs_data:
    driver: local
    driver_opts:
      type: nfs
      o: addr=<IP_AWS>,nfsvers=4,soft,rw
      device: :/srv/shared
```

### 📘 Explication des options

| Option      | Rôle                                                                         |
| ----------- | ---------------------------------------------------------------------------- |
| `addr`      | IP du serveur NFS distant                                                    |
| `nfsvers=4` | utilise la version 4 du protocole NFS                                        |
| `soft`      | la commande échoue si le serveur ne répond pas (vs `hard` = attente infinie) |
| `rw`        | autorise lecture/écriture                                                    |
| `device`    | chemin exporté par le serveur (`:/srv/shared`)                               |

---

### ▶️ Étape 5 — Lancer

```bash
docker compose -f docker-compose-nfs.yml up
```

Résultat attendu :

```
total 4
-rw-r--r-- 1 nobody nogroup 26 Oct 27 15:00 info.txt
Bienvenue depuis NFS AWS
```

---

### 🧠 Analyse

- Les données sont hébergées sur le **serveur distant**.

- Toute modification dans `/srv/shared` côté AWS est visible localement.

- La latence dépend du réseau et de la configuration SG.

---

### 🧹 Nettoyage

```bash
docker compose -f docker-compose-nfs.yml down
```

---

# 📊 Résumé comparatif

| Cas | Type         | Persistance | Localisation              | Usage typique          |
| --- | ------------ | ----------- | ------------------------- | ---------------------- |
| 1   | Volume nommé | ✅           | `/var/lib/docker/volumes` | bases de données       |
| 2   | Bind mount   | ✅           | dossier local             | code source, config    |
| 3   | Tmpfs        | ❌ (RAM)     | mémoire vive              | caches temporaires     |
| 4   | Driver_opts  | ✅           | dossier choisi            | stockage avancé        |
| 5   | NFS          | ✅           | serveur distant           | stockage partagé cloud |

---

# 💡 Bonnes pratiques

✅ Toujours utiliser **volumes nommés** pour les données persistantes Docker.  
✅ Privilégier les **bind mounts** en développement (code live).  
✅ Utiliser **tmpfs** pour les fichiers sensibles/éphémères.  
✅ Sur AWS : restreindre les IP autorisées aux ports NFS.  
✅ Sauvegarder les volumes :

```bash
docker run --rm -v db_data:/data alpine tar czf - /data > backup.tar.gz
```

---

# 🧹 Nettoyage global

```bash
docker compose -f docker-compose-volume-named.yml down -v
docker compose -f docker-compose-bind.yml down -v
docker compose -f docker-compose-tmpfs.yml down -v
docker compose -f docker-compose-driveropts.yml down -v
docker compose -f docker-compose-nfs.yml down -v || true
docker volume prune -f
```



# 🌐 Introduction complète — Les *drivers* et *options* réseaux dans Docker Compose

---

## 🎯 Objectif

Dans Docker, un **réseau** (network) définit **comment les conteneurs communiquent entre eux** et avec le monde extérieur.  
Compose permet de **définir, configurer et isoler** ces réseaux avec des **drivers** et des **options avancées (IPAM, DNS, passerelles, etc.)**.

Nous allons examiner :

1. Les **drivers** de réseaux disponibles.

2. Les **options configurables** par driver.

3. L’arborescence logique d’une configuration `networks:` dans un `docker-compose.yml`.

4. Les **implications pratiques** (isolation, connectivité, performances, sécurité).

---

## 🧩 1️⃣ Arborescence complète d’un bloc `networks:` dans Compose

```
networks:
  <nom_du_reseau>:
    driver: <type_driver>
    driver_opts:          # options propres au driver
      com.docker.network.bridge.name: br-demo
      com.docker.network.bridge.enable_icc: "true"
    enable_ipv6: true     # active IPv6
    internal: false       # bloque la sortie vers Internet si true
    external: false       # utilise un réseau Docker déjà existant
    attachable: true      # autorise docker run --network=<nom>
    labels:               # métadonnées personnalisées
      purpose: "test-lab"
    ipam:                 # configuration IP avancée
      driver: default
      config:
        - subnet: 172.25.0.0/16
          gateway: 172.25.0.1
          ip_range: 172.25.0.0/24
          aux_addresses:
            db: 172.25.0.10
            web: 172.25.0.20
```

---

## 🧠 2️⃣ Les principaux *drivers réseau* Docker

| Driver      | Description                                                                     | Usage typique                                                                      |
| ----------- | ------------------------------------------------------------------------------- | ---------------------------------------------------------------------------------- |
| **bridge**  | Réseau virtuel local par défaut. Chaque conteneur reçoit une IP interne isolée. | Environnements de développement / démo                                             |
| **host**    | Partage directement le réseau de la machine hôte (pas d’isolation).             | Applications réseau nécessitant les ports réels (serveurs de monitoring, sniffers) |
| **none**    | Aucun réseau. Pas d’accès externe, ni DNS.                                      | Conteneurs totalement isolés                                                       |
| **overlay** | Réseau distribué entre plusieurs hôtes Docker (Swarm / multi-node).             | Cluster / haute disponibilité                                                      |
| **macvlan** | Attribue une vraie adresse MAC au conteneur sur le LAN physique.                | Cas d’intégration réseau avancée (VMs, appliances virtuelles)                      |
| **ipvlan**  | Variante moderne de macvlan avec meilleure performance.                         | Réseaux physiques segmentés                                                        |

👉 Pour une machine Ubuntu locale (VirtualBox), **bridge**, **host**, et **none** sont les plus pertinents.

---

## ⚙️ 3️⃣ Options globales applicables aux réseaux Docker

| Option        | Valeurs possibles            | Rôle                                                               |
| ------------- | ---------------------------- | ------------------------------------------------------------------ |
| `internal`    | `true` / `false`             | Si `true`, les conteneurs **ne peuvent pas sortir vers Internet**. |
| `external`    | `true` / nom réseau existant | Réutilise un réseau Docker déjà créé.                              |
| `attachable`  | `true`                       | Autorise `docker run` à se rattacher à ce réseau.                  |
| `enable_ipv6` | `true`                       | Active IPv6 (doit être activé dans `/etc/docker/daemon.json`).     |
| `labels`      | `clé:valeur`                 | Métadonnées pour documentation ou automation.                      |

---

## ⚙️ 4️⃣ Options spécifiques au driver `bridge` (le plus courant)

Ces options se définissent dans `driver_opts:` :

| Option                                           | Description                                                             | Exemple             |
| ------------------------------------------------ | ----------------------------------------------------------------------- | ------------------- |
| `com.docker.network.bridge.name`                 | Nom explicite de l’interface réseau sur l’hôte.                         | `br-demo`           |
| `com.docker.network.bridge.enable_icc`           | Communication inter-conteneurs (Inter Container Communication).         | `"true"` (autorise) |
| `com.docker.network.bridge.enable_ip_masquerade` | Active la translation NAT pour la sortie Internet.                      | `"true"`            |
| `com.docker.network.bridge.host_binding_ipv4`    | Adresse IP sur laquelle Docker publie les ports (`0.0.0.0` par défaut). | `"127.0.0.1"`       |
| `com.docker.network.bridge.default_bridge`       | Définit le bridge par défaut.                                           | `"false"`           |
| `com.docker.network.bridge.gateway`              | Adresse IP de la passerelle du réseau.                                  | `"172.25.0.1"`      |

---

## ⚙️ 5️⃣ IPAM – *IP Address Management*

Le bloc `ipam:` permet de contrôler la **plage d’adresses IP**, la **passerelle**, et les **adresses réservées**.

Exemple d’un réseau personnalisé :

```yaml
networks:
  mynet:
    driver: bridge
    ipam:
      driver: default
      config:
        - subnet: 172.30.0.0/16
          gateway: 172.30.0.1
          ip_range: 172.30.0.0/24
          aux_addresses:
            dns: 172.30.0.2
            db: 172.30.0.10
```

| Clé             | Rôle                                                  |
| --------------- | ----------------------------------------------------- |
| `subnet`        | Plage d’adresses IP du réseau (CIDR).                 |
| `gateway`       | Adresse IP de la passerelle.                          |
| `ip_range`      | Sous-plage assignable automatiquement aux conteneurs. |
| `aux_addresses` | Réservation d’adresses pour des services précis.      |

---

## 🔒 6️⃣ Bonnes pratiques et cas d’usage

| Scénario                                          | Recommandation                                           |
| ------------------------------------------------- | -------------------------------------------------------- |
| Applications multi-services sur une seule machine | `bridge` avec IPAM personnalisé                          |
| Conteneur unique exposé publiquement              | `host` pour éviter la redirection de ports               |
| Sandbox de sécurité / tests unitaires             | `none` (aucune sortie réseau)                            |
| Environnement distribué (Swarm, Kubernetes)       | `overlay`                                                |
| Réseau d’entreprise avec intégration LAN          | `macvlan` ou `ipvlan` (si interface physique accessible) |

---

## 🔧 7️⃣ Commandes Docker réseau utiles

| Commande                                | Description                                            |
| --------------------------------------- | ------------------------------------------------------ |
| `docker network ls`                     | Liste les réseaux créés.                               |
| `docker network inspect <nom>`          | Affiche tous les détails (IP, interfaces, containers). |
| `docker network create -d bridge <nom>` | Crée un réseau manuellement.                           |
| `docker network rm <nom>`               | Supprime un réseau.                                    |
| `docker inspect                         | grep -A3 Networks`                                     |

---

## 💡 8️⃣ Points à retenir avant la pratique

- Par défaut, Docker Compose crée **un réseau “project_default”** pour tous les services.

- Chaque service peut appartenir à **plusieurs réseaux**.

- Tous les conteneurs dans un même réseau peuvent **se résoudre par leur nom DNS** (`ping db`, `curl web:8080`).

- Le réseau `bridge` natif de Docker (`bridge`) est différent de ceux créés par Compose (`<project>_default`).

---

## 📦 9️⃣ Drivers additionnels (pour culture DevOps)

| Driver                       | Plugin requis   | Fonction                                  |
| ---------------------------- | --------------- | ----------------------------------------- |
| `macvlan`                    | intégré         | Fournit une adresse MAC réelle sur le LAN |
| `ipvlan`                     | intégré         | Variante plus performante de macvlan      |
| `overlay`                    | intégré (Swarm) | Réseau multi-nœud                         |
| `weave`, `flannel`, `calico` | plugin externe  | Solutions SDN pour Kubernetes             |

---

## 📘 10️⃣ Exemple synthétique complet

```yaml
networks:
  my_custom_net:
    driver: bridge
    driver_opts:
      com.docker.network.bridge.name: br-custom
      com.docker.network.bridge.enable_icc: "true"
      com.docker.network.bridge.enable_ip_masquerade: "true"
    enable_ipv6: false
    internal: false
    ipam:
      config:
        - subnet: 172.28.0.0/16
          gateway: 172.28.0.1
```



1. Réseau *bridge* par défaut

2. Réseau personnalisé avec IPAM

3. Réseau *internal* (pas d’accès Internet)

4. Réseau *host*

5. Réseau *none*

6. Association multi-réseaux dans un même Compose

Parfait 💪  
On reste donc dans ton environnement **réaliste et cohérent** :

> 🖥️ **Une seule machine Ubuntu** (dans VirtualBox),  
> sans cluster, sans Swarm, sans VLAN physique.
> 
> ⚙️ Objectif : comprendre et tester **tous les types de réseaux Docker disponibles localement** avec Compose.

---

# 🧪 Atelier 6 — Réseaux dans Docker Compose (sur machine Ubuntu / VirtualBox)

---

## 1️⃣ Contexte & Objectif

Docker crée par défaut un réseau virtuel *bridge* isolé pour chaque projet Compose.  
Mais il est possible de **créer, nommer et configurer** ses propres réseaux avec des comportements très différents :

| Cas | Type de réseau                     | Objectif principal                            |
| --- | ---------------------------------- | --------------------------------------------- |
| 1   | `bridge` (par défaut)              | Communication entre conteneurs isolés         |
| 2   | `bridge` personnalisé + IPAM       | Contrôle précis de la plage IP                |
| 3   | `internal: true`                   | Réseau privé sans Internet                    |
| 4   | `host`                             | Accès direct au réseau hôte (pas d’isolation) |
| 5   | `none`                             | Conteneur totalement isolé                    |
| 6   | Multi-réseaux dans un même Compose | Communication sélective entre services        |

---

## 2️⃣ Préparation de l’environnement

Sur ta machine Ubuntu (hôte VirtualBox) :

```bash
sudo apt update
sudo apt install -y docker.io docker-compose curl iproute2
sudo systemctl enable --now docker
mkdir -p ~/atelier-compose-networks && cd ~/atelier-compose-networks
```

---

# ⚙️ CAS 1 — Réseau *bridge* par défaut

### 🎯 Objectif

Découvrir le réseau créé automatiquement par Compose et tester la communication interne entre services.

---

### 🧩 Étape 1 — Créer le fichier Compose

Créer **docker-compose-bridge-default.yml** :

```yaml
version: "3.9"

services:
  web:
    image: nginx:1.27
    container_name: demo_bridge_web
    ports:
      - "8080:80"

  client:
    image: curlimages/curl:8.7.1
    container_name: demo_bridge_client
    depends_on:
      - web
    command: ["sh", "-c", "sleep 3 && curl -I http://web:80"]
```

---

### ▶️ Étape 2 — Démarrer

```bash
docker compose -f docker-compose-bridge-default.yml up
```

Résultat attendu :

```
HTTP/1.1 200 OK
Server: nginx/1.27.0
```

---

### 🔍 Étape 3 — Vérifier le réseau

```bash
docker network ls
```

Tu verras un réseau du type :

```
NETWORK ID     NAME                              DRIVER
ab12cd34ef56   atelier-compose-networks_default  bridge
```

Inspecte-le :

```bash
docker network inspect atelier-compose-networks_default | grep -A3 "Containers"
```

➡️ Les deux conteneurs (`web` et `client`) sont connectés à ce réseau.

---

### 🧠 Analyse

- Le réseau `*_default` est **créé automatiquement**.

- Tous les services peuvent communiquer via leur **nom DNS** (`web`, `client`).

- Les ports exposés (`8080:80`) permettent un accès depuis l’hôte Ubuntu.

---

### 🧹 Nettoyage

```bash
docker compose -f docker-compose-bridge-default.yml down
```

---

# ⚙️ CAS 2 — Réseau *bridge* personnalisé avec IPAM

### 🎯 Objectif

Créer un réseau avec un **nom**, une **plage IP spécifique**, et un **bridge** identifiable.

---

### 🧩 Étape 1 — Créer le fichier Compose

Créer **docker-compose-bridge-custom.yml** :

```yaml
version: "3.9"

services:
  web:
    image: nginx:1.27
    container_name: demo_bridge_custom_web
    networks:
      - mynet

  client:
    image: curlimages/curl:8.7.1
    container_name: demo_bridge_custom_client
    depends_on:
      - web
    networks:
      - mynet
    command: ["sh", "-c", "sleep 2 && ping -c 2 web"]

networks:
  mynet:
    driver: bridge
    driver_opts:
      com.docker.network.bridge.name: br-demo
      com.docker.network.bridge.enable_icc: "true"
    ipam:
      driver: default
      config:
        - subnet: 172.25.0.0/16
          gateway: 172.25.0.1
```

---

### ▶️ Étape 2 — Démarrer

```bash
docker compose -f docker-compose-bridge-custom.yml up
```

Résultat attendu :

```
PING web (172.25.0.2): 56 data bytes
64 bytes from web: icmp_seq=1 ttl=64 time=0.091 ms
```

---

### 🔍 Étape 3 — Vérification

Sur l’hôte :

```bash
ip a | grep br-demo
```

Tu verras une interface `br-demo` créée automatiquement.

---

### 🧠 Analyse

- IPAM définit la plage IP (172.25.0.0/16).

- Le `driver_opts` nomme l’interface Linux (`br-demo`).

- `enable_icc: "true"` autorise la communication inter-conteneurs.

- Ce réseau est **personnalisé** et **persistant**.

---

### 🧹 Nettoyage

```bash
docker compose -f docker-compose-bridge-custom.yml down
docker network rm atelier-compose-networks_mynet
```

---

# ⚙️ CAS 3 — Réseau interne (`internal: true`)

### 🎯 Objectif

Créer un réseau **sans sortie Internet**, mais permettant la communication entre conteneurs.

---

### 🧩 Étape 1 — Créer le fichier Compose

Créer **docker-compose-internal.yml** :

```yaml
version: "3.9"

services:
  api:
    image: nginx:1.27
    container_name: demo_internal_api
    networks:
      - internal_net

  test:
    image: curlimages/curl:8.7.1
    container_name: demo_internal_test
    depends_on:
      - api
    networks:
      - internal_net
    command: ["sh", "-c", "sleep 3 && curl -I http://api"]

networks:
  internal_net:
    driver: bridge
    internal: true
```

---

### ▶️ Étape 2 — Démarrer

```bash
docker compose -f docker-compose-internal.yml up
```

Résultat attendu :

```
HTTP/1.1 200 OK
```

---

### 🔍 Étape 3 — Vérification Internet bloqué

Essaye :

```bash
docker exec -it demo_internal_test ping -c 1 8.8.8.8
```

Résultat attendu :

```
ping: bad address '8.8.8.8'
```

---

### 🧠 Analyse

- Le réseau est **fermé vers l’extérieur** (`internal: true`).

- Idéal pour des **bases de données** ou des **services internes**.

- Communication autorisée uniquement entre services du même réseau.

---

### 🧹 Nettoyage

```bash
docker compose -f docker-compose-internal.yml down
```

---

# ⚙️ CAS 4 — Réseau `host`

### 🎯 Objectif

Faire fonctionner un conteneur **sur le réseau de l’hôte** (pas de NAT, pas de bridge).

---

### 🧩 Étape 1 — Créer le fichier Compose

Créer **docker-compose-host.yml** :

```yaml
version: "3.9"

services:
  web:
    image: nginx:1.27
    container_name: demo_host_net
    network_mode: host
```

---

### ▶️ Étape 2 — Lancer

```bash
docker compose -f docker-compose-host.yml up -d
```

Tester :

```bash
curl http://localhost
```

➡️ Accès direct, sans redirection de port.

---

### 🧠 Analyse

- Le conteneur partage **le même réseau** que l’hôte.

- Aucun port n’est publié (`ports:` inutile).

- Performances meilleures, mais **aucune isolation réseau**.

---

### 🧹 Nettoyage

```bash
docker compose -f docker-compose-host.yml down
```

---

# ⚙️ CAS 5 — Réseau `none` (isolation totale)

### 🎯 Objectif

Créer un conteneur totalement isolé : aucun accès Internet, ni DNS.

---

### 🧩 Étape 1 — Créer le fichier Compose

Créer **docker-compose-none.yml** :

```yaml
version: "3.9"

services:
  isolated:
    image: alpine:3.20
    container_name: demo_none
    network_mode: none
    command: ["sh", "-c", "ip a && sleep 10"]
```

---

### ▶️ Étape 2 — Lancer

```bash
docker compose -f docker-compose-none.yml up
```

Résultat :

```
1: lo: <LOOPBACK> mtu 65536 ...
```

➡️ Seule l’interface `lo` (loopback) est visible.

---

### 🧠 Analyse

- Conteneur totalement coupé du réseau.

- Parfait pour **tests de sécurité**, **exécution de batchs** sans dépendance réseau.

---

### 🧹 Nettoyage

```bash
docker compose -f docker-compose-none.yml down
```

---

# ⚙️ CAS 6 — Multi-réseaux (isolation sélective)

### 🎯 Objectif

Faire communiquer une application sur **deux réseaux différents** :  
un réseau interne et un réseau public.

---

### 🧩 Étape 1 — Créer le fichier Compose

Créer **docker-compose-multinet.yml** :

```yaml
version: "3.9"

services:
  db:
    image: mysql:8.0
    container_name: demo_multi_db
    environment:
      - MYSQL_ROOT_PASSWORD=rootpass
    networks:
      - internal_net

  api:
    image: nginx:1.27
    container_name: demo_multi_api
    depends_on:
      - db
    networks:
      - internal_net
      - public_net
    ports:
      - "8085:80"

networks:
  internal_net:
    driver: bridge
    internal: true

  public_net:
    driver: bridge
    ipam:
      config:
        - subnet: 172.30.0.0/16
          gateway: 172.30.0.1
```

---

### ▶️ Étape 2 — Démarrer

```bash
docker compose -f docker-compose-multinet.yml up -d
```

---

### 🔍 Étape 3 — Vérification

Inspecte les réseaux :

```bash
docker inspect demo_multi_api | grep -A5 Networks
```

Tu verras :

```
"internal_net": { "IPAddress": "172.18.0.3" },
"public_net":   { "IPAddress": "172.30.0.2" }
```

---

### 🧠 Analyse

- `api` est connecté à **deux réseaux** :
  
  - `internal_net` pour parler à `db`,
  
  - `public_net` pour recevoir des requêtes HTTP.

- Structure typique des **architectures en couches** (DB privée / API publique).

---

### 🧹 Nettoyage

```bash
docker compose -f docker-compose-multinet.yml down
```

---

# 📊 Résumé global

| Cas | Type de réseau  | Accès Internet | Isolation  | Cas d’usage              |
| --- | --------------- | -------------- | ---------- | ------------------------ |
| 1   | bridge (défaut) | ✅              | Moyenne    | apps internes            |
| 2   | bridge + IPAM   | ✅              | Moyenne    | IP maîtrisée             |
| 3   | internal        | ❌              | Forte      | bases, backend           |
| 4   | host            | ✅              | Faible     | monitoring, perf         |
| 5   | none            | ❌              | Totale     | sandbox                  |
| 6   | multi-net       | Sélectif       | Granulaire | architectures multi-tier |

---

# 💡 Bonnes pratiques

✅ Utiliser des **réseaux internal** pour les services non publics (DB, cache).  
✅ Utiliser un **bridge personnalisé** avec IPAM pour contrôler les IPs.  
✅ Réserver `host` uniquement pour des services système.  
✅ Pour des API publiques, combiner :

```yaml
networks:
  - public_net
  - private_net
```

✅ Inspecter les réseaux régulièrement :

```bash
docker network inspect <nom_reseau>
```

Excellente remarque 👏 — tu mets le doigt sur **deux notions souvent négligées**, mais **fondamentales en production** :  
la directive **`external:`** pour **les réseaux** et pour **les volumes**.  
Effectivement, dans les ateliers 5 (Volumes) et 6 (Networks), on a couvert toutes les configurations *internes* (`driver`, `driver_opts`, `ipam`, etc.),  
mais **pas encore le cas “external”**.  
On va donc corriger cela ici, avant de passer à l’atelier 7.

---

# 🧩 Interlude technique — Le mot-clé `external:` pour réseaux et volumes

---

## 🎯 Objectif

La directive **`external:`** indique à Docker Compose de **réutiliser une ressource déjà existante** (volume ou réseau)  
au lieu de la créer ou de la gérer automatiquement.  
Cela permet de **partager des ressources entre plusieurs projets Compose**,  
ou d’utiliser des volumes/réseaux créés manuellement via `docker network create` / `docker volume create`.

---

# ⚙️ Partie 1 — `external` pour un **réseau**

---

## 🧠 Principe

- Sans `external`, Compose crée un réseau nommé :  
  `nom_du_projet_nom_du_reseau`

- Avec `external: true`, Compose **se connecte à un réseau déjà existant**.  
  Il ne le crée **pas** et **ne le supprime pas**.

Cela permet :

- à plusieurs projets Compose d’être sur le **même réseau logique**,

- de **connecter manuellement** d’autres conteneurs externes (via `docker run --network`).

---

## 🧩 Exemple concret (Ubuntu local)

### Étape 1 — Créer un réseau externe

```bash
docker network create -d bridge shared_net
docker network ls
```

### Étape 2 — Créer le fichier Compose

Créer **docker-compose-external-network.yml** :

```yaml
version: "3.9"

services:
  web:
    image: nginx:1.27
    container_name: demo_external_net_web
    networks:
      - shared_net_ext

networks:
  shared_net_ext:
    external: true
    name: shared_net
```

### Étape 3 — Lancer

```bash
docker compose -f docker-compose-external-network.yml up -d
```

### Étape 4 — Vérification

```bash
docker inspect demo_external_net_web | grep -A3 Networks
```

Résultat :

```
"shared_net": {
    "IPAMConfig": null,
    "Links": null,
    "Aliases": ["demo_external_net_web"]
}
```

---

## 🧠 Analyse

- Le réseau **`shared_net`** existait déjà → Compose s’y rattache.

- À la suppression (`down`), Compose **n’efface pas** le réseau externe.

- Utile pour connecter :
  
  - plusieurs stacks (ex : une base Redis commune),
  
  - un conteneur lancé à la main,
  
  - ou une stack d’intégration avec d’autres outils (Prometheus, ELK…).

---

## 🧹 Nettoyage

```bash
docker compose -f docker-compose-external-network.yml down
docker network rm shared_net
```

---

# ⚙️ Partie 2 — `external` pour un **volume**

---

## 🧠 Principe

Un volume `external` signifie que Compose **ne gère pas la création** du volume :  
il doit déjà exister dans Docker.  
Cela permet :

- de **partager le même volume entre plusieurs projets Compose** (ex: sauvegardes, cache, logs),

- ou d’utiliser un volume **créé à la main** via `docker volume create`.

---

## 🧩 Exemple concret (Ubuntu local)

### Étape 1 — Créer un volume externe

```bash
docker volume create shared_data
docker volume ls
```

### Étape 2 — Créer le fichier Compose

Créer **docker-compose-external-volume.yml** :

```yaml
version: "3.9"

services:
  app:
    image: alpine:3.20
    container_name: demo_external_vol
    command: ["sh", "-c", "echo 'Contenu externe' > /data/hello.txt && cat /data/hello.txt"]
    volumes:
      - shared_vol:/data

volumes:
  shared_vol:
    external: true
    name: shared_data
```

---

### Étape 3 — Lancer

```bash
docker compose -f docker-compose-external-volume.yml up
```

Sortie attendue :

```
Contenu externe
```

---

### Étape 4 — Vérifier le contenu sur le volume

```bash
docker run --rm -v shared_data:/mnt alpine cat /mnt/hello.txt
```

Résultat :

```
Contenu externe
```

---

## 🧠 Analyse

- Le volume `shared_data` était **préexistant** : Compose **ne le crée pas**.

- Il **n’est pas supprimé** par `docker compose down`.

- Cela permet :
  
  - d’utiliser un même volume entre plusieurs stacks Compose ;
  
  - de garder des données partagées entre versions d’une même app.

---

## 🧹 Nettoyage

```bash
docker compose -f docker-compose-external-volume.yml down
docker volume rm shared_data
```

---

# 📊 Comparatif : `external` vs standard

| Élément               | Sans `external`         | Avec `external`                    |
| --------------------- | ----------------------- | ---------------------------------- |
| Création automatique  | ✅ oui                   | ❌ non                              |
| Suppression au `down` | ✅ oui                   | ❌ non                              |
| Nom du réseau/volume  | `project_name_resource` | défini manuellement                |
| Usage multi-projet    | ⚠️ non conseillé        | ✅ oui                              |
| Exemple d’usage       | stack isolée            | stack intégrée, monitoring partagé |

---

# 💡 Bonnes pratiques

✅ Toujours créer explicitement les ressources partagées :

```bash
docker network create shared_net
docker volume create shared_data
```

✅ Référencer ensuite dans Compose :

```yaml
networks:
  shared_net:
    external: true
```

✅ Vérifier les ressources externes avant lancement :

```bash
docker network inspect shared_net
docker volume inspect shared_data
```

✅ Utiliser des noms cohérents :

```
corp_net_backend
corp_data_mysql
```

✅ Attention : ne pas confondre :

- `external: true` (réutilisation)

- `external: { name: ... }` (nom explicite, équivalent mais plus précis).

Excellent 👍  
On enchaîne donc avec **l’🧪 Atelier 7 — `user` et `security_opt`**, toujours dans ton environnement

> 🖥️ Ubuntu sous VirtualBox (une seule machine).

Cet atelier est essentiel : il traite de la **sécurité et de l’isolation d’exécution des conteneurs**.  
On va explorer comment :

- exécuter un conteneur avec un **utilisateur non-root** ;

- restreindre ses privilèges Linux via **`security_opt`** ;

- utiliser **`cap_add`** et **`cap_drop`** pour gérer les *capabilities* Linux ;

- comprendre les implications dans un contexte Compose.

---

Parfait ⚙️  
On passe donc à l’**🧪 Atelier 8 — Limitations de ressources Docker Compose : `mem_limit`, `cpus`, `pids_limit`, `ulimits`**,  
toujours dans le même environnement de travail :

> 🖥️ Ubuntu sous VirtualBox (une seule machine hôte, Docker installé localement).

---

# 🧪 Atelier 9 — Limiter les ressources des conteneurs Docker Compose

---

## 1️⃣ Contexte & Objectif

Docker permet de **limiter la consommation de ressources** d’un conteneur pour éviter qu’il monopolise la machine hôte.  
C’est essentiel dans :

- les environnements de production multi-services ;

- les pipelines CI/CD ;

- ou simplement pour **stabiliser** un environnement d’apprentissage.

Les paramètres principaux sont :

| Directive    | Rôle                                                                 | Exemple                   |
| ------------ | -------------------------------------------------------------------- | ------------------------- |
| `mem_limit`  | limite la mémoire RAM utilisée                                       | `mem_limit: 256m`         |
| `cpus`       | limite la part CPU (exprimée en cœurs logiques)                      | `cpus: 0.5`               |
| `pids_limit` | limite le nombre maximum de processus simultanés                     | `pids_limit: 50`          |
| `ulimits`    | définit les limites *Linux kernel* (fichiers ouverts, threads, etc.) | `ulimits: {nofile: 1024}` |

---

## 2️⃣ Préparation de l’environnement

Sur la machine Ubuntu :

```bash
sudo apt update
sudo apt install -y docker.io docker-compose stress-ng
sudo systemctl enable --now docker
mkdir -p ~/atelier-compose-limits && cd ~/atelier-compose-limits
```

---

# ⚙️ CAS 1 — Limitation mémoire (`mem_limit`)

### 🎯 Objectif

Empêcher un conteneur de dépasser une quantité de RAM donnée.

---

### 🧩 Étape 1 — Créer le fichier Compose

Créer **docker-compose-memlimit.yml** :

```yaml
version: "3.9"

services:
  stress_mem:
    image: polinux/stress
    container_name: demo_mem_limit
    mem_limit: 128m
    command: ["--vm", "2", "--vm-bytes", "200M", "--timeout", "10s"]
```

---

### ▶️ Étape 2 — Lancer

```bash
docker compose -f docker-compose-memlimit.yml up
```

Résultat attendu :

```
stress: info: [1] dispatching hogs: 2 vm
stress: FAIL: [1] (416) <-- VM allocation failed: Cannot allocate memory
```

---

### 🧠 Analyse

- Le conteneur essaie d’allouer 200 Mo alors que `mem_limit` = 128 Mo.

- Le kernel Docker (cgroups) bloque la demande et l’application échoue.

- `mem_limit` s’exprime en :
  
  - octets (`b`)
  
  - kilo (`k`)
  
  - méga (`m`)
  
  - giga (`g`)

> ⚠️ Sur un système sans swap, le conteneur sera immédiatement tué.

---

### 🔍 Vérification

```bash
docker stats demo_mem_limit
```

Tu verras :

```
MEM USAGE / LIMIT: 120MiB / 128MiB
```

---

### 🧹 Nettoyage

```bash
docker compose -f docker-compose-memlimit.yml down
```

---

# ⚙️ CAS 2 — Limitation CPU (`cpus`)

### 🎯 Objectif

Limiter la part de CPU qu’un conteneur peut consommer.

---

### 🧩 Étape 1 — Créer le fichier Compose

Créer **docker-compose-cpulimit.yml** :

```yaml
version: "3.9"

services:
  stress_cpu:
    image: polinux/stress
    container_name: demo_cpu_limit
    cpus: 0.5        # = 50% d’un cœur logique
    command: ["--cpu", "2", "--timeout", "15s"]
```

---

### ▶️ Étape 2 — Lancer

```bash
docker compose -f docker-compose-cpulimit.yml up
```

Ouvre un autre terminal :

```bash
docker stats demo_cpu_limit
```

Tu verras :

```
CPU % ~50.00
```

---

### 🧠 Analyse

- `cpus: 0.5` signifie : le conteneur ne peut pas dépasser **50 % d’un CPU**.

- Sur un CPU à 4 cœurs, il pourra utiliser 0.5 / 4 = 12.5 % du total.

- Cette option agit sur le **temps CPU alloué par cgroups**.

> ⚠️ Sous VirtualBox, l’efficacité dépend du nombre de CPU virtuels alloués à la VM.

---

### 🧹 Nettoyage

```bash
docker compose -f docker-compose-cpulimit.yml down
```

---

# ⚙️ CAS 3 — Limitation du nombre de processus (`pids_limit`)

### 🎯 Objectif

Empêcher un conteneur de lancer trop de processus (fork bomb, erreurs non maîtrisées).

---

### 🧩 Étape 1 — Créer le fichier Compose

Créer **docker-compose-pidslimit.yml** :

```yaml
version: "3.9"

services:
  stress_pids:
    image: alpine:3.20
    container_name: demo_pids_limit
    pids_limit: 50
    command: ["sh", "-c", "for i in $(seq 1 100); do sleep 100 & done; wait"]
```

---

### ▶️ Étape 2 — Lancer

```bash
docker compose -f docker-compose-pidslimit.yml up
```

Résultat attendu :

```
sh: can't fork: Resource temporarily unavailable
```

---

### 🧠 Analyse

- Le conteneur essaie de lancer 100 processus simultanés.

- `pids_limit: 50` bloque la création au-delà de 50.

- Protection utile contre :
  
  - les scripts défaillants,
  
  - les attaques “fork bomb”.

---

### 🧹 Nettoyage

```bash
docker compose -f docker-compose-pidslimit.yml down
```

---

# ⚙️ CAS 4 — Limites système via `ulimits`

### 🎯 Objectif

Configurer les limites système Linux internes (ex : nombre de fichiers ouverts).

---

### 🧩 Étape 1 — Créer le fichier Compose

Créer **docker-compose-ulimits.yml** :

```yaml
version: "3.9"

services:
  app:
    image: alpine:3.20
    container_name: demo_ulimits
    ulimits:
      nproc: 100     # max processus utilisateur
      nofile: 200    # max fichiers ouverts
    command: ["sh", "-c", "ulimit -a && sleep 5"]
```

---

### ▶️ Étape 2 — Lancer

```bash
docker compose -f docker-compose-ulimits.yml up
```

Résultat :

```
max user processes (-u) 100
open files (-n) 200
```

---

### 🧠 Analyse

- `ulimits` reflète la commande Linux `ulimit`.

- Ces paramètres sont **indépendants de Docker** (limites POSIX).

- Très utile pour contrôler :
  
  - le nombre de connexions simultanées (sockets),
  
  - les fichiers log ouverts,
  
  - les processus de fond dans une app.

---

# ⚙️ CAS 5 — Combinaison complète (production réaliste)

### 🎯 Objectif

Combiner plusieurs limitations sur un conteneur applicatif.

---

### 🧩 Étape 1 — Créer le fichier Compose

Créer **docker-compose-combined-limits.yml** :

```yaml
version: "3.9"

services:
  api:
    image: nginx:1.27
    container_name: demo_combined_limits
    mem_limit: 256m
    cpus: 0.25
    pids_limit: 100
    ulimits:
      nofile: 256
    ports:
      - "8080:80"
```

---

### ▶️ Étape 2 — Démarrer

```bash
docker compose -f docker-compose-combined-limits.yml up -d
docker stats demo_combined_limits
```

---

### 🧠 Analyse

- RAM limitée à 256 Mo.

- CPU limité à 25 % d’un cœur.

- 100 processus maximum.

- 256 fichiers ouverts au maximum.

- Parfait pour déployer des **petits services web** ou **API contrôlées**.

---

### 🧹 Nettoyage

```bash
docker compose -f docker-compose-combined-limits.yml down
```

---

# 📊 Tableau comparatif

| Option       | Unité                    | Appliqué par     | Effet                   |
| ------------ | ------------------------ | ---------------- | ----------------------- |
| `mem_limit`  | Mo / Go                  | cgroups (kernel) | RAM maximale autorisée  |
| `cpus`       | fraction (ex: 0.5)       | cgroups          | part CPU allouée        |
| `pids_limit` | nombre                   | cgroups          | nombre max de processus |
| `ulimits`    | variable selon ressource | shell Linux      | limites POSIX internes  |

---

# 💡 Bonnes pratiques

✅ Toujours fixer un `mem_limit` même pour des services simples (évite les crashs du système).  
✅ Utiliser `pids_limit` sur les conteneurs exécutant du code non fiable.  
✅ Pour les serveurs applicatifs :

```yaml
ulimits:
  nofile: 1024
  nproc: 200
```

✅ Vérifier les limites actives :

```bash
docker inspect <container> | grep -A3 Limit
```

✅ Surveiller en temps réel :

```bash
docker stats
```

---

# 🧹 Nettoyage global

```bash
docker compose -f docker-compose-memlimit.yml down
docker compose -f docker-compose-cpulimit.yml down
docker compose -f docker-compose-pidslimit.yml down
docker compose -f docker-compose-ulimits.yml down
docker compose -f docker-compose-combined-limits.yml down
docker image prune -f
```

---

# 🧪 Atelier 8 — Sécurité des conteneurs : `user`, `security_opt`, `cap_add`, `cap_drop`

---

## 1️⃣ Contexte & Objectif

Par défaut, un conteneur Docker s’exécute en **root** à l’intérieur de son espace isolé.  
Cela pose un risque : si un attaquant échappe au conteneur, il devient root sur la machine hôte.

Les options suivantes permettent de **réduire la surface d’attaque** :

| Option                   | Rôle                                                                   |
| ------------------------ | ---------------------------------------------------------------------- |
| `user:`                  | Définit l’UID/GID ou nom d’utilisateur pour exécuter le process.       |
| `security_opt:`          | Configure AppArmor, SELinux, seccomp ou d’autres profils de sécurité.  |
| `cap_add:` / `cap_drop:` | Ajoute ou retire des *capabilities* Linux (permissions système fines). |

---

## 2️⃣ Préparation de l’environnement

Sur ta machine Ubuntu :

```bash
sudo apt update
sudo apt install -y docker.io docker-compose curl
sudo systemctl enable --now docker
mkdir -p ~/atelier-compose-security && cd ~/atelier-compose-security
```

---

# ⚙️ CAS 1 — Exécution en utilisateur non-root (`user:`)

### 🎯 Objectif

Lancer un conteneur avec un utilisateur non-root et vérifier son UID/GID.

---

### 🧩 Étape 1 — Créer le fichier Compose

Créer **docker-compose-user.yml** :

```yaml
version: "3.9"

services:
  app:
    image: alpine:3.20
    container_name: demo_user_app
    user: "1001:1001"              # UID:GID non-root
    command: ["sh", "-c", "id && whoami && touch /data/test.txt || echo 'Permission denied'"]
    volumes:
      - type: bind
        source: ./data
        target: /data
```

### ▶️ Étape 2 — Préparer le dossier

```bash
mkdir -p ~/atelier-compose-security/data
sudo chmod 777 ~/atelier-compose-security/data
```

### ▶️ Étape 3 — Lancer

```bash
docker compose -f docker-compose-user.yml up
```

Résultat attendu :

```
uid=1001 gid=1001
Permission denied
```

---

### 🧠 Analyse

- Le conteneur s’exécute sous l’UID 1001, sans privilèges root.

- L’écriture échoue si les permissions ne sont pas adaptées.

- C’est la **première ligne de défense** contre les élévations de privilèges.

> 🔹 Si tu veux autoriser l’écriture :

```bash
sudo chown 1001:1001 ./data
```

---

### 🧹 Nettoyage

```bash
docker compose -f docker-compose-user.yml down
```

---

# ⚙️ CAS 2 — `security_opt` avec profil AppArmor

### 🎯 Objectif

Appliquer un profil de sécurité **AppArmor** pour restreindre ce que le conteneur peut faire.

---

### 🧩 Étape 1 — Vérifier AppArmor sur Ubuntu

```bash
sudo aa-status
```

Résultat attendu :

```
apparmor module is loaded.
```

---

### 🧩 Étape 2 — Créer un profil AppArmor minimal

Créer **/etc/apparmor.d/docker-nginx** :

```bash
# AppArmor profile minimal pour un conteneur Nginx
profile docker-nginx flags=(attach_disconnected,mediate_deleted) {
  # autoriser les fichiers nécessaires
  file,
  capability net_bind_service,
  network inet stream,
  network inet6 stream,
  deny /etc/shadow r,
}
```

Charger le profil :

```bash
sudo apparmor_parser -r /etc/apparmor.d/docker-nginx
```

---

### 🧩 Étape 3 — Créer le fichier Compose

Créer **docker-compose-apparmor.yml** :

```yaml
version: "3.9"

services:
  web:
    image: nginx:1.27
    container_name: demo_apparmor_web
    security_opt:
      - apparmor:docker-nginx
    ports:
      - "8081:80"
```

### ▶️ Étape 4 — Démarrer

```bash
docker compose -f docker-compose-apparmor.yml up -d
```

---

### 🧠 Analyse

- Le profil AppArmor `docker-nginx` limite les accès fichier et réseau.

- Si tu essayes d’ouvrir `/etc/shadow` depuis le conteneur → **permission denied**.

- Tu peux créer plusieurs profils selon le rôle du conteneur.

---

### 🧹 Nettoyage

```bash
docker compose -f docker-compose-apparmor.yml down
sudo apparmor_parser -R /etc/apparmor.d/docker-nginx
```

---

# ⚙️ CAS 3 — Capabilities Linux (`cap_add` et `cap_drop`)

### 🎯 Objectif

Comprendre comment ajuster les **permissions système fines** d’un conteneur.

---

## 🔹 Rappel rapide

Sous Linux, chaque processus possède un ensemble de *capabilities* :  
ex. `NET_ADMIN`, `SYS_TIME`, `CHOWN`, `KILL`, etc.

Docker retire la plupart d’entre elles par défaut.  
Mais on peut en **ajouter** ou **supprimer** explicitement.

---

### 🧩 Étape 1 — Créer le fichier Compose

Créer **docker-compose-capabilities.yml** :

```yaml
version: "3.9"

services:
  net_test:
    image: alpine:3.20
    container_name: demo_cap_add
    cap_add:
      - NET_ADMIN
    command: ["sh", "-c", "apk add iproute2 -q && ip link add dummy0 type dummy && ip link show dummy0 && sleep 5"]
```

---

### ▶️ Étape 2 — Démarrer

```bash
docker compose -f docker-compose-capabilities.yml up
```

Résultat attendu :

```
dummy0: <BROADCAST,NOARP> mtu 1500 qdisc noop state DOWN mode DEFAULT group default qlen 1000
```

---

### 🧠 Analyse

- `cap_add: NET_ADMIN` donne la capacité de gérer des interfaces réseau.

- Sans cette permission, la commande `ip link add` échoue (`Operation not permitted`).

- Les capabilities sont beaucoup plus fines que `user:` :
  
  - root + `cap_drop: ALL` = conteneur quasi stérile.
  
  - user non-root + `cap_add` sélectif = sécurité renforcée.

---

### 🧩 Étape 3 — Exemple inverse (suppression)

Créer **docker-compose-cap-drop.yml** :

```yaml
version: "3.9"

services:
  test_drop:
    image: alpine:3.20
    container_name: demo_cap_drop
    cap_drop:
      - NET_RAW
    command: ["sh", "-c", "apk add iputils -q && ping -c 1 127.0.0.1 || echo 'ICMP bloqué'"]
```

### ▶️ Étape 4 — Lancer

```bash
docker compose -f docker-compose-cap-drop.yml up
```

Résultat attendu :

```
ICMP bloqué
```

---

### 🧠 Analyse

- `cap_drop: NET_RAW` empêche l’émission de paquets ICMP → `ping` échoue.

- On peut retirer **toutes** les capacités (`cap_drop: ALL`) et n’en réactiver que certaines.

---

# ⚙️ CAS 4 — Combinaison complète (sécurité renforcée)

### 🎯 Objectif

Exécuter une application non-root, avec profil restreint, capabilities limitées, et root FS en lecture seule.

---

### 🧩 Étape 1 — Créer le fichier Compose

Créer **docker-compose-secure.yml** :

```yaml
version: "3.9"

services:
  secure_app:
    image: alpine:3.20
    container_name: demo_secure
    user: "1001:1001"
    read_only: true
    cap_drop:
      - ALL
    security_opt:
      - no-new-privileges:true
    command: ["sh", "-c", "echo 'Sécurité renforcée' && sleep 5"]
```

---

### ▶️ Étape 2 — Lancer

```bash
docker compose -f docker-compose-secure.yml up
```

Résultat :

```
Sécurité renforcée
```

---

### 🧠 Analyse

- `read_only: true` : système de fichiers en lecture seule.

- `no-new-privileges:true` : empêche tout gain de privilèges (sudo, setuid).

- `user:` + `cap_drop: ALL` = aucune élévation possible.

- Parfait pour des **conteneurs applicatifs en production**.

---

# 📊 Résumé comparatif

| Option         | Rôle                                         | Exemple d’usage                    |
| -------------- | -------------------------------------------- | ---------------------------------- |
| `user`         | exécution sous UID/GID spécifique            | éviter le root                     |
| `security_opt` | profils AppArmor / Seccomp / NoNewPrivileges | isolation stricte                  |
| `cap_add`      | ajouter une permission système               | ex: `NET_ADMIN`                    |
| `cap_drop`     | retirer une permission                       | ex: `NET_RAW`                      |
| `read_only`    | FS en lecture seule                          | limiter les modifications internes |

---

# 💡 Bonnes pratiques

✅ Toujours exécuter les conteneurs applicatifs avec `user:` non-root.  
✅ Utiliser `read_only: true` pour les services statiques (nginx, API).  
✅ Supprimer les capacités inutiles (`cap_drop: ALL`).  
✅ Appliquer `security_opt: no-new-privileges:true`.  
✅ Vérifier les capacités d’un conteneur :

```bash
docker inspect <container> | grep Cap
```

✅ Tester les restrictions avec :

```bash
docker exec -it <container> sh
```

---

# 🧹 Nettoyage global

```bash
docker compose -f docker-compose-user.yml down
docker compose -f docker-compose-apparmor.yml down
docker compose -f docker-compose-capabilities.yml down
docker compose -f docker-compose-cap-drop.yml down
docker compose -f docker-compose-secure.yml down
docker image prune -f
```
