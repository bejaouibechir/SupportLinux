# Limites RAM et CPU pour les conteneurs

# 1) Contexte & objectif

- **Contexte** : Sur une machine hôte Linux avec Docker installé, on veut observer l’impact des **limites de ressources** (CPU/RAM) sur un conteneur.

- **Objectif** :
  
  1. Lancer un conteneur **sans limites** puis le soumettre à une charge.
  
  2. Lancer un conteneur **avec limites strictes** (ex. 1 vCPU et 256–512 MiB RAM) et soumettre la même charge.
  
  3. **Comparer** le comportement (perf, OOM kill, throttling CPU) et **vérifier** les limites appliquées.
  
  4. Nettoyer l’environnement.

---

# 2) Préparation de l’environnement

- Machine hôte : Debian/Ubuntu à jour.

- Docker installé et fonctionnel (sinon, installez-le).

- Accès shell avec `sudo`.

### Vérifications rapides

```bash
docker version
docker info | sed -n '1,80p'
```

> Si Docker n’est pas installé, installez-le depuis le dépôt officiel (ou dites-moi et je vous fournis le script complet d’installation pour votre distro).

---

# 3) Exécution pas à pas (avec explications)

## 3.1 Fichiers utilitaires (scripts commentés)

Créer le fichier **scripts/00_check_env.sh** :

```bash
#!/usr/bin/env bash
# Objet : Vérifier l'environnement Docker et quelques infos utiles.
# Usage : ./scripts/00_check_env.sh
set -euo pipefail

# 1) Vérifier que Docker répond
if ! docker info >/dev/null 2>&1; then
  echo "[ERREUR] Docker ne répond pas. Lancez le service ou installez Docker."
  exit 1
fi
echo "[OK] Docker est opérationnel."

# 2) Afficher un résumé utile (version, cgroup driver, cgroup version)
echo "=== Résumé Docker court ==="
docker version --format '{{.Client.Version}} / {{.Server.Version}}' || true
docker info --format 'CGroupDriver={{.CgroupDriver}}  CgroupVersion={{.CgroupVersion}}' || true

# 3) Conseils en cas de cgroup v2
# En cgroup v2, les limites CPU sont gérées via cpu.max, et la mémoire via memory.max.
# Docker traduit --cpus / --cpu-quota et --memory vers les paramètres cgroup correspondants.
echo "[TIP] Sous cgroup v2, attendez-vous à voir cpu.max et memory.max dans /sys/fs/cgroup."
```

Créer le fichier **scripts/10_run_unlimited.sh** :

```bash
#!/usr/bin/env bash
# Objet : Lancer un conteneur SANS limites (CPU/RAM) et y installer stress-ng pour tester.
# Usage : ./scripts/10_run_unlimited.sh
set -euo pipefail

NAME="lab-unlimited"
IMG="ubuntu:24.04"

# 1) Nettoyage préalable si un conteneur du même nom existe
docker rm -f "$NAME" >/dev/null 2>&1 || true

# 2) Lancer le conteneur sans limites en mode interactif en arrière-plan
#    --detach : rester en arrière-plan
#    --name   : nommer le conteneur
#    command  : démarrer un shell qui "dort" pour garder le conteneur vivant
docker run -d --name "$NAME" "$IMG" bash -c "sleep infinity"
echo "[OK] Conteneur sans limites lancé: $NAME"

# 3) Installer stress-ng à l'intérieur (Ubuntu : apt)
#    Remarque : on le fait dans le conteneur pour éviter de construire une image.
docker exec -it "$NAME" bash -c "apt-get update -y && apt-get install -y stress-ng > /dev/null"
echo "[OK] stress-ng installé dans $NAME"

# 4) Lancer une charge CPU + mémoire (en tâche de fond dans le conteneur)
#    --cpu 4      : 4 workers CPU
#    --vm 1       : 1 worker mémoire
#    --vm-bytes 1G: tenter d'allouer ~1 GiB RAM
#    --timeout 60s: durant 60 secondes
docker exec -d "$NAME" bash -c "stress-ng --cpu 4 --vm 1 --vm-bytes 1G --timeout 60s"
echo "[INFO] Charge stress-ng lancée (CPU+RAM) pendant 60s dans $NAME"

# 5) Conseils de suivi
echo "[TIP] Surveillez 'docker stats' dans un autre terminal pour voir l'usage en direct."
```

Créer le fichier **scripts/20_run_limited.sh** :

```bash
#!/usr/bin/env bash
# Objet : Lancer un conteneur AVEC limites (CPU/RAM) et y installer stress-ng pour tester.
# Usage : ./scripts/20_run_limited.sh
set -euo pipefail

NAME="lab-limited"
IMG="ubuntu:24.04"

# Paramètres de limites (ajustez selon vos besoins)
LIMIT_CPUS="1.0"     # limite à 1 vCPU logique
LIMIT_MEM="512m"     # limite RAM totale (ex: 256m, 512m, 1g)

# 1) Nettoyage préalable
docker rm -f "$NAME" >/dev/null 2>&1 || true

# 2) Lancer le conteneur AVEC limites
#    --cpus         : limite stricte en fraction de CPU
#    --memory       : limite stricte RAM
#    --memory-swap  : total RAM+swap autorisé; pour "désactiver" le swap conteneur, = memory
docker run -d --name "$NAME" \
  --cpus "$LIMIT_CPUS" \
  --memory "$LIMIT_MEM" \
  --memory-swap "$LIMIT_MEM" \
  "$IMG" bash -c "sleep infinity"

echo "[OK] Conteneur limité lancé: $NAME (cpus=$LIMIT_CPUS, mem=$LIMIT_MEM, swap=off)"

# 3) Installer stress-ng
docker exec -it "$NAME" bash -c "apt-get update -y && apt-get install -y stress-ng > /dev/null"
echo "[OK] stress-ng installé dans $NAME"

# 4) Lancer une charge identique à celle du conteneur sans limites
#    On garde la même commande pour une comparaison juste.
docker exec -d "$NAME" bash -c "stress-ng --cpu 4 --vm 1 --vm-bytes 1G --timeout 60s"
echo "[INFO] Charge stress-ng lancée (CPU+RAM) pendant 60s dans $NAME"

# 5) Conseils de suivi
echo "[TIP] Comparez 'docker stats' entre $NAME et le conteneur illimité."
```

Créer le fichier **scripts/30_verify.sh** :

```bash
#!/usr/bin/env bash
# Objet : Vérifier visuellement les limites appliquées et l'effet de stress-ng.
# Usage : ./scripts/30_verify.sh
set -euo pipefail

UNL="lab-unlimited"
LIM="lab-limited"

echo "=== docker stats (appuyez sur Ctrl+C pour quitter) ==="
echo "[TIP] Observez l'écart CPU% et MEM USAGE/LIMIT entre $UNL et $LIM."
docker stats "$UNL" "$LIM"
```

Créer le fichier **scripts/40_inspect_limits.sh** :

```bash
#!/usr/bin/env bash
# Objet : Inspecter les limites configurées côté Docker et côté cgroups du conteneur limité.
# Usage : ./scripts/40_inspect_limits.sh
set -euo pipefail

LIM="lab-limited"

echo "=== Inspect HostConfig (limites déclarées) ==="
docker inspect "$LIM" --format '{{json .HostConfig}}' | jq . | sed -n '1,200p'

# Récupérer le chemin cgroup du conteneur (cgroup v2 : /sys/fs/cgroup/<...>)
# Note: cgroup paths varient suivant la config; on tente une approche générique :
echo "=== Approx cgroup paths (peuvent varier selon la distro/daemon) ==="
CID=$(docker inspect -f '{{.Id}}' "$LIM")
echo "ContainerID=$CID"
# Chercher les fichiers cpu.max et memory.max (cgroup v2) :
CGP=$(grep -RIl "$CID" /sys/fs/cgroup 2>/dev/null | head -n1 | xargs dirname || true)
if [[ -n "${CGP:-}" ]]; then
  echo "[INFO] cgroup path: $CGP"
  if [[ -f "$CGP/cpu.max" ]]; then
    echo "--- cpu.max ---"
    cat "$CGP/cpu.max"
  fi
  if [[ -f "$CGP/memory.max" ]]; then
    echo "--- memory.max ---"
    cat "$CGP/memory.max"
  fi
else
  echo "[WARN] cgroup path non localisé automatiquement. Environnement spécifique."
  echo "      Consultez manuellement /sys/fs/cgroup/ pour cpu.max et memory.max."
fi
```

Créer le fichier **scripts/90_cleanup.sh** :

```bash
#!/usr/bin/env bash
# Objet : Nettoyer l'environnement de l'atelier.
# Usage : ./scripts/90_cleanup.sh
set -euo pipefail

for C in lab-unlimited lab-limited; do
  docker rm -f "$C" >/dev/null 2>&1 || true
done
echo "[OK] Conteneurs supprimés."

# Vous pouvez aussi nettoyer les images et réseaux dangling si nécessaire :
# docker system prune -f
```

> Donnez les droits d’exécution une seule fois :

```bash
chmod +x scripts/*.sh
```

---

## 3.2 Démarrage du labo

1. Vérifier l’environnement :

```bash
./scripts/00_check_env.sh
```

2. Lancer le conteneur **sans limites** et démarrer une charge :

```bash
./scripts/10_run_unlimited.sh
```

3. Lancer le conteneur **avec limites** et démarrer la même charge :

```bash
./scripts/20_run_limited.sh
```

4. Ouvrir un **deuxième terminal** et observer en direct :

```bash
./scripts/30_verify.sh
```

- Surveillez **CPU%** et **MEM USAGE / LIMIT** pour `lab-unlimited` vs `lab-limited`.

- Attendez la fin des 60 s de `stress-ng` pour chaque conteneur.
5. Inspecter les **limites déclarées** et (si possible) **cgroup v2** :

```bash
./scripts/40_inspect_limits.sh
```

---

# 4) Vérification & résultats attendus

- **Sans limites (`lab-unlimited`)**
  
  - `docker stats` : peut monter très haut en **CPU%** (selon votre machine).
  
  - **Mémoire** : peut grimper au-delà de 512 MiB si la charge (`--vm-bytes 1G`) réussit.
  
  - Pas de `MEM LIMIT` visible (ou “N/A”).

- **Avec limites (`lab-limited`)**
  
  - `docker stats` : **CPU% plafonné** (throttling) autour de 100% d’un vCPU (la lecture exacte dépend de la façon dont Docker/Compose affichent la limite).
  
  - **Mémoire** : `MEM USAGE / LIMIT` doit **montrer la limite** (ex. 512 MiB).
  
  - Si la charge mémoire tente 1 GiB (`--vm-bytes 1G`) alors que `--memory=512m` :
    
    - Vous pouvez voir un **OOM kill** du process stress-ng à l’intérieur du conteneur.
    
    - Le conteneur reste généralement UP (sauf si le process principal est tué).
    
    - `docker logs lab-limited` peut montrer des indices, et `docker inspect` un `OOMKilled` dans `.State`.

- **Inspection cgroups (cgroup v2)**
  
  - `cpu.max` : valeurs du type `quota period` (ex. `100000 100000` pour ~1 CPU).
  
  - `memory.max` : valeur en bytes (ex. ~`536870912` pour 512 MiB).

---

# 5) Nettoyage / rollback

Quand vous avez fini, exécutez :

```bash
./scripts/90_cleanup.sh
```

Optionnel (libérer davantage d’espace) :

```bash
docker system prune -f
```

---

# 6) Conseils & pièges (tips & pitfalls)

- **`--cpus` vs `--cpu-shares`**  
  `--cpus` impose une **vraie limite**.  
  `--cpu-shares` n’est qu’un **poids relatif** (utile en contention, mais pas une barrière dure).

- **Swap désactivé** pour le conteneur  
  Utilisez `--memory-swap` **égal** à `--memory` pour **interdire** l’usage de swap par le conteneur (comportement plus prévisible pour le labo).

- **Compose local vs Swarm**  
  La section `deploy.resources.limits` est prise en compte **en Swarm**.  
  En **Compose local**, préférez des clés supportées par le Compose Spec (p. ex. `mem_limit`, `cpus` au niveau du service) ou lancez vos conteneurs en ligne de commande comme dans cet atelier.

- **Images avec `stress-ng` prêt à l’emploi**  
  On a choisi d’installer `stress-ng` dans le conteneur pour rester simple.  
  En production de tests, vous pouvez construire une image dédiée (Dockerfile) pour éviter l’`apt`.

- **cgroup v2**  
  La plupart des distros modernes utilisent cgroup v2 : attendez-vous à trouver `cpu.max`, `memory.max` plutôt que `cpu.cfs_quota_us`, etc.

---

## (Bonus) Exemple Docker Compose (pour usage local hors Swarm)

Créer le fichier **docker-compose.yml** :

```yaml
version: "3.9"
services:
  unlimited:
    image: ubuntu:24.04
    container_name: lab-unlimited-compose
    command: ["bash", "-c", "sleep infinity"]
    # Pas de limites ici (illimité côté conteneur)

  limited:
    image: ubuntu:24.04
    container_name: lab-limited-compose
    command: ["bash", "-c", "sleep infinity"]
    # Limites pour usage local avec Compose (hors Swarm)
    # Selon votre version de Compose, ces clés sont supportées pour le moteur local.
    mem_limit: 512m
    cpus: 1.0
```

> Après `docker compose up -d`, vous pouvez `exec` dedans comme dans les scripts (installer `stress-ng`, lancer la charge) puis observer via `docker stats`.


